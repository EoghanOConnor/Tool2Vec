{
  "pandas.CategoricalDtype.categories": {
    "new_func": "EnumeratedClassification",
    "description": "This property retrieves an index object encompassing all permissible classifications within a categorical datatype. These classifications are the discrete, distinct values that the data type can take.",
    "class": "CategoricalDtype"
  },
  "pandas.ArrowDtype": {
    "new_func": "PlumeTypeSpecifier",
    "description": "This class represents a data type specifier compatible with a specific columnar data format's types. It's primarily used for specifying data types with additional parameters that aren't covered by typical string representations. The class is marked as experimental and may undergo changes. Input argument: pyarrow_dtype (an instance of columnar format's data type). Return value: An object representing the specified data type.",
    "class": "ArrowDtype"
  },
  "pandas.Categorical.dtype": {
    "new_func": "CategoryDataTypeAttribute",
    "description": "This property provides access to the data type object specific to categorical variables for a given categorical array. The returned object details the types and, potentially, the order of the categorical data.",
    "class": "Categorical"
  },
  "pandas.Categorical.ordered": {
    "new_func": "HierarchySpecifier",
    "description": "This property indicates if the categorical variable's values possess a natural rank or sequence. It returns a boolean value signifying whether there is a meaningful order to the categories.",
    "class": "Categorical"
  },
  "pandas.CategoricalIndex.as_ordered": {
    "new_func": "RankedCategoricalIndexer",
    "description": "This method transforms a categorical index into one that has a defined sequence, implying a logical progression among the index's values. The method returns a new, sequence-enforced version of the index.",
    "class": "CategoricalIndex"
  },
  "pandas.CategoricalIndex.add_categories": {
    "new_func": "CategoricalIndex_augment_classes",
    "description": "Appends new class labels to the existing classification scheme within an index structure. These additional labels are integrated at the end of the current hierarchy, initially not associated with any elements. Input: new_classes (category or list-like) - Additional class labels to incorporate. Output: An object similar to the original but with the expanded set of class labels. Exception: Raises a ValueError if the new labels intersect with existing ones or fail integrity checks as valid class labels.",
    "class": "CategoricalIndex"
  },
  "pandas.Categorical.__array__": {
    "new_func": "Categorical_to_array",
    "description": "Provides a compatible one-dimensional array representation of the categorical data. Output: An array adhering to the specified data type or, by default, maintaining the original data classification type.",
    "class": "Categorical"
  },
  "pandas.Categorical.from_codes": {
    "new_func": "Categorical_construct_from_indices",
    "description": "Generates a categorical object utilizing pre-defined indices and class labels or a specified data type. Input: indices (array-like of int) - Array of integer indices mapping to categories. class_labels (index-like, optional) - Unique class labels for the categorical object. If not supplied, must be defined in the data type. sequence_order (bool, optional) - Determines if the categorical is ordered. data_type (CategoricalDtype or 'category', optional) - Data type specification for the categorical object. validate_codes (bool, default True) - Ensures the validity of the indices for the given data type. Output: A categorical object created from the provided indices and class labels or data type.",
    "class": "Categorical"
  },
  "pandas.BooleanDtype": {
    "new_func": "LogicalDataType",
    "description": "Defines a data type for binary data, with true/false states, as an extension to the typical data types. Note: This data type is under development and aspects of its API or internal behavior may change.",
    "class": "BooleanDtype"
  },
  "pandas.Categorical": {
    "new_func": "CategoryArray",
    "description": "Creates a specialized structure for handling data that can take on a limited number of distinct categories, potentially with an inherent order. Unlike numerical data, operations like addition or division are not applicable. Input: data_values (list-like) - The potential categories. class_labels (Index-like, unique, optional) - Explicitly defined unique category labels. If omitted, deduced from data_values. is_ordered (bool, default False) - Indicates if the categories have a meaningful sequence. data_type (CategoricalDtype) - Specific data type for category encoding. Exception: ValueError is raised if the class_labels are not valid or TypeError if an order is specified without class_labels and the data_values are not inherently sortable.",
    "class": "Categorical"
  },
  "pandas.DataFrame.abs": {
    "new_func": "positive_transform",
    "description": "Converts each element in the data structure to its non-negative counterpart. This operation is only applicable to elements that are numeric. The result is a similar data structure containing the non-negative values of each element.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.__iter__": {
    "new_func": "axis_enumerator",
    "description": "Provides an iterator to traverse along the index axis of the data structure, enabling iteration over its elements.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.add": {
    "new_func": "increment_merge",
    "description": "Combines the data structure with another, performing an element-wise summation. It allows for a specified value to replace any missing entries during the operation. This method also supports an arithmetic operation involving addition. Arguments: other (scalar, sequence, compatible data structure) - The element(s) to add to the data structure. axis (0 for index, 1 for columns) - The axis along which to perform the addition. level (int or label) - The level in a MultiIndex to align with. fill_value (number) - The value to use for replacing missing entries. Returns: A new data structure with the summation result.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.add_suffix": {
    "new_func": "append_postfix",
    "description": "Attaches a specified substring to the end of the labels within the data structure. For a series, it alters row labels, while for a data frame, it modifies column labels. Arguments: postfix (string) - The substring to append to each label. axis (0 for index, 1 for columns, or None) - The axis on which to operate, adding the postfix to labels. Returns: A new series or data structure with updated labels.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.align": {
    "new_func": "synchronize_structure",
    "description": "Adjusts two data objects to conform to the same axes, using a specific method to determine the alignment. The alignment can be defined separately for each axis. Arguments: other (compatible data structure) - The object to align with. join (string, one of 'outer', 'inner', 'left', 'right') - The type of alignment to perform. axis (index or columns, or None) - The axis to align. level (int or name) - The level for aligning a MultiIndex. copy (bool) - Whether to return new objects or not. fill_value (compatible value) - The value to use for missing entries. Returns: A tuple containing the two aligned objects.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.aggregate": {
    "new_func": "consolidate_data",
    "description": "Performs one or multiple operations across a chosen axis, condensing the dataset. This method can receive a single operation, a collection of operations, or a mapping of column-specific operations. It can be applied per column or per row, depending on the specified axis. Parameters: operation: a callable, string, list, or dictionary specifying the operation(s) to perform. axis: 0 to apply per column, 1 to apply per row. Variable arguments and keyword arguments are passed to the operation(s). Returns: Depending on the operation(s) provided, it can return a scalar value, a Series, or a DataFrame with the aggregated results.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.any": {
    "new_func": "exists_truthy",
    "description": "Checks if at least one truthy value exists over a specified axis or within the entire dataset. It disregards missing or null values by default but can include them if specified. Parameters: axis: specifies the axis to be evaluated or None for the entire dataset. bool_only: if set, it limits the evaluation to boolean columns only. skipna: considers missing values as False when true, unless all values are missing. Returns: A Series or DataFrame indicating the presence of truthy values across the specified axis.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.asof": {
    "new_func": "last_valid_snapshot",
    "description": "Retrieves the latest valid entries up to certain dates without missing values. If a subset of columns is specified, only those columns are considered for the presence of missing values. Parameters: where: a date or an array-like of dates specifying the point in time for the snapshot. subset: columns to consider when checking for missing values. Returns: Depending on the input, it returns a scalar, Series, or DataFrame with the last valid data before the specified date(s).",
    "class": "DataFrame"
  },
  "pandas.DataFrame.apply": {
    "new_func": "execute_by_axis",
    "description": "Executes a function across a specified axis, passing each row or column to the function as a Series or array. The behavior can be fine-tuned with additional parameters to control the nature of the operation and its results. Parameters: function: the callable to apply to each segment. axis: 0 to apply the function to columns, 1 to rows. raw: if true, the function receives an array instead of a Series. result_type: controls the type of the resulting output. args: additional positional arguments for the function. engine: the computation engine to use ('python' or 'numba'). engine_kwargs: keyword arguments for the computation engine. Returns: A Series or DataFrame with the results of applying the function along the given axis.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.assign": {
    "new_func": "append_columns",
    "description": "Creates a new dataset by appending new columns to the existing ones. The new columns are specified as keyword arguments, which can be a callable, a Series, a scalar, or an array. Parameters: Keyword arguments consisting of {str: callable or Series}, where the key represents the column name. Returns: A new DataFrame with the existing and newly appended columns.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.backfill": {
    "new_func": "future_element_filler",
    "description": "Populate missing entries using subsequent valid data points along a specified axis. If the 'inplace' parameter is set to true, the operation modifies the data structure in place and returns None; otherwise, it returns a modified copy with the missing entries filled.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.bool": {
    "new_func": "to_single_truth_value",
    "description": "Extracts the truth value from a data structure with exactly one element. If the data structure contains more than one element, or the single element is not a boolean value, a ValueError is raised. The function returns the extracted boolean value.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.boxplot": {
    "new_func": "quartile_visualizer",
    "description": "Generates a graphical representation of data distribution using quartiles. The method creates plots that illustrate the central 50% of the values, the median, and potential outliers using a specified grouping or overall. The user can customize various aspects of the plot, such as the axis, font size, rotation of labels, grid visibility, figure size, and layout. Depending on the 'return_type' parameter, it may return the plot axes, a dictionary with plot components, both, or a NumPy array of axes.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.clip": {
    "new_func": "boundary_restrictor",
    "description": "Limits the data to a specified range, setting values below or above given thresholds to the threshold values. This operation can be applied across a specified axis and can be done in place. Returns the modified data structure, or None if the operation is performed in place.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.between_time": {
    "new_func": "temporal_interval_selector",
    "description": "Retrieves entries within a specific time frame on a given day. The method can also be used inversely to select data outside the defined interval by setting the 'start_time' later than 'end_time'. It operates on the assumption that the index is time-based and returns the data that meet the time constraints. If the index does not support time-based operations, a TypeError is thrown.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.corr": {
    "new_func": "columnwise_affinity",
    "description": "Calculates the statistical association between columns, ignoring missing values. Available methods include 'pearson', 'kendall', and 'spearman' for different types of correlation coefficients, or a user-defined callable for custom calculations. Requires a sufficient number of observations per column pair to yield a valid outcome. Can optionally focus on numerical data types only. Outputs a matrix reflecting the association strengths where the diagonal elements are unity and the matrix is symmetric. Parameters: method (str or callable), min_periods (int, optional), numeric_only (bool, default False). Returns: a matrix of correlation coefficients.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.convert_dtypes": {
    "new_func": "optimize_column_types",
    "description": "Transforms column data types to use the most appropriate data types that support missing values, such as 'pd.NA'. Offers control over conversion for object types, strings, integers, booleans, and floating-point numbers. An option to select a specific data type backend is also provided. Parameters: infer_objects (bool, default True), convert_string (bool, default True), convert_integer (bool, default True), convert_boolean (bool, default True), convert_floating (bool, default True), dtype_backend (str, default 'numpy_nullable'). Returns: a copy of the input with updated data types.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.count": {
    "new_func": "non_null_tally",
    "description": "Tallies non-missing cells across specified rows or columns. Recognizes None, NaN, NaT, and the library's native missing value as missing. Parameters: axis ({0 or 'index', 1 or 'columns'}, default 0), numeric_only (bool, default False). Returns: a tally of non-missing entries for each specified dimension.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.cummin": {
    "new_func": "progressive_minimum",
    "description": "Generates a sequence or tabular structure of the same size containing the progressive lowest values along a specified axis. Excludes missing values by default but can consider them if specified. Parameters: axis ({0 or 'index', 1 or 'columns'}, default 0), skipna (bool, default True). Returns: a sequence or tabular structure with the cumulative lowest values.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.corrwith": {
    "new_func": "mutual_affinity_measure",
    "description": "Calculates the mutual statistical association between the rows or columns of the primary dataset and another dataset. Aligns both datasets along their axes prior to computing the association metrics. Offers various methods for calculating correlation coefficients or accepts a custom callable function. Parameters: other (Dataset or Sequence), axis ({0 or 'index', 1 or 'columns'}, default 0), drop (bool, default False), method (str or callable), numeric_only (bool, default False). Returns: a sequence of pairwise association metrics.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.dot": {
    "new_func": "matrix_product",
    "description": "Calculates the matrix product with another similar structured data container. This method allows you to take the matrix product of the calling data container with another array-like structure, including elements of similar objects or arrays. It also supports the matmul operator '@'. Input Parameters: other (Series, similar structured data container, or array-like): The object to compute the matrix product with. Returns: If 'other' is a Series, the result is a Series. If 'other' is a similar structured data container or an array, the result is a similar structured data container or an array.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.cov": {
    "new_func": "pairwise_column_covariance",
    "description": "Calculates the covariance between pairs of columns, excluding any missing or NA values. The output is a matrix representing the covariance values between the columns of the data container. You can set a minimum number of observations required for a valid result. Commonly used for time series data analysis. Input Parameters: min_periods (int, optional): Minimum number of observations required per pair of columns to have a valid result. ddof (int, default 1): Modifier for the divisor in the calculation. numeric_only (bool, default False): If True, includes only numeric data. Returns: A new data container with the covariance matrix of the column series.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.describe": {
    "new_func": "summary_statistics",
    "description": "Generates summary statistics that capture aspects such as the central tendency, dispersion, and distribution shape, excluding missing values. Works with numeric and categorical data, and the output varies according to the input type. Input Parameters: percentiles (list-like of numbers, optional): Percentiles to include in the output, between 0 and 1. include (list-like of dtypes or 'all', optional): Specifies data types to include in the result. exclude (list-like of dtypes, optional): Specifies data types to omit from the result. Returns: A new data container or Series with summary statistics of the provided data.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.droplevel": {
    "new_func": "eliminate_hierarchy",
    "description": "Removes specified levels from the index or column labels. Input Parameters: level (int, str, or list-like): The levels to remove, identified by name or index. axis ({0 or 'index', 1 or 'columns'}, default 0): The axis along which to remove the levels. Returns: A data container or Series with the specified index or column levels removed.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.drop": {
    "new_func": "discard_labels",
    "description": "Eliminates specified row or column labels. Input Parameters: labels (single label or list-like): Index or column labels to eliminate. axis ({0 or 'index', 1 or 'columns'}, default 0): Axis from which to remove the labels. index (single label or list-like): Directly specify index names to remove. columns (single label or list-like): Directly specify column names to remove. level (int or level name, optional): For a multi-level index, the level from which labels will be removed. inplace (bool, default False): If True, performs operation in place and returns None. errors ({'ignore', 'raise'}, default 'raise'): If 'ignore', suppresses errors for labels that don't exist. Returns: A data container with specified labels removed or None if 'inplace' is True. Raises KeyError if labels are not found and 'errors' is set to 'raise'.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.expanding": {
    "new_func": "broadening_calculations",
    "description": "Performs calculations over an increasing scope of data points in a tabular structure. The scope begins with a minimum number of entries and widens to encompass more data as it progresses. Parameters: min_periods (int, default 1) - The least count of observations within the scope necessary to produce a result; else, the outcome is NaN. axis (int or str, default 0) - Determinates whether the operation extends across rows (0 or 'index') or columns (1 or 'columns'). method (str {'single', 'table'}, default 'single') - Specifies the execution manner of the operation either per column/row or the entire structure. Returns: An object that encapsulates the expanding calculations.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.cummax": {
    "new_func": "accumulative_peak",
    "description": "Determines the growing peak value along a specified axis within a tabular data structure. The result retains the original dimensions and contains the maximum value encountered so far. Parameters: axis ({0 or 'index', 1 or 'columns'}, default 0) - Indicates the direction of computation. skipna (bool, default True) - Whether to ignore or consider NA/null values in the computation. Returns: A structure of equivalent size with the cumulative peak values.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.fillna": {
    "new_func": "populate_voids",
    "description": "Replaces missing or undefined entries with a given value or via a defined method. Parameters: value (scalar, dict, Series, or DataFrame) - The replacement value or a collection mapping replacements to indexes or columns. method ({'backfill', 'bfill', 'ffill', None}, default None) - The procedure for filling gaps. axis ({0 or 'index', 1 or 'columns'}) - The axis along which to apply the replacements. inplace (bool, default False) - Whether to modify the data structure in place. limit (int, default None) - Sets a cap on the number of consecutive missing values to replace. downcast (dict, default None) - An optional dict on how to downcast types if possible. Returns: The modified data structure with filled values or None if modifications were made in place.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.ffill": {
    "new_func": "propagate_forward",
    "description": "Imputes missing or undefined entries by carrying the last known value forward along a given axis. Parameters: axis ({0 or 'index', 1 or 'columns'}) - The axis for applying the imputation. inplace (bool, default False) - Whether the data structure should be updated directly. limit (int, default None) - The maximum number of consecutive undefined values to impute. limit_area ({None, 'inside', 'outside'}, default None) - Constrains the imputation to a specific area relative to valid values. downcast (dict, default None) - A mapping dictating if type downcasting is feasible. Returns: The data arrangement with forward-filled values, or None if changes were made directly.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.filter": {
    "new_func": "refine_by_labels",
    "description": "Extracts a subset of rows or columns from a data structure based on specified index labels. It does not consider the data content but operates on the index labels. Parameters: items (list-like) - The labels to retain. like (str) - A string pattern that labels must match. regex (str) - A regular expression pattern that labels must satisfy. axis ({0 or 'index', 1 or 'columns', None}, default None) - The axis to apply the label filtering. Returns: A subset of the original data structure filtered by the specified labels.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.first": {
    "new_func": "initial_timeframe",
    "description": "Extracts the beginning segments of temporal data using a specified duration. This method is being phased out and it is recommended to utilize a mask with .loc for this purpose. When working with chronologically ordered data, it allows for the retrieval of entries falling within the initial period as defined by the given duration. Input: duration (string, DateOffset, or dateutil.relativedelta) - The time span for which data should be retrieved, e.g., '1ME' for the initial month's data. Output: A subset of the original dataset. Exception: TypeError is raised if the dataset's index isn't chronologically ordered.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.first_valid_index": {
    "new_func": "initial_nonmissing_locator",
    "description": "Determines the position of the first occurrence where the data is not missing, or returns None if all entries are missing. Output: The type corresponding to the index of the initial non-missing value.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.floordiv": {
    "new_func": "integral_quotient",
    "description": "Calculates the element-wise quotient of the dataset and another specified element, rounding down to the nearest whole number. It's similar to the // operator but also allows for the substitution of a specified value for any missing data points. Input: other (scalar, sequence, Series, dict, or another dataset) - The divisor. axis (0 or 'index', 1 or 'columns') - The axis along which to perform the operation. level (int or label) - If the dataset has a hierarchical index, this specifies the level to use for broadcasting. fill_value (float or None) - The value to use for replacing any missing data. Output: A dataset containing the results of the division, rounded down.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.ge": {
    "new_func": "at_least_as_large",
    "description": "Compares the dataset with another element-wise, determining whether each element is greater than or equal to its counterpart. It's part of a set of methods that provide comparisons similar to >=, allowing you to specify the axis and hierarchical index level for the comparison. Input: other (scalar, sequence, Series, or another dataset) - The comparison target. axis (0 or 'index', 1 or 'columns') - The axis for the comparison. level (int or label) - The hierarchical index level to use for broadcasting. Output: A boolean dataset representing the results of the comparison.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.from_dict": {
    "new_func": "construct_from_mapping",
    "description": "Builds a new dataset from a mapping of array-like structures or mappings. This constructor transforms a dictionary to a dataset by columns or by index, with the option to specify the data type. Input: data (dictionary) - The dictionary with array-like or dictionary values. orient (string) - The orientation of the input data, with 'columns' for dictionary keys as columns, 'index' for keys as rows, or 'tight' for a structured dictionary. dtype (dtype) - The data type to enforce. columns (list) - The column labels for the resulting dataset when using 'index' orientation. Output: A newly constructed dataset.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.iloc": {
    "new_func": "integer_based_selector",
    "description": "Enables selection by pure integer-based positions. It accepts integer, list or array of integers, slice objects with integers, boolean arrays, and callables that return one of the aforementioned types. It allows for the retrieval of a specific sub-section of the data structure based on the numerical order of rows or columns, starting from zero. Out-of-bound indices raise an error, except for slice indices which conform to typical slice semantics.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.infer_objects": {
    "new_func": "infer_column_types",
    "description": "Efforts to enhance data types within object columns through a milder form of type conversion that leaves unaffected those columns that are non-object or cannot be converted. This operation is akin to the rules applied when initially constructing a data structure. Arguments include a boolean indicating whether to replicate non-object or non-convertible columns or series. The function returns the same type as the input.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.insert": {
    "new_func": "embed_column",
    "description": "Embeds a new column into the data structure at a specified index. If the column label already exists within the structure, a ValueError is produced unless duplication is permitted. Accepts the insertion index, column label, column content, and a boolean to allow duplicates.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.interpolate": {
    "new_func": "fill_missing_values",
    "description": "Employs various interpolation techniques to fill in missing or null values within the data. Supports a range of methods including linear spacing, time intervals, index values, and others. Accepts arguments for the interpolation method, axis, maximum number of consecutive nulls to fill, whether to update the data in-place, direction and area of limit, and downcast options. Returns the modified structure or None if updated in-place.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.info": {
    "new_func": "summarize_structure",
    "description": "Outputs a brief summary of the data structure, detailing column types, counts of non-null values, and memory usage. The verbosity, output buffer, column threshold for truncated output, and whether to calculate detailed memory usage can be specified. The summary can be printed to any writable buffer and does not return any value.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.items": {
    "new_func": "column_series_pairs",
    "description": "Produces an iterator yielding pairs consisting of the attribute identifier and its corresponding unidimensional data structure holding the data. Each pair is composed of the attribute's identifier as a label and the data structure containing the data entries for that particular attribute.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.isna": {
    "new_func": "detect_absent_data",
    "description": "Produces a boolean matrix of identical dimensions as the original, where each entry signifies whether the corresponding data point is absent (True) or present (False). Absent data points are typically represented by 'None' or 'NaN', and are flagged as True, whereas all other data points are marked as False.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.isnull": {
    "new_func": "verify_missing_entries",
    "description": "Generates a boolean matrix matching the shape of the original, indicating the presence (False) or absence (True) of data. It serves as a synonym to another method for detecting missing entries. Entries considered as missing are marked as True, while all others are marked as False.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.isin": {
    "new_func": "check_membership",
    "description": "Returns a matrix of boolean values, with each entry indicating whether the corresponding element exists within the provided collection. Accepts various types of collections such as list-like structures, one-dimensional labeled arrays, two-dimensional labeled arrays, or dictionaries with matching attribute names.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.iterrows": {
    "new_func": "row_series_enumerator",
    "description": "Provides an iterator that returns tuples, each containing a row identifier and a unidimensional data structure representing the row's data. For a multi-tiered index, the row identifier is given as a tuple.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.keys": {
    "new_func": "column_identifiers",
    "description": "This method retrieves the axis labels for the dataset, which are typically column names. Returns: An Index object representing the axis labels.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.kurt": {
    "new_func": "column_peakness",
    "description": "This method calculates the peakness of the distribution for the dataset across a specified axis, which is a measure of the tails' heaviness compared to a normal distribution. Parameters: axis ({0 or 'index', 1 or 'columns'}, default 0) - The axis to compute the peakness over. skipna (bool, default True) - Whether to exclude missing values. numeric_only (bool, default False) - Whether to include only numerical data. Returns: A Series or scalar value representing the peakness of each column or the entire dataset.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.kurtosis": {
    "new_func": "distribution_tail_weight",
    "description": "This method computes the degree of peakedness in the data's distribution along a specific axis, according to a reference standard for a normal distribution. Parameters: axis ({0 or 'index', 1 or 'columns'}, default 0) - The axis on which to calculate the peakedness. skipna (bool, default True) - Option to exclude missing values from the calculation. numeric_only (bool, default False) - Restricts the calculation to numeric data only. Returns: Either a Series or a scalar value representing the peakedness.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.join": {
    "new_func": "combine_with_alignment",
    "description": "This method merges the columns of another dataset into the calling dataset, aligning data either on the index or a specified column. Various join types are supported. Parameters: other (DataFrame, Series) - The dataset to join with. on (string or list of strings, optional) - Column(s) or index level name(s) to join on. how (string, {'left', 'right', 'outer', 'inner', 'cross'}) - Specifies the type of merge to perform. lsuffix (string) - Suffix for overlapping column names from the left dataset. rsuffix (string) - Suffix for overlapping column names from the right dataset. sort (bool) - Whether to sort the resulting dataset. validate (string, optional) - Indicates the type of join to validate against. Returns: A DataFrame containing the combined columns from both datasets.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.mean": {
    "new_func": "average_values",
    "description": "Calculates the arithmetic average across a specified axis, optionally excluding null entries and considering only numeric data if specified. Parameters: axis (int, default 0) - Determines if the operation should be row-wise (0) or column-wise (1). skip_na (bool, default True) - Omits any null entries from the calculation. numeric_only (bool, default False) - Restricts the calculation to numeric data types. **kwargs - Additional arguments passed to the function. Returns: A Series or a scalar value representing the average.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.memory_usage": {
    "new_func": "column_memory_footprint",
    "description": "Estimates the amount of space taken up by the data structure, with options to include index memory and to perform a deep introspection for object data types. Parameters: index (bool, default True) - If True, includes the memory footprint of the index. deep (bool, default False) - If True, performs a deeper inspection for actual memory usage. Returns: A Series with index labels corresponding to column names and values representing the memory usage in bytes for each column.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.merge": {
    "new_func": "combine_tables",
    "description": "Combines two data structures in a SQL-style join operation, allowing various types of joins like one-to-one, one-to-many, and many-to-many relationships. Parameters: right - The data structure to join with. how (str, default 'inner') - Defines the type of join. on - The label or list of labels to join on. left_on/right_on - Labels or list of labels to join on in the left/right data structure. left_index/right_index (bool, default False) - Whether to use the index from the left/right data structure as the join keys. sort (bool, default False) - Determines if the join keys should be sorted in the result. suffixes (tuple of str, default ('_x', '_y')) - Suffixes to apply to overlapping column names. copy (bool, default True) - If False, avoids copying data if possible. indicator (bool or str, default False) - If True, adds a column with information about the source of each row. validate (str, optional) - Validates if the merge is of a specified type. Returns: A new data structure resulting from the merge.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.mod": {
    "new_func": "elementwise_remainder",
    "description": "Calculates the remainder of division between the data structure and another element-wise, with an option to replace missing data with a specified value before the operation. Parameters: other - The divisor which can be a scalar, sequence, Series, dict, or another data structure. axis (int or str, default 'columns') - The axis to perform the operation on. level (int or label, optional) - The level in case of a MultiIndex to broadcast across. fill_value (float, optional) - The value to use to fill missing data before the operation. Returns: A new data structure containing the remainders of the element-wise division.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.min": {
    "new_func": "smallest_values",
    "description": "Identifies the smallest entries across the specified axis, with options to ignore null values and focus on numeric data types. Parameters: axis (int, default 0) - The axis over which to find the smallest values. skip_na (bool, default True) - Whether to exclude NA/null values from consideration. numeric_only (bool, default False) - Whether to restrict the operation to numeric data types. **kwargs - Additional arguments for the function. Returns: A Series or scalar representing the minimum values.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.nsmallest": {
    "new_func": "minimal_ordered_subset",
    "description": "Retrieves a specified number of rows with the lowest values in the given columns, preserving the original row order. Additional columns are included but not considered when determining the row order. This method is optimized for performance compared to sorting the entire dataframe and selecting the top rows. Input arguments: number_to_select (int) - The count of rows to fetch; sort_columns (list or str) - The columns to consider when determining row order; tie_policy ({'first', 'last', 'all'}) - Determines which occurrences to return in case of equal values. Return value: A dataframe containing the specified number of rows with the lowest values in the specified columns.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.notnull": {
    "new_func": "validate_existence",
    "description": "Creates a boolean mask indicating the presence of data in each cell. True represents the existence of any value other than NA in the cell, while False indicates the presence of NA. Input arguments: None. Return value: A boolean dataframe mirroring the shape of the original, where each cell represents the existence check for its corresponding value.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.pct_change": {
    "new_func": "relative_variation",
    "description": "Calculates the proportionate difference between the current and a prior element along the specified axis. The default shift is one period, which can be adjusted. To obtain percentage values, these results should be multiplied by 100. Input arguments: shift_periods (int, default 1) - The number of periods to shift for calculation; na_handling_method (deprecated, default None) - Method to handle NA values before calculation; max_na_fill (deprecated, default None) - The maximum count of consecutive NA values to fill; time_frequency (DateOffset, timedelta, or str, optional) - The time frequency increment for time series data; **kwargs - Additional arguments passed to the shift function. Return value: The same type as the input, containing the calculated proportionate differences.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.pad": {
    "new_func": "propagate_last_valid",
    "description": "Fills NA/NaN values by carrying forward the last valid observation. This method has been deprecated and replaced with a more appropriately named function. Input arguments: axis_option (optional) - The axis along which to fill missing values; apply_changes_inplace (bool, default False) - Whether to modify the object in place; max_fill (optional) - The maximum number of consecutive NA values to fill; downcast (optional) - Dict of item->dtype of what to downcast if possible. Return value: Either an updated object with missing values filled or None if changes are applied in place.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.nunique": {
    "new_func": "distinct_value_counter",
    "description": "Counts the number of unique elements along the given axis, optionally excluding NA values from the count. The result is a series indicating the count of unique items. Input arguments: count_axis ({0 or 'index', 1 or 'columns'}, default 0) - The axis along which to count distinct elements; na_omission (bool, default True) - Whether to exclude NA values from the count. Return value: A series containing the count of unique elements along the specified axis.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.nlargest": {
    "new_func": "top_tier_selector",
    "description": "Retrieves a subset of rows with the highest values across specified columns, sorted in descending order by those columns. The output includes all columns from the original dataset, regardless of their ranking relevance. Parameters: n (int) - The number of top rows to retrieve. order_by (label or list of labels) - The column label(s) to sort by. precedence ({'first', 'last', 'all'}) - Determines which duplicates to prioritize: 'first' for earliest occurrences, 'last' for latest occurrences, or 'all' to include every instance, potentially exceeding n rows. Returns: A subset of the original dataset, containing the specified number of rows with the highest values in the designated columns, sorted accordingly.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.pivot": {
    "new_func": "reshaper",
    "description": "Alters the structure of a dataset by organizing it based on unique values from specified indices or columns, generating a new layout. The function creates an alternate view of the dataset without aggregating data; if multiple records exist for a combination of the chosen index and columns, a hierarchical index will be used. Parameters: column_labels (str, object or a list of these) - The column(s) to form the new layout's columns. row_labels (str, object, optional) - The column(s) to form the new layout's index. If not specified, the current index is used. cell_values (str, object, optional) - The column(s) used to populate the new layout's values. Omitting this argument will use all remaining columns. Returns: A restructured dataset based on the given indices and column values.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.pipe": {
    "new_func": "streamline",
    "description": "Facilitates the application of a sequence of transformations to the dataset, which are represented as functions that can process its structure. Parameters: operation (function) - The transformation to apply. *arguments (iterable, optional) - Positional arguments passed to the operation. **keyword_args (mapping, optional) - Keyword arguments passed to the operation. Returns: The result of applying the specified transformation operation to the dataset.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.pivot_table": {
    "new_func": "summary_creator",
    "description": "Generates a summarized table similar to a spreadsheet pivot table, organizing data with hierarchical indexes based on specified keys and aggregation functions. Parameters: data_values (list-like, optional) - The column or columns to summarize. row_keys (column, array, optional) - The grouping keys for the table's index. column_keys (column, array, optional) - The grouping keys for the table's columns. summary_function (function, list of functions, dict) - Function(s) used for aggregation, with 'mean' as the default. value_replacement (scalar, optional) - Value used to substitute missing data after aggregation. include_totals (bool) - If True, adds subtotal rows and columns. exclude_na (bool) - If True, excludes columns with only NaN values before calculating totals. totals_label (str) - The label for the subtotal rows and columns when include_totals is True. show_observed (bool) - Determines whether to show observed values for categorical groupers. order_result (bool) - If True, the resulting table is sorted. Returns: A table that summarizes the data by the specified rows and columns, using the given aggregation function(s).",
    "class": "DataFrame"
  },
  "pandas.DataFrame.plot.area": {
    "new_func": "cumulative_distribution_chart",
    "description": "Creates a visual representation of quantitative data as a cumulative chart, where the area below the line is filled. This visualization is a wrapper around the corresponding matplotlib function. Parameters: coordinate_x (label or position, optional) - The reference for the horizontal axis. Typically, this is the dataset's index. coordinate_y (label or position, optional) - The column(s) to be plotted. By default, all columns are included. layering (bool) - Indicates whether to stack the areas, with the default as True for stacked representation. **additional_args - Further arguments documented in the underlying chart plotting function. Returns: A graphical object representing the area chart, or an array of charts if multiple plots are created.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.plot.hist": {
    "new_func": "dataframe_column_distribution",
    "description": "Creates a graphical representation of the frequency distribution of numerical data by grouping data into bins. This method is helpful when comparing the scale of various series within a data framework. Each bin represents a range of values, and the frequency of occurrence within each bin is graphed, allowing for easy identification of distribution patterns. Parameters: by (optional) - Groups the data by a specified column. bins (default 10) - Determines the number of bins used for the histogram. **kwargs - Additional arguments passed to the plotting method. Returns: An axis subplot object representing the histogram.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.plot.kde": {
    "new_func": "density_curve_generator",
    "description": "Produces a smoothed frequency distribution representation by calculating the estimated probability density function of a dataset. This technique uses Gaussian smoothing to create a continuous curve that represents the data's distribution. Parameters: bw_method (optional) - Defines the method for bandwidth estimation, which affects the smoothness of the resulting curve. ind (optional) - Specifies the evaluation points for the probability density function, either as an array or as a number of equally spaced points. **kwargs - Additional arguments passed to the plotting method. Returns: An axis object or an array of axis objects for the plot.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.plot.box": {
    "new_func": "quartile_range_diagram",
    "description": "Generates a chart that visually conveys the central tendency and variability of a dataset through quartiles. The central box of the chart spans from the first quartile (Q1) to the third quartile (Q3), with a line indicating the median. Whiskers extend from the box to show the full range of the data, with outliers potentially appearing beyond the whiskers. Parameters: by (optional) - A column to group data by before plotting. **kwargs - Additional arguments passed to the plotting method. Returns: An axis object or an array of axis objects for the box plot.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.plot.scatter": {
    "new_func": "bivariate_correlation_display",
    "description": "Crafts a two-dimensional plot where markers represent individual data points. The plot illustrates the relationship between two variables through their Cartesian coordinates. Marker sizes and colors can vary, providing additional layers of information about the data points. Parameters: x - Specifies the column for the horizontal axis. y - Specifies the column for the vertical axis. s (optional) - Determines the size of the markers. c (optional) - Sets the color of the markers, which can also be linked to a data column to create a color gradient based on values. **kwargs - Additional arguments passed to the plotting method. Returns: An axis object or an array of axis objects for the scatter plot.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.plot.pie": {
    "new_func": "circular_value_chart",
    "description": "Illustrates the relative magnitude of parts to a whole by dividing a circle into proportional segments. This visual is particularly useful for displaying the composition of numerical data within a single column. When no specific column is designated, separate pie charts can be generated for each numerical column if desired. Parameters: y (optional) - The label or index of the column to visualize. **kwargs - Additional arguments passed to the plotting method. Returns: An axis object or an array of axis objects for the pie chart, depending on the subplot parameter.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.plot.line": {
    "new_func": "tabular_coordinate_sketch",
    "description": "Renders a graphical representation of data points with continuous lines. The graph can illustrate a single set of values or compare multiple sets by using the columns' values as coordinates. Parameters: x_label (str or int, optional) - Specifies the horizontal axis using a column label or position. Defaults to the data structure's index. y_label (str or int, optional) - Specifies the vertical axis using a column label or position. Defaults to all numerical columns. color_scheme (str, list, or dict, optional) - Determines the line color(s) using a variety of formats such as a color name, hex code, or a dictionary mapping column names to colors. Additional parameters (kwargs) - These are passed directly to the underlying graphing method. Returns: Axes object or an array of such objects - The graph representation, with each column potentially having its own axis when multiple plots are requested.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.pop": {
    "new_func": "extract_and_remove_column",
    "description": "Retrieves and subsequently removes a specified column from the data structure. If the column does not exist, an error is raised. Parameters: column_label (str) - The label of the column to extract. Returns: Series - The data corresponding to the removed column.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.prod": {
    "new_func": "calculate_cumulative_product",
    "description": "Computes the cumulative multiplication of elements along a specified axis, optionally excluding null values and considering only certain data types. Parameters: multiplication_axis (int, {0, 1}) - Determines whether to calculate along rows (0) or columns (1). ignore_null (bool, default true) - If true, ignores any null entries. data_type_restriction (bool, default false) - If true, only numeric data types are factored into the computation. valid_data_minimum (int, default 0) - Sets the minimum number of non-null values required for the operation to yield a non-null result. Additional parameters (kwargs) - These are passed to the function. Returns: Series or a single numerical value - The result of the cumulative product operation.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.product": {
    "new_func": "aggregate_multiplication",
    "description": "Performs an aggregation that multiplies elements along an indicated axis, excising null entries and filtering by data type if specified. Parameters: target_axis (int, {0, 1}) - The axis along which to execute the multiplication. skip_nulls (bool, default true) - If true, null values do not affect the result. include_numerics (bool, default false) - If true, restricts the operation to numeric data types. required_count (int, default 0) - The minimum count of valid data needed to avoid a null result. Additional parameters (kwargs) - These are passed to the aggregation function. Returns: Series or a single number - The product of the elements after aggregation.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.quantile": {
    "new_func": "compute_percentile_values",
    "description": "Calculates the value(s) below which a certain percentage of data in the dataset falls, over a defined axis. Parameters: quantile_index (float or list, default 0.5) - The target percentile(s) to compute, ranging from 0 to 1. quantile_axis ({0, 'rows', 1, 'columns'}, default 0) - Specifies whether the calculation is row-wise (0) or column-wise (1). include_numeric_types (bool, default false) - If true, includes only numeric data types in the calculations. percentile_interpolation (str) - Defines the method for estimating percentiles between two data points. computation_method (str, default 'single') - Determines if percentiles should be calculated per-column ('single') or across all columns ('table'). Returns: Series or DataFrame - If a single percentile is requested, a Series is returned with column names as the index. If multiple percentiles are requested, a DataFrame is returned with the percentiles as the index.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.pow": {
    "new_func": "elementwise_exponentiation",
    "description": "Performs element-by-element exponential calculations between two data structures, optionally substituting a specified value for any missing data. This method supports broadcasting over different axes and applying the operation across a specific MultiIndex level. Parameters: other (scalar, sequence, Series, dict, or similar structure): The right-hand side operand for exponential calculations. axis ({0 or 'index', 1 or 'columns'}): The axis over which to perform the operation. level (int or label, optional): If specified, the operation will be performed across the given MultiIndex level. fill_value (float or None, optional): A value to substitute for any missing data before the operation. Returns: A modified structure with the result of the exponential calculations.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.rank": {
    "new_func": "ordinal_positioning",
    "description": "Assigns a numerical order to each element along an axis, based on its value, with options for handling ties and missing values. The order can be ascending or descending, and the results can be displayed as percentile ranks if desired. Parameters: axis ({0 or 'index', 1 or 'columns'}, default 0): The axis along which to rank. method (str, default 'average'): The method to use for assigning ranks to tied values. numeric_only (bool, default False): If True, only numeric data will be considered for ranking. na_option (str, default 'keep'): Specifies how NaN values should be ranked. ascending (bool, default True): If True, ranks will be assigned in ascending order. pct (bool, default False): If True, ranks will be expressed as percentile ranks. Returns: A structure with ranks assigned to the data.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.reindex": {
    "new_func": "align_indices",
    "description": "Adjusts the structure to conform to a new set of labels, introducing missing values where labels do not match and optionally filling them based on various methods. This can result in a new object unless the indices are unchanged and copying is not requested. Parameters: labels (array-like, optional): New labels to conform to. index (array-like, optional): New labels for the index. columns (array-like, optional): New labels for the columns. axis (int or str, optional): The axis to target for the new labels. method (str, optional): The method used to fill gaps in the reindexed structure. fill_value (scalar, default NaN): The value to use for missing data. limit (int, optional): The maximum number of consecutive elements to fill. tolerance (optional): The maximum distance allowed for matching labels. Returns: A reindexed structure with the new set of labels.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.reindex_like": {
    "new_func": "match_indices",
    "description": "Returns a new object with its indices conformed to those of another reference object, with the option to fill missing values that may arise from the reindexing. If the indices are the same as the current object and copying is not required, a new object may not be generated. Parameters: other: The reference object with the desired indices. method (str, optional): The method used to fill gaps in the reindexed object. copy (bool, default True): Whether to return a new object if the indices are the same. limit (int, optional): The maximum number of consecutive labels to fill for inexact matches. tolerance (optional): The allowed distance between original and new labels for matches. Returns: A new structure matching the indices of the reference object.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.rdiv": {
    "new_func": "elementwise_reciprocal_division",
    "description": "Computes the element-wise inverse division between two data structures, optionally filling missing values in the input with a specified value. The operation allows broadcasting over specified axes and can apply to a certain MultiIndex level. Parameters: other (scalar, sequence, Series, dict, or similar structure): The divisor in the inverse division operation. axis ({0 or 'index', 1 or 'columns'}): The axis along which to perform the division. level (int or label, optional): If specified, the operation will be targeted across the given MultiIndex level. fill_value (float or None, optional): A value to substitute for any missing data before computation. Returns: A new structure with the result of the inverse division operation.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.radd": {
    "new_func": "rightward_augment",
    "description": "Performs an element-wise addition between the provided object and the calling data structure from the right-hand side. It supports an optional value to fill in for missing data. This method is the reverse equivalent of adding the calling data structure to the given object. Parameters: other (scalar, sequence, Series, dict, or data structure) - The value to add. axis ({0 or 'index', 1 or 'columns'}) - The axis to perform the operation on. level (int or label) - The MultiIndex level to broadcast across. fill_value (float or None) - The value to use for replacing missing data. Returns: data structure - The result of the addition.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.query": {
    "new_func": "conditional_retrieve",
    "description": "Evaluates a logical condition to filter the data structure's columns. Allows the use of expressions to perform boolean indexing. Parameters: expr (str) - The expression to evaluate. inplace (bool) - If set to True, modifies the data structure in place. **kwargs - Additional arguments for fine-tuning the evaluation process. Returns: data structure or None - The filtered data structure or None if modified in place.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.rename": {
    "new_func": "alter_labels",
    "description": "Changes the labels of the indices or columns. Accepts a mapping or a function for the transformation. Unchanged labels remain as they are, and additional labels in the mapping do not cause an error. Parameters: mapper (dict-like or function) - The mapping or function for label transformation. index (dict-like or function) - Specifies the mapping for index labels. columns (dict-like or function) - Specifies the mapping for column labels. axis ({0 or 'index', 1 or 'columns'}) - The axis to target. copy (bool) - Determines if the data should be copied. inplace (bool) - If set to True, the operation is done in place. level (int or level name) - For MultiIndex, only renames labels in the specified level. errors ({'ignore', 'raise'}) - Error handling strategy. Returns: data structure or None - The data structure with renamed labels or None if modified in place.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.reset_index": {
    "new_func": "revert_indexing",
    "description": "Restores the index to the default integer index, optionally removing one or more levels in the case of a MultiIndex. Parameters: level (int, str, tuple, or list) - Specifies the levels to remove. drop (bool) - If True, does not insert the index into the data structure's columns. inplace (bool) - If set to True, the operation is done in place. col_level (int or str) - Determines the level where labels are inserted if columns have multiple levels. col_fill (object) - Specifies how other levels are named if columns have multiple levels. allow_duplicates (bool) - Allows creating duplicate column labels. names (int, str, or list) - The new name(s) for the data structure's column containing the index data. Returns: data structure or None - The data structure with the reset index or None if modified in place.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.resample": {
    "new_func": "time_series_regroup",
    "description": "Reorganizes time-series data by a new frequency, changing the temporal resolution. The data structure must have a datetime-like index or a specified datetime-like label or level. Parameters: rule (DateOffset, Timedelta, or str) - The target frequency for conversion. axis ({0 or 'index', 1 or 'columns'}) - The axis for resampling. closed ({'right', 'left'}) - Specifies which side of the interval is closed. label ({'right', 'left'}) - Specifies which edge to label the bucket with. convention ({'start', 'end', 's', 'e'}) - For PeriodIndex, controls whether to use the start or end of the rule. kind ({'timestamp', 'period'}) - Determines the index type of the result. on (str) - For DataFrame, the column to use instead of the index for resampling. level (str or int) - For MultiIndex, the level to use for resampling. origin (Timestamp or str) - The timestamp to adjust the grouping. offset (Timedelta or str) - An offset added to the origin. group_keys (bool) - If True, includes group keys in the result index when using .apply(). Returns: Resampler object - An object for further resampling operations.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.rename_axis": {
    "new_func": "relabel_axis_identifiers",
    "description": "Changes the label of the specified axis for the calling object. This can be used to modify the names of either the row index or the column labels. It accepts a variety of input types for transformation, including scalars, lists, dictionaries, or functions. The operation can be performed in place or a new object can be returned with the updated axis labels. Parameters: mapper (optional) - A scalar, list-like, dict-like or function to set the new names. index, columns (optional) - Specify the new labels for the index or columns respectively. axis (0 or 1) - The axis whose labels you want to change. copy (bool, default None) - If True, also copy the underlying data. inplace (bool, default False) - If True, modify the object in place; otherwise, return a new object with updated labels. Returns: The modified object or None if performed inplace.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.rolling": {
    "new_func": "moving_evaluation",
    "description": "Applies a moving evaluation window over the data and computes aggregate metrics for each window. It can handle fixed and variable-sized windows specified by an integer, time delta, or custom indexer. Adjustments can be made to the minimum number of periods within the window, the weighting of points, and the position of window labels. Parameters: window (int or time-related) - Size or time span of the moving window. min_periods (int, default None) - Minimum number of observations required per window. center (bool, default False) - Whether to center the window labels. win_type (str, default None) - Type of weighting to apply to points. on (str, optional) - Column on which to calculate the moving window. axis (int or str, default 0) - Axis along which to perform the rolling. closed (str, default None) - Specifies which side of the window interval is closed. step (int, default None) - Step value for window evaluation. method (str, default 'single') - Whether to perform the operation per column or for the entire object. Returns: An object that can perform the rolling operation.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.round": {
    "new_func": "decimal_precision_adjustment",
    "description": "Adjusts the numerical precision of the data by rounding each element to a specified number of decimal places. This can be applied uniformly across all columns or variably for each column. Parameters: decimals (int, dict, or Series) - The number of decimal places to round to, either as a uniform integer, a dictionary specifying columns and precision, or a Series with an index matching the columns. Returns: A new object with the rounded values.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.rsub": {
    "new_func": "complementary_difference",
    "description": "Computes the element-wise difference between a specified value and the data, effectively reversing the order of subtraction. It also supports filling in missing values with a specified fill value before the operation. Parameters: other (scalar, sequence, Series, dict, or object) - The value to subtract from. axis (0 or 1) - The axis along which to perform the subtraction. level (int or label) - Level to broadcast across if the object has a MultiIndex. fill_value (float, default None) - Value to fill missing data before computation. Returns: A new object with the result of the subtraction.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.rpow": {
    "new_func": "complementary_exponentiation",
    "description": "Raises a specified value to the power of each element in the data on an element-wise basis, supporting reversed operation of exponentiation. It allows for a fill value to be specified for missing data prior to performing the calculation. Parameters: other (scalar, sequence, Series, dict, or object) - The base value for the exponentiation. axis (0 or 1) - The axis along which to apply the exponentiation. level (int or label) - Level to broadcast across if the object has a MultiIndex. fill_value (float, default None) - Value to fill missing data before computation. Returns: A new object with the result of the exponentiation.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.rtruediv": {
    "new_func": "elementwise_reverse_fraction",
    "description": "Performs element-by-element reciprocal division between a data structure and the calling object, where the calling object's elements are divided by the external data structure's corresponding elements. It also allows for a specified value to be used in place of missing data during the calculation. This operation is the complement of direct division, enabling reverse calculations. Input Arguments: - other (scalar, sequence, Series, dict, or another data frame): The object to divide the calling object by. - axis (0 or 'rows', 1 or 'columns'): Specifies which axis to align the 'other' object with. - level (int or label): Used to broadcast across a certain level for MultiIndex. - fill_value (float or None): Value to replace missing data before the operation. Returns: A new data frame resulting from the division operation.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.sample": {
    "new_func": "select_random_subset",
    "description": "Chooses a specified quantity or fraction of random entries from an object's axis. Utilizing a seed or a random number generation object ensures consistent results. Input Arguments: - n (int, optional): The number of items to return. - frac (float, optional): The fraction of items to return. - replace (bool): Whether to allow repeated sampling of the same entry. - weights (str or array-like): Assigns probabilities to entries for non-uniform sampling. - random_state (int, array-like, BitGenerator, random number generator object): Seed or RNG object for reproducibility. - axis (0, 1, or None): The axis from which to sample. - ignore_index (bool): Assigns a new integer index to the result if True. Returns: A new object containing the randomly selected entries.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.sem": {
    "new_func": "calculate_standard_error",
    "description": "Determines the standard error of the mean across a specified axis, adjusting for bias by default with N-1 normalization. This adjustment can be altered via the degrees of freedom parameter. Input Arguments: - axis (0 for 'rows', 1 for 'columns'): The axis over which to compute. - skipna (bool): Whether to exclude missing values. - ddof (int): The delta degrees of freedom for normalization. - numeric_only (bool): Restricts the calculation to numerical data types. Returns: A new object containing the standard error values.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.set_axis": {
    "new_func": "apply_new_labels",
    "description": "Updates the labels for the specified axis of the data structure with a new set of labels. This can be applied to either the row or column indices. Input Arguments: - labels (list-like or Index): The new labels to apply. - axis (0 for 'rows', 1 for 'columns'): The axis to modify. - copy (bool): Determines whether to copy the underlying data. Returns: A new data structure with updated labels.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.set_flags": {
    "new_func": "update_object_flags",
    "description": "Produces a new object with modified metadata flags. This method allows for the control of certain object behaviors such as enabling the allowance of duplicate labels. Input Arguments: - copy (bool): Indicates if the object should be copied. - allows_duplicate_labels (bool, optional): Sets the permission for duplicate labels in the returned object. Returns: A new object with the updated flags, of the same type as the original.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.set_index": {
    "new_func": "establish_primary_labels",
    "description": "Assigns one or more columns or arrays as the primary labels for the data structure's rows. These labels can either replace the current labels or be added to them. It is possible to either modify the original data structure or return a modified copy. If the integrity check is enabled, duplicate label entries will be verified. Parameters: keys (label/array/list) - A single or a list of column keys and/or arrays to set as new row labels. drop (bool) - Whether to remove the columns used as new row labels. append (bool) - Whether to add the new labels to the existing ones. inplace (bool) - If set to true, the original data structure will be updated; otherwise, a new modified copy will be returned. verify_integrity (bool) - Whether to check for duplicates in the new labels. Returns: Modified data structure or None if 'inplace' is True.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.sort_index": {
    "new_func": "order_labels",
    "description": "Arranges the data structure based on its row or column labels. Depending on the specified axis, the labels are sorted and can be set to either an ascending or descending order. Multiple sorting algorithms are available, and the order can be set on a per-level basis for MultiIndex. Parameters: axis (int or str) - Specifies whether rows (0 or 'index') or columns (1 or 'columns') are sorted. level (int/str/list) - Determines index level(s) to sort by. ascending (bool/list) - Direction of the sort, either ascending (True) or descending (False). inplace (bool) - If true, the original data structure is updated. kind (str) - The sorting algorithm to use. Returns: A sorted copy of the data structure or None if 'inplace' is True.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.shift": {
    "new_func": "move_index",
    "description": "Alters the alignment of the data by a specified number of intervals, optionally adjusting the time frequency. When a frequency is not given, the alignment of the data remains unchanged, and only the labels are moved. Conversely, providing a frequency will adjust the labels according to the given time rule. Parameters: periods (int/Sequence) - The number of intervals to move, positive or negative. freq (DateOffset/timedelta/str) - The time frequency for adjusting the index. axis (int/str) - The axis to move along, either rows (0 or 'index') or columns (1 or 'columns'). fill_value (object) - The value used for introduced missing values. suffix (str) - A string added to the name of the moved columns when periods is a sequence. Returns: A modified copy of the object with shifted labels.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.sparse.density": {
    "new_func": "calculate_fill_ratio",
    "description": "Computes the proportion of non-empty entries to the total number of potential entries in the data structure.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.size": {
    "new_func": "element_count",
    "description": "Provides the total number of entries within the data structure. For a single-dimensional data structure, it returns the count of rows. For a two-dimensional data structure, it multiplies the count of rows by the count of columns.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.shape": {
    "new_func": "dimensions_tuple",
    "description": "Provides a duo of integers indicating the count of rows and columns in a tabular dataset.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.sparse.to_dense": {
    "new_func": "compact_to_expanded",
    "description": "Transforms a tabular structure with compactly represented data into its expanded, regularly stored equivalent. The outcome is a new tabular structure where all elements are explicitly allocated in memory.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.select_dtypes": {
    "new_func": "filter_column_types",
    "description": "Extracts a subset of a tabular dataset including only the columns whose data types match specified inclusion or exclusion criteria. This method requires at least one of the criteria to be defined. It outputs a new dataset with the filtered columns.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.stack": {
    "new_func": "collapse_columns",
    "description": "Transposes specified levels of column hierarchies into index hierarchies, potentially reshaping the dataset into a Series or a dataset with multi-level indices. It can also exclude null entries and sort the new index levels based on preference. The function accepts level, dropna, sort, and future_stack as parameters, and outputs the reshaped dataset or Series.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.squeeze": {
    "new_func": "condense_singular_axes",
    "description": "Compresses datasets with singular dimensional axes into simpler forms. If the dataset has only one element, it returns a single value. If it contains a single row or column, a one-dimensional series is returned. If none of these conditions apply, the original object is returned unchanged. The user can specify an axis to target or allow the method to apply to all applicable axes. Outputs can be a condensed dataset, a one-dimensional series, or a scalar.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.to_dict": {
    "new_func": "convert_to_mapping",
    "description": "Transforms the data structure into a collection of key-value associations. The format of these pairs can be defined using various styles, including nested dictionaries, lists of values, collections of data in a split format, and more. The exact structure of the returned collection is determined by a specified orientation style. Also, a custom mapping type can be specified to determine the type of the returned collection, and whether to include row identifiers can be controlled by a boolean flag.\nParameters: orient (str) - The desired format of the output collection. into (class or instance, default dict) - The type of mapping to return. index (bool, default True) - Whether to include row identifiers in the output.\nReturns: A collection object (dict, list, or mapping) that represents the data structure based on the chosen orientation.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.to_excel": {
    "new_func": "export_to_spreadsheet",
    "description": "Transfers the information contained within to a spreadsheet file format commonly used by a well-known office suite. This method allows for specifying various aspects of the output, such as what sheet to write on, how to represent missing data, and whether to include row and column labels. The function supports writing to different sheets and requires saving changes after all operations. Overwriting a file with the same name will result in the loss of the original content.\nParameters: excel_writer (path-like, file-like, or writer object) - The destination for the output. Various other formatting and option parameters are available to customize the output.\nReturns: None. The data is written directly to the file specified by the excel_writer argument.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.to_feather": {
    "new_func": "serialize_to_feather",
    "description": "Outputs the contained data to a file in a lightweight binary format, which is suitable for efficient storage and quick access. This operation allows additional parameters to be specified, which are passed on to the underlying writing function, enabling control over aspects like compression and chunk sizes.\nParameters: path (str or path-like object) - The file path or object where the data will be saved. **kwargs - Variable keyword arguments to customize the writing process.\nReturns: None. The data is serialized and saved to the specified file.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.to_gbq": {
    "new_func": "upload_to_bigquery",
    "description": "Sends the data structure to a specified table within Google's large-scale data analytics platform. This action has been deprecated in favor of another method in a separate module specifically designed for interactions with the platform. Nevertheless, this method allows for various configurations such as project identification, how to handle existing table scenarios, and credentials for Google API access.\nParameters: destination_table (str) - The target dataset and table name. Additional parameters for project configuration, authentication, and write behavior are also available.\nReturns: None. The data is uploaded to the specified table on the platform.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.to_hdf": {
    "new_func": "archive_to_hierarchical_file",
    "description": "This function archives the dataset into a structured file format designed for storing and organizing complex data. The format allows the encapsulation of a diverse range of data types and structures within a single file. It is capable of handling large volumes of data and supports various data compression mechanisms. The function enables appending to or creating a new file, with support for different storage schemas and querying capabilities.\nParameters: path_or_buf (str or store object) - The file path or store to which the data will be written. key (str) - The identifier for the dataset within the file. Additional parameters for file access mode, compression, data format, and error handling are available.\nReturns: None. The data is written to an HDF5 file as specified.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.to_html": {
    "new_func": "convert_table_to_web_markup",
    "description": "Transforms a tabular data structure into an HTML table representation. This can be helpful for displaying data in web pages or Jupyter notebooks. The method allows selective column output, custom formatting for missing data, and various styling options. It can also generate a string output if no file buffer is provided. Parameters: Various parameters to customize the HTML output such as buffer, column selection, formatting options, CSS classes, etc. Returns: A string containing the HTML representation if no buffer is provided, else writes to the buffer and returns None.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.to_json": {
    "new_func": "serialize_table_to_json",
    "description": "Transforms the contents of a tabular data structure into a JSON formatted string. This serialization can accommodate various orientations for the JSON structure such as records, columns, or split format. It also handles special data types like NaNs and datetimes appropriately. Parameters: Various parameters allowing for customization of the JSON output format, file path, compression, and serialization options. Returns: A JSON-formatted string if no file path is provided, otherwise writes to the file and returns None.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.to_latex": {
    "new_func": "export_table_to_tex",
    "description": "Converts the tabular data structure into a LaTeX tabular, longtable, or nested table format, which can be included in LaTeX documents. The function provides customization for the appearance of the table such as font styles, column formats, and the inclusion of multicolumn and multirow enhancements. Parameters: Various parameters for specifying output buffer, column selection, formatting options, table layout and styling, and LaTeX-specific options. Returns: A LaTeX-formatted string if no buffer is provided, else writes to the buffer and returns None.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.to_markdown": {
    "new_func": "transform_table_to_markdown",
    "description": "Converts the tabular data structure into a Markdown formatted string, suitable for documentation or version-controlled reports. Parameters: An optional buffer to write to, a mode for file writing, and an index flag to denote if row labels should be included. Additional keyword arguments for tabulate formatting can also be provided. Returns: A Markdown-formatted string if no buffer is provided, otherwise writes to the buffer and returns None.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.to_orc": {
    "new_func": "write_table_to_columnar_format",
    "description": "Saves the tabular data structure to a file in the Optimized Row Columnar (ORC) format, which is a type of columnar storage designed to offer efficient data compression and support for complex data types. Parameters: A file path or object to write to, an optional index parameter to include the index in the output, and additional keyword arguments for the underlying ORC engine. Returns: Bytes object if no path is provided, otherwise writes to the path and returns None.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.to_numpy": {
    "new_func": "frame_to_array",
    "description": "Transforms the input data structure into a homogeneous multidimensional array. By default, it chooses the most accommodating data type across all columns. Data coercion and duplication might occur depending on the specified parameters, potentially leading to increased resource consumption. Parameters: dtype - Desired data type for the array, optional. copy - Whether to return a copy of the data or a view, default is False. na_value - Placeholder value for missing entries, with a default that varies based on the data type. Returns: A multidimensional array representing the original data.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.to_parquet": {
    "new_func": "frame_to_compact_file",
    "description": "Saves the data structure to a compressed binary file format designed for efficient data storage. The function enables choosing between different backend libraries and compression methods. Parameters: path - File path or object where the data will be saved, optional. engine - Library used for serialization, 'auto' by default. compression - Compression method to be applied, 'snappy' by default. index - Whether to include index(es) in the output, optional. partition_cols - Column names for dataset partitioning, optional. storage_options - Additional parameters for the storage connection, optional. **kwargs - Extra arguments for the serialization library. Returns: A byte object if no file path is provided, otherwise None.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.to_period": {
    "new_func": "frame_to_time_segment",
    "description": "Alters the time-indexing of the data structure, converting it to use period-based indexing with a specified frequency. Parameters: freq - The target frequency for the period index, optional. axis - The axis to apply the conversion on, default 0. copy - Whether to copy the underlying data, optional. Returns: A modified version of the input with a period-based time index.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.to_pickle": {
    "new_func": "frame_to_serialized_file",
    "description": "Serializes the data structure and saves it to a specified location using binary storage. Parameters: path - The destination for the serialized object. compression - Compression protocol to apply, 'infer' by default. protocol - Pickle protocol version to use, default is 5. storage_options - Additional parameters for the storage connection, optional. Returns: None, the operation is used for its side effect of saving a file.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.to_sql": {
    "new_func": "frame_to_database",
    "description": "Inserts the content of the data structure into a relational database table. Depending on the parameters, it can create a new table, append to an existing one, or replace it. Parameters: name - Name of the target database table. con - Database connection object. schema - Database schema in which to place the table, optional. if_exists - Action to take if the table already exists, 'fail' by default. index - Whether to write the index as a separate column, default True. index_label - Label for the index column(s), optional. chunksize - Number of rows per batch to write, optional. dtype - Data type specification for the columns, optional. method - SQL insertion clause strategy, optional. Returns: The number of rows inserted if a callable is provided to method, otherwise None.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.to_records": {
    "new_func": "frame_to_structured_array",
    "description": "Transforms the tabular structure into a structured array. If required, the row labels can be included as the initial field of the output array. Accepts an option to specify data types for columns and index, either uniformly or per column/index level. Returns a structured array representation of the input data, optionally including row labels.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.transpose": {
    "new_func": "flip_dimensions",
    "description": "Rotates the orientation of the axes, switching the designation of rows and columns. This operation is akin to reflecting the structure over its main diagonal. Parameters include an option for compatibility with other numeric libraries and a boolean to determine if the data should be duplicated post-operation. The result is a reshaped version of the initial data structure.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.to_xml": {
    "new_func": "serialize_to_markup",
    "description": "Transforms the structure into a markup language document. Various customization options are available including inclusion of row labels, custom root and row tags, null value representation, and namespace management. Outputs can be pretty printed and optionally transformed using an XSLT stylesheet. Supports different methods of compression and storage options. The output can be a string or written to a file-like object.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.truediv": {
    "new_func": "elementwise_divide",
    "description": "Performs element-by-element division between the data structure and another, supporting the option to replace missing values with a specified number. This method allows for division with alignment along a particular axis and can broadcast over a specific level in the case of a multi-index. Outputs the resulting structure post-operation.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.truncate": {
    "new_func": "slice_by_index",
    "description": "Reduces the size of the data structure by discarding elements outside the specified index range. Parameters allow selection of a beginning and ending index value, and the axis along which to perform the reduction. The method returns either a copy or a view of the modified data structure, depending on the specified options.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.tz_localize": {
    "new_func": "assign_time_zone",
    "description": "Assigns a specific time zone to the index of a data structure without timezone information, effectively converting it to timezone-aware. If None is passed as the time zone, it will remove existing time zone data while maintaining the local time. Arguments include the time zone specification, the axis to work on, an optional level for a MultiIndex, and flags for how to handle ambiguous or non-existent times due to daylight saving transitions. Returns the same type of object with updated time zone information.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.unstack": {
    "new_func": "pivot_index_level",
    "description": "Transforms one or more levels of a hierarchically-indexed object into column labels, effectively reshaping the data. Missing values resulting from the operation can optionally be filled with a specified value. By default, the last level is pivoted and the resulting column labels are sorted. The output can be either a reshaped DataFrame or Series, depending on the structure of the index.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.update": {
    "new_func": "merge_in_place",
    "description": "Alters the calling object by replacing its values with those from another similar structured object where the indices match, but only where the original data has missing or NA values. This operation is performed in place with no return value. Users can specify whether to overwrite existing data, apply a custom filter for selecting values to be updated, and how to handle errors when overlapping non-NA data is encountered.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.values": {
    "new_func": "extract_raw_data",
    "description": "Retrieves the underlying data of the object as a multidimensional array, stripping away any axis labels. It is recommended to use the alternative method that provides a similar functionality, as this property is maintained for backward compatibility.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.tz_convert": {
    "new_func": "change_time_zone",
    "description": "Modifies a data structure with timezone-aware index or columns to reflect a different time zone. The target time zone, the axis to modify, and an optional level for MultiIndex structures can be specified. Users have the option to create a copy of the data during this conversion. The result is the same type of object with the time zone of the specified axis changed.",
    "class": "DataFrame"
  },
  "pandas.DatetimeIndex": {
    "new_func": "ImmutableTemporalIndices",
    "description": "Creates an immutable array-like structure of date and time objects, internally represented as 64-bit integers. The structure can also encapsulate time zone information and supports boxing to objects that include additional metadata. With version 2.0.0, numeric date and time attributes hold 32-bit integer data types, instead of the previous 64-bit. Input Parameters: data (1-dimensional array-like) - Data for index creation. freq (string or offset object) - Frequency for the index or 'infer' to determine frequency automatically. tz (timezone object or string) - Time zone for the date and time data. normalize (boolean) - Adjusts start/end dates to midnight before generating a range. closed (string) - Specifies if start/end boundary points should be included. ambiguous (various options) - Determines handling of times during Daylight Saving Time transitions. dayfirst (boolean) - Interprets the day as the first value in ambiguous date formats. yearfirst (boolean) - Interprets the year as the first value in ambiguous date formats. dtype (data type) - Specifies the data type, with datetime64[ns] being the only allowed NumPy type. copy (boolean) - Indicates if the data should be copied. name (label) - Designated name for the index. Returns: An immutable array-like structure specialized for datetime data.",
    "class": "DatetimeIndex"
  },
  "pandas.DatetimeIndex.ceil": {
    "new_func": "TemporalIndexCeiling",
    "description": "Adjusts the date and time values upwards to the nearest specified frequency level. Input Parameters: freq (string or Offset) - The frequency to round up to. ambiguous (various options) - Instructions for handling ambiguous times due to Daylight Saving Time transitions. nonexistent (various options) - Instructions for handling times that do not exist in certain time zones due to DST transitions. Returns: An index or series of the same type as the input, with adjusted date and time values.",
    "class": "DatetimeIndex"
  },
  "pandas.DatetimeIndex.date": {
    "new_func": "TemporalIndexToDate",
    "description": "Retrieves an array of date objects, representing the date component of each datetime entry without time and timezone context. Returns: An array of standard date objects.",
    "class": "DatetimeIndex"
  },
  "pandas.DatetimeIndex.day": {
    "new_func": "TemporalIndexDayComponent",
    "description": "Extracts the day component as an integer value from each entry in the datetime index. Returns: An index or array representing the day component of the datetime entries.",
    "class": "DatetimeIndex"
  },
  "pandas.DatetimeIndex.day_name": {
    "new_func": "TemporalIndexWeekdayNames",
    "description": "Provides the names of the weekdays in the given or default locale for the dates in the index. Input Parameters: locale (string) - The locale code that decides the language for the weekday names. Returns: An index or series with names corresponding to the weekdays.",
    "class": "DatetimeIndex"
  },
  "pandas.DatetimeIndex.day_of_year": {
    "new_func": "annual_ordinal_position",
    "description": "Retrieves the position of a date within the context of its respective year, counting from January 1st as the first position. This attribute provides an integer indicating a date's sequential placement in the year. Parameters: None. Returns: Integer or array-like of integers representing the year-based positional value.",
    "class": "DatetimeIndex"
  },
  "pandas.DatetimeIndex.day_of_week": {
    "new_func": "weekday_integer",
    "description": "Yields an integer corresponding to the weekday of each date, where the week begins with Monday indexed as 0 and ends with Sunday indexed as 6. This attribute is accessible for series of datetime objects as well as date indices. Parameters: None. Returns: Integer or array-like of integers ranging from 0 (Monday) to 6 (Sunday) mapping the days of the week.",
    "class": "DatetimeIndex"
  },
  "pandas.DatetimeIndex.dayofweek": {
    "new_func": "week_position",
    "description": "Delivers an integer signifying the weekday for dates, with the week commencing on Monday indexed as 0 through Sunday indexed as 6. This attribute can be utilized on series with datetime objects or directly on date indices. Parameters: None. Returns: Integer or array-like of integers indicating the position of the weekday, where 0 represents Monday and 6 represents Sunday.",
    "class": "DatetimeIndex"
  },
  "pandas.DatetimeIndex.dayofyear": {
    "new_func": "year_progression",
    "description": "Retrieves the sequential day number within the current year, starting from January 1st. The attribute returns an integer indicating the date's position in the annual sequence. Parameters: None. Returns: Integer or array-like of integers denoting the progression of days in the year.",
    "class": "DatetimeIndex"
  },
  "pandas.DatetimeIndex.hour": {
    "new_func": "time_of_day_hours",
    "description": "Obtains the hour component from a datetime, reflecting the time within a day on a 24-hour scale. This attribute returns the hour portion of the datetime object. Parameters: None. Returns: Integer or array-like of integers representing the hour of the day from the datetime.",
    "class": "DatetimeIndex"
  },
  "pandas.DatetimeIndex.freq": {
    "new_func": "temporal_increment",
    "description": "Accessor to retrieve the regularity with which data points occur within the index. It encapsulates the interval that separates consecutive time points in the index.",
    "class": "DatetimeIndex"
  },
  "pandas.DatetimeIndex.freqstr": {
    "new_func": "rhythm_notation",
    "description": "Accessor that provides the interval notation as a textual representation if established, or returns a null value otherwise.",
    "class": "DatetimeIndex"
  },
  "pandas.DatetimeIndex.floor": {
    "new_func": "time_series_minimization",
    "description": "Adjusts the timestamps in the index downwards to the nearest multiple of the specified frequency. Parameters: frequency - The interval to round down to, must be a stable frequency. ambiguity_resolution - Strategy to resolve timestamps that occur during Daylight Saving Time transitions, can be 'infer', a boolean array, 'NaT', or 'raise' (default). nonexistent_time_handling - Method for handling timestamps that do not exist due to DST shifts, options include 'shift_forward', 'shift_backward', 'NaT', timedelta, or 'raise' (default). Returns: An index of the same type, adjusted to the specified frequency floor.",
    "class": "DatetimeIndex"
  },
  "pandas.DatetimeIndex.indexer_between_time": {
    "new_func": "locator_within_time_bounds",
    "description": "Identifies indices of data points occurring within the specified time bounds. Parameters: start_period, end_period - The start and end time boundaries, either as time objects or strings in the appropriate format. boundary_inclusion_start - Boolean indicating whether to include the start time boundary. boundary_inclusion_end - Boolean indicating whether to include the end time boundary. Returns: An array of integer indices.",
    "class": "DatetimeIndex"
  },
  "pandas.DatetimeIndex.is_month_end": {
    "new_func": "terminus_monthly_check",
    "description": "Accessor that signifies if the dates in the index correspond to the final day of their respective months. Returns: A Series or array with boolean values indicating the result of the check.",
    "class": "DatetimeIndex"
  },
  "pandas.DatetimeIndex.is_month_start": {
    "new_func": "commences_month_check",
    "description": "Determines if the dates in the index represent the commencement of their respective months. Resultant values indicate the truthfulness of this condition as a series of boolean flags, one for each date in the index.",
    "class": "DatetimeIndex"
  },
  "pandas.DatetimeIndex.is_quarter_end": {
    "new_func": "terminates_quarter_check",
    "description": "Assesses if the dates fall on the final day of a financial quarter. The output mirrors the input structure and consists of boolean indicators corresponding to each date entry.",
    "class": "DatetimeIndex"
  },
  "pandas.DatetimeIndex.is_year_start": {
    "new_func": "initiates_annum_check",
    "description": "Evaluates whether the dates mark the inaugural day of their respective years. The output is a collection of booleans reflecting the result of this evaluation for each date.",
    "class": "DatetimeIndex"
  },
  "pandas.DatetimeIndex.is_year_end": {
    "new_func": "concludes_annum_check",
    "description": "Checks if the dates correspond to the final day of their respective years. The resulting data maintains the original structure, providing boolean indicators for each of the dates analyzed.",
    "class": "DatetimeIndex"
  },
  "pandas.DatetimeIndex.inferred_freq": {
    "new_func": "deduced_temporal_cadence",
    "description": "Attempts to deduce a character code that represents the regular interval at which the dates occur. If the interval cannot be determined, the function yields 'None'.",
    "class": "DatetimeIndex"
  },
  "pandas.DatetimeIndex.is_leap_year": {
    "new_func": "calendar_extra_day_check",
    "description": "Indicates whether dates in the index occur within a year that contains an additional day for alignment with the solar cycle. These years have one extra day added to the shortest month. The rule for determining such a year involves divisibility by four, except for end-of-century years, which must be divisible by 400 to qualify. Parameters: None. Returns: An array-like object of boolean values indicating the presence of an extra day in the corresponding year of each date.",
    "class": "DatetimeIndex"
  },
  "pandas.DatetimeIndex.is_quarter_start": {
    "new_func": "initial_quarter_day_flag",
    "description": "Signifies if the dates are the initial day of a three-month financial period. This is typically significant for fiscal calculations and alignments. Parameters: None. Returns: An object of the same type as the caller with boolean values, each indicating whether the corresponding date marks the commencement of a financial period.",
    "class": "DatetimeIndex"
  },
  "pandas.DatetimeIndex.indexer_at_time": {
    "new_func": "locate_time_indices",
    "description": "Retrieves the positions within the index that correspond to a specified time of day. This can be used to isolate records at particular daily occurrences. Parameters: 'time' (datetime.time or str) - The time to query, which can be provided as a time object or a string in a recognized format. 'asof' (bool) - Defaults to False; if True, the method uses the 'as of' logic. Returns: An array of integers indicating positions of the matching times.",
    "class": "DatetimeIndex"
  },
  "pandas.DatetimeIndex.minute": {
    "new_func": "time_component_minutes",
    "description": "Retrieves the minute segments from the time portion of the datetime objects. Parameters: None. Returns: An array-like object containing the minute values extracted from each datetime in the index.",
    "class": "DatetimeIndex"
  },
  "pandas.DatetimeIndex.mean": {
    "new_func": "average_datetime",
    "description": "Calculates the central value in the series of dates or times by averaging the values. This can be useful for finding a representative point in time within a range. Parameters: 'skipna' (bool) - Defaults to True, determines whether to exclude or include null date or time elements. 'axis' (int) - Optional, generally defaults to 0, indicating the dimension along which the operation is performed. Returns: A scalar representing the average value, either as a timestamp or timedelta.",
    "class": "DatetimeIndex"
  },
  "pandas.DatetimeIndex.month": {
    "new_func": "monthly_ordinal",
    "description": "Retrieves the ordinal representation of the month from a date-time index, where the first month of the year is denoted by a 1 and the last by a 12. Parameters: None. Returns: Integers - An array-like object of the month numbers corresponding to the date-time index.",
    "class": "DatetimeIndex"
  },
  "pandas.DatetimeIndex.nanosecond": {
    "new_func": "subsecond_timestamp",
    "description": "Accesses the nanosecond component of the time stamps in a date-time index. Parameters: None. Returns: Integers - An array-like object of the nanosecond values corresponding to each time stamp in the date-time index.",
    "class": "DatetimeIndex"
  },
  "pandas.DatetimeIndex.month_name": {
    "new_func": "moniker_of_month",
    "description": "Yields the full names of the months in a date-time index localized to a specified language setting. Parameters: locale (str, optional) - The locale code dictating the language for the month names, defaults to English ('en_US.utf8'). Returns: Object - An array-like object with the localized month names.",
    "class": "DatetimeIndex"
  },
  "pandas.DatetimeIndex.microsecond": {
    "new_func": "fractional_second_bits",
    "description": "Extracts the microsecond part from each time stamp within a date-time index. Parameters: None. Returns: Integers - An array-like object containing the microsecond portions of the time stamps.",
    "class": "DatetimeIndex"
  },
  "pandas.DatetimeIndex.quarter": {
    "new_func": "three_month_period",
    "description": "Retrieves the period of the year, divided into four parts, to which each date in the date-time index belongs. Parameters: None. Returns: Integers - An array-like object indicating the quarter (ranging from 1 to 4) for each date.",
    "class": "DatetimeIndex"
  },
  "pandas.DatetimeIndex.normalize": {
    "new_func": "midnight_adjustment",
    "description": "Transforms the time portion of date-time objects to the start of the day. The resulting output retains the original length and timezone information. Applicable to both Series with date-time type and directly to Date-time Array/Index structures. Output: Identical data structure type as input with the time adjusted to the beginning of the day.",
    "class": "DatetimeIndex"
  },
  "pandas.DatetimeIndex.second": {
    "new_func": "extract_seconds_component",
    "description": "Retrieves the seconds component from the time element of date-time instances as an integer.",
    "class": "DatetimeIndex"
  },
  "pandas.DatetimeIndex.std": {
    "new_func": "temporal_deviation",
    "description": "Calculates the sample deviation in time over a specified axis, with normalization based on N-1 by default, adjustable via the 'ddof' parameter. Excludes null values by default. The operation results in a Timedelta object indicating the variability. Input arguments: axis (optional integer), ddof (integer, default 1), skipna (boolean, default True).",
    "class": "DatetimeIndex"
  },
  "pandas.DatetimeIndex.timetz": {
    "new_func": "time_with_zone_array",
    "description": "Extracts an array of time objects, each including timezone information, from the date-time instances.",
    "class": "DatetimeIndex"
  },
  "pandas.DatetimeIndex.to_frame": {
    "new_func": "index_to_tabular",
    "description": "Converts the Index into a tabular structure with a single column containing the index data. Input arguments: index (boolean, default True), name (object, default to index name). Output: A tabular structure with the original Index data.",
    "class": "DatetimeIndex"
  },
  "pandas.DatetimeIndex.tz": {
    "new_func": "timezone_retriever",
    "description": "Accessor that retrieves the time zone information associated with the datetime elements in the collection. If the elements are time zone naive, the method will return None; otherwise, it returns the relevant time zone information for each element. Input: None. Output: Time zone information object or None.",
    "class": "DatetimeIndex"
  },
  "pandas.DatetimeIndex.time": {
    "new_func": "clock_components_extractor",
    "description": "Accessor that extracts the time components from each datetime element in the collection, yielding an array of time objects that represent the time-only portions. Input: None. Output: Array of time objects.",
    "class": "DatetimeIndex"
  },
  "pandas.DatetimeIndex.round": {
    "new_func": "precision_adjuster",
    "description": "Method that adjusts the precision of datetime elements in the series by rounding to the nearest specified frequency level. It handles ambiguous and non-existent times caused by daylight saving time transitions according to provided parameters. Input: Frequency (string or offset), Ambiguous time handling strategy, Non-existent time handling strategy. Output: Adjusted collection of the same type with modified precision.",
    "class": "DatetimeIndex"
  },
  "pandas.DatetimeIndex.tz_convert": {
    "new_func": "timezone_translator",
    "description": "Method that changes the time zone of time-aware datetime elements in the collection to a specified new time zone. If the new time zone is None, the method converts the collection to Coordinated Universal Time (UTC) and removes the time zone information. Input: New time zone information. Output: Transformed collection or Index. Throws a TypeError if the original collection is time zone naive.",
    "class": "DatetimeIndex"
  },
  "pandas.DatetimeIndex.tz_localize": {
    "new_func": "timezone_awareness_toggle",
    "description": "Method that assigns or removes a time zone to/from time-naive datetime elements in the collection, effectively toggling their time zone awareness. When localizing to a time zone, it handles ambiguous and non-existent times due to daylight saving time according to specified parameters. Input: Time zone information, Ambiguous time handling strategy, Non-existent time handling strategy. Output: Updated collection of the same type with altered time zone information. Throws a TypeError if the original collection is already time zone aware and a new time zone is specified.",
    "class": "DatetimeIndex"
  },
  "pandas.DatetimeIndex.year": {
    "new_func": "annual_extractor",
    "description": "Retrieves the annual component from a given date series instance. This attribute yields the numeric value representing the year in each date element of the series.",
    "class": "DatetimeIndex"
  },
  "pandas.DatetimeIndex.weekday": {
    "new_func": "week_position_identifier",
    "description": "Acquires the position of the week for each date entry in a date series, with the week commencing on Monday (represented by 0) and concluding on Sunday (indicated by 6). The result is an array or similar structure containing integer values that correspond to the weekdays.",
    "class": "DatetimeIndex"
  },
  "pandas.DatetimeTZDtype": {
    "new_func": "timezone_aware_type_constructor",
    "description": "Creates a type for datetime data with timezone information. The created type is in line with the precision specified by the 'unit' parameter and the 'tz' parameter, which denotes the timezone. Note that a specific error is raised if the timezone provided is not recognized.",
    "class": "DatetimeTZDtype"
  },
  "pandas.ExcelFile.book": {
    "new_func": "workbook_accessor",
    "description": "Provides access to the workbook object of the spreadsheet file, allowing for manipulation and retrieval of information contained within the entire workbook.",
    "class": "ExcelFile"
  },
  "pandas.ExcelFile.parse": {
    "new_func": "spreadsheet_decoder",
    "description": "Interprets the specified sheet(s) from a workbook and transforms it into a structured data frame or a dictionary of data frames. This procedure supports a range of parameters that determine how the sheet is read and interpreted, such as the sheet name, headers, use columns, data type conversion, date parsing, and more. The output is a structured representation of the read sheet data.",
    "class": "ExcelFile"
  },
  "pandas.ExcelFile.sheet_names": {
    "new_func": "tab_identifiers",
    "description": "Retrieves a list of tab titles contained within an Excel workbook. This attribute is accessible without loading the entire file into memory, providing a quick overview of the data sections available.",
    "class": "ExcelFile"
  },
  "pandas.ExcelFile": {
    "new_func": "spreadsheet_reader",
    "description": "This class is designed for the interpretation of tabulated data from spreadsheet files into frame structures. It supports multiple file formats for compatibility with various spreadsheet software. The initialization of this class involves specifying the location or buffer of the spreadsheet file, the desired reading mechanism, and additional options for customization. Input Arguments: location_or_buffer: A string specifying the file path, a file-like object, or a workbook object. reading_engine: An optional string specifying the reading library to use. storage_options: A dictionary containing file-specific options for remote storage systems. engine_parameters: A dictionary containing additional keyword arguments for the reading engine. Return Values: An instance of the class, equipped to parse specified spreadsheet files into frame structures.",
    "class": "ExcelFile"
  },
  "pandas.ExcelWriter": {
    "new_func": "spreadsheet_composer",
    "description": "A constructor for creating an interface to write frame structures into spreadsheet files. It supports multiple output formats and allows for detailed formatting options. This class should be utilized within a context manager to ensure proper closure of file resources or explicitly closed using the close method. Input Arguments: file_path: A string or binary I/O object specifying the target file. writing_engine: An optional string to choose the writing library. date_str_format: An optional string for date formatting. datetime_str_format: An optional string for datetime formatting. write_mode: A string indicating the file writing mode, 'write' or 'append'. storage_parameters: A dictionary with additional options suitable for the storage system in use. sheet_existence_handling: A string or dictionary dictating the behavior when writing to an already existing sheet. engine_parameters: A dictionary of keyword arguments to be passed to the writing engine. Return Values: An instance of the class capable of writing frame structures into spreadsheet files with the provided configuration.",
    "class": "ExcelWriter"
  },
  "pandas.Float32Dtype": {
    "new_func": "numeric32bit_type",
    "description": "Defines a data type representing 32-bit floating-point numbers in a specialized format. This format is particularly useful for ensuring consistent precision of numeric data and employs a specific placeholder to represent missing or undefined values.",
    "class": "Float32Dtype"
  },
  "pandas.Flags": {
    "new_func": "attribute_directives",
    "description": "This class encapsulates configuration directives applicable to frame or series structures. One notable directive includes the governance of label uniqueness within the object. Input Arguments: associated_obj: The frame or series structure to which these directives will be applied. label_uniqueness: A boolean indicating whether duplicate labels are permissible. The default allows duplicates, but can be set to disallow them, enforcing label uniqueness. Return Values: An instance of the class with the specified directives set for the associated frame or series structure.",
    "class": "Flags"
  },
  "pandas.Index.dtype": {
    "new_func": "element_type",
    "description": "This property retrieves the data type of the elements within the collection.",
    "class": "Index"
  },
  "pandas.Index.drop_duplicates": {
    "new_func": "prune_repetitions",
    "description": "Produces a new collection by removing repeated elements based on specified criteria. It can preserve the initial or final occurrence of each value or remove all instances of duplicates.\nParameters:\nkeep - Options are 'first', 'last', or False. Determines which duplicates to retain.\nReturns:\nA new collection with duplicates removed.",
    "class": "Index"
  },
  "pandas.Index.duplicated": {
    "new_func": "mark_reiterations",
    "description": "Generates a boolean array indicating the presence of repetitive elements in the collection. Users can choose to mark all duplicates, or exclude the first or last instances.\nParameters:\nkeep - Options include 'first', 'last', or False. Specifies which duplicates to flag.\nReturns:\nA boolean array where true denotes duplicates.",
    "class": "Index"
  },
  "pandas.Index.dropna": {
    "new_func": "omit_nulls",
    "description": "Returns a new collection devoid of any null or missing values. For multi-level collections, it drops an element if any or all levels are null, based on the specified criteria.\nParameters:\nhow - Can be 'any' or 'all', dictating when to drop an element in the presence of null values.\nReturns:\nA new collection without any null elements.",
    "class": "Index"
  },
  "pandas.Index.empty": {
    "new_func": "index_is_void",
    "description": "This property checks if the collection is devoid of elements.",
    "class": "Index"
  },
  "pandas.Index.putmask": {
    "new_func": "apply_mask",
    "description": "Yields a new collection of elements where specified conditionals are imposed. Elements are replaced with a given value based on a boolean array. Suitable for modifying elements conditionally without altering the original structure.\nParameters: mask (array-like) - A boolean array that determines which positions to replace; value (scalar) - The value to use as a replacement where the mask is True.\nReturns: A new collection with the masked values applied.",
    "class": "Index"
  },
  "pandas.Index.nunique": {
    "new_func": "index_distinct_count",
    "description": "Calculates the count of distinct elements, optionally ignoring null entries by default. This method is useful for obtaining a quick summary of the diversity within a collection.\nParameters: drop_null (bool, default True) - Determines whether to exclude null values from the count.\nReturns: int - The total number of unique, non-null elements.",
    "class": "Index"
  },
  "pandas.Index.ravel": {
    "new_func": "flatten_structure",
    "description": "Creates a contiguous flattened array from the given structure. It may return a view depending on the memory layout of the array.\nReturns: A flattened, one-dimensional array representation of the original structure.",
    "class": "Index"
  },
  "pandas.Index.searchsorted": {
    "new_func": "sorted_insert_position",
    "description": "Determines the indices at which certain elements should be inserted to maintain an ordered sequence. It assumes that the sequence is already sorted and provides the position where new elements should be added.\nParameters: target (array-like or scalar) - The elements to locate within the sequence; placement_side ({'left', 'right'}, optional) - Specifies whether to return the first or last possible index for insertion; sorter (1-D array-like, optional) - An array of indices that sort the sequence into ascending order.\nReturns: int or array of ints - The index or indices where the target elements would be inserted.",
    "class": "Index"
  },
  "pandas.Index.repeat": {
    "new_func": "duplicate_elements",
    "description": "Generates a new sequence where each item is replicated a specified number of times. The result is a sequence expanded by the repetition of its elements.\nParameters: replication_factor (int or array of ints) - The number of times to duplicate each element; axis (None) - Should be None; included for compatibility with certain functions.\nReturns: A new sequence with elements duplicated as specified by the replication_factor.",
    "class": "Index"
  },
  "pandas.IndexSlice": {
    "new_func": "MultiLevelSlicer",
    "description": "Creates a construct to facilitate slicing operations across multiple index levels in a data structure. This slicer object enables selection of specific sections within nested index hierarchies with ease.",
    "class": "IndexSlice"
  },
  "pandas.Int16Dtype": {
    "new_func": "ShortIntegerDataType",
    "description": "Defines a data type for storing 16-bit signed integers in a columnar data structure. It designates a specific missing value indicator to represent absence of data instead of the traditional 'not a number' marker.",
    "class": "Int16Dtype"
  },
  "pandas.Int32Dtype": {
    "new_func": "MediumIntegerDataType",
    "description": "Represents a data type for storing 32-bit signed integers in a tabular format. This type assigns a novel non-available value to indicate missing entries, distinguishing it from the conventional 'not a number' placeholder.",
    "class": "Int32Dtype"
  },
  "pandas.Int8Dtype": {
    "new_func": "TinyIntegerDataType",
    "description": "Introduces a data type for managing 8-bit signed integers within a dataset. It utilizes a distinct non-available value for indicating missing data points, providing an alternative to the standard 'not a number' symbol.",
    "class": "Int8Dtype"
  },
  "pandas.Interval": {
    "new_func": "BoundedRange",
    "description": "Defines an immutable entity that represents a bounded range with specific endpoints. The entity is characterized by its left and right bounds, which are orderable scalars, and includes configuration for specifying which sides of the interval are inclusive.",
    "class": "Interval"
  },
  "pandas.Int64Dtype": {
    "new_func": "ExtendedInteger64Type",
    "description": "Defines a data type for 64-bit integer values with a distinct absent value indicator. This type utilizes a specific placeholder to represent missing entries, differing from the conventional null representation.",
    "class": "Int64Dtype"
  },
  "pandas.Interval.closed": {
    "new_func": "IntervalInclusiveness",
    "description": "Denotes which boundaries of an interval are inclusive, with options to specify left, right, both, or neither end as inclusive.",
    "class": "Interval"
  },
  "pandas.Interval.closed_right": {
    "new_func": "RightBoundInclusiveCheck",
    "description": "Evaluates whether the interval includes its right endpoint. The outcome indicates if the right edge is inclusive or exclusive.",
    "class": "Interval"
  },
  "pandas.Interval.closed_left": {
    "new_func": "LeftBoundInclusiveCheck",
    "description": "Assesses whether the interval encompasses its left endpoint. This property confirms the inclusivity of the left boundary.",
    "class": "Interval"
  },
  "pandas.Interval.is_empty": {
    "new_func": "IntervalVoidnessIndicator",
    "description": "Determines the absence of any elements within an interval. The result is either a single boolean value for stand-alone intervals or an array of booleans for an array or index of intervals.",
    "class": "Interval"
  },
  "pandas.Interval.left": {
    "new_func": "bound_start",
    "description": "Obtains the starting boundary value of an interval.",
    "class": "Interval"
  },
  "pandas.Interval.length": {
    "new_func": "span_measure",
    "description": "Calculates the extent between the boundaries of an interval. The result is a scalar value representing the distance.",
    "class": "Interval"
  },
  "pandas.Interval.open_left": {
    "new_func": "is_unsealed_start",
    "description": "Determines if the interval's starting boundary is unsealed. Outputs a boolean value: True indicates an unsealed starting point, whereas False signifies it is sealed.",
    "class": "Interval"
  },
  "pandas.Interval.right": {
    "new_func": "bound_end",
    "description": "Retrieves the terminating boundary value of an interval.",
    "class": "Interval"
  },
  "pandas.IntervalDtype": {
    "new_func": "span_data_type",
    "description": "Defines a data type for intervals, which is not a genuine type of the numpy library but functions similarly. The type of interval boundaries can be specified upon instantiation. Accepts a string or data type for the boundary definition as well as a parameter for the closure type.",
    "class": "IntervalDtype"
  },
  "pandas.IntervalIndex.from_arrays": {
    "new_func": "boundaries_to_intervals",
    "description": "Creates an index of intervals from separate arrays indicating the start and end points. Arguments: start_points (array-like) - Beginning values for intervals. end_points (array-like) - Ending values for intervals. interval_closure (string) - Specifies whether intervals are open or closed at each end. Refer to 'closed' parameter options. index_label (string, optional) - Designation for the resulting index structure. replicate_data (boolean, default False) - Whether to duplicate the input data. data_type (dtype, optional) - Specifies the data type, inferred if not provided. Returns: A new index structure consisting of intervals. Errors: ValueError - Raised if there are inconsistencies between start and end points or if ordering is invalid.",
    "class": "IntervalIndex"
  },
  "pandas.IntervalIndex.contains": {
    "new_func": "interval_enclosure_check",
    "description": "Evaluates on an element-wise basis if the values fall within the defined intervals. Returns an array of booleans indicating the result. Arguments: element (scalar) - The value to test for enclosure within the intervals. Returns: Array of booleans indicating whether the element is enclosed by each interval.",
    "class": "IntervalIndex"
  },
  "pandas.IntervalIndex.is_empty": {
    "new_func": "void_interval_check",
    "description": "Determines if intervals are devoid of any values. Outputs either a single boolean for a scalar interval or an array of booleans for each interval in the structure. Returns: Either a boolean for a single interval or an array of booleans for multiple intervals, indicating their emptiness.",
    "class": "IntervalIndex"
  },
  "pandas.IntervalIndex.get_indexer": {
    "new_func": "index_alignment_locator",
    "description": "Computes the alignment positions for a new index relative to the current one. The resulting array of integers can be used to rearrange data to match the new index. Arguments: new_index (Index) - The index to align with. search_method (string, optional) - Strategy for inexact matching. Refer to 'method' parameter options. max_span (int, optional) - Maximum range for consecutive matches. proximity_limit (optional) - Maximum allowable distance for matches. Returns: Array of integers indicating the positions of alignment, with missing target values indicated by -1.",
    "class": "IntervalIndex"
  },
  "pandas.IntervalIndex.from_breaks": {
    "new_func": "splits_to_interval_index",
    "description": "Constructs an index of intervals using an array representing breakpoints between intervals. Arguments: dividers (array-like) - Specifies the boundaries for the intervals. interval_closure (string) - Indicates whether intervals are open or closed. index_label (string, optional) - Name for the created index. replicate_data (boolean, default False) - Flag to indicate if input data should be copied. data_type (dtype or None, optional) - Determines the data type or infers it. Returns: A newly created interval index.",
    "class": "IntervalIndex"
  },
  "pandas.MultiIndex.dtypes": {
    "new_func": "composite_index_data_types",
    "description": "Retrieves the data types as a Series for the underlying composite index structure.",
    "class": "MultiIndex"
  },
  "pandas.MultiIndex.from_tuples": {
    "new_func": "hierarchical_index_from_sequence",
    "description": "Transforms a sequence of tuple-like objects into a hierarchical index structure. Input arguments include a sequence of tuples, an integer defining the order level of the index, and optionally a list of names for the index levels. The output is a new hierarchical index.",
    "class": "MultiIndex"
  },
  "pandas.MultiIndex.from_product": {
    "new_func": "hierarchical_index_from_cartesian_combination",
    "description": "Generates a hierarchical index from the Cartesian product of multiple input sequences. Accepts iterables for each index level, a sorting order integer, and optional level names. The result is a newly created hierarchical index.",
    "class": "MultiIndex"
  },
  "pandas.MultiIndex.from_arrays": {
    "new_func": "hierarchical_index_from_collection",
    "description": "Creates a hierarchical index from a collection of array-like objects. Each array-like provides values for one level of the resulting index, with the option to specify sorting order and names for the index levels. The function returns a hierarchical index constructed from the provided arrays.",
    "class": "MultiIndex"
  },
  "pandas.MultiIndex.levels": {
    "new_func": "hierarchical_layers",
    "description": "Retrieves the distinct hierarchical layers or categories of a multi-tiered index. This attribute returns a tuple containing unique Index objects for each separate layer, representing the individual dimensions of the multi-tiered index.",
    "class": "MultiIndex"
  },
  "pandas.MultiIndex.levshape": {
    "new_func": "index_dimension_lengths",
    "description": "Returns the dimensions of each hierarchical level as a tuple, indicating how many distinct categories exist within each level.",
    "class": "MultiIndex"
  },
  "pandas.MultiIndex.nlevels": {
    "new_func": "hierarchy_depth",
    "description": "Retrieves the total count of hierarchical tiers present in the index structure.",
    "class": "MultiIndex"
  },
  "pandas.MultiIndex.get_loc": {
    "new_func": "find_label_position",
    "description": "Determines the position of a specified label within the hierarchical index. The output can be an integer, a section of the index, or a mask indicating the location of the label. Parameters: key - A single label or a tuple consisting of one label per hierarchical level. Returns: The position, either as an integer, a slice object, or a boolean mask.",
    "class": "MultiIndex"
  },
  "pandas.MultiIndex.names": {
    "new_func": "level_identifiers",
    "description": "Acquires the identifiers associated with each hierarchical level within the index.",
    "class": "MultiIndex"
  },
  "pandas.MultiIndex.get_locs": {
    "new_func": "find_multiple_positions",
    "description": "Retrieves the positions for a set of labels across multiple levels, returning an array of integers suitable for positional indexing. Parameters: seq - A sequence consisting of labels, slices, lists, masks, or a combination thereof, corresponding to each hierarchical level. Returns: An array of integers indicating the positions of the specified labels.",
    "class": "MultiIndex"
  },
  "pandas.MultiIndex.sortlevel": {
    "new_func": "hierarchical_index_organize",
    "description": "Arranges a hierarchical index at a specified tier. Maintains the initial sequence of the categorical factor at the chosen tier. Accepts a single tier or a list for multi-tier arrangement. Direction can be set to ascend or descend. Additionally, you can control the position of null values in the sorted output. Input: tier (name or list of names/integers), direction (boolean or list for direction), order_remaining (boolean), nulls_order ('first' or 'last'). Output: a tuple containing the restructured index and the array of indices mapping to the original index.",
    "class": "MultiIndex"
  },
  "pandas.MultiIndex.set_levels": {
    "new_func": "hierarchical_index_update_tiers",
    "description": "Updates the tiers of a hierarchical index with new values. By default, generates a new index. Arguments include the new tiers to apply and an optional specification of which tiers to update. Additionally, it checks for compatibility between levels and codes if required. Input: new_tiers (sequence or list of sequence), specified_tier (integer, name, or sequence of either), integrity_check (boolean). Output: an updated hierarchical index.",
    "class": "MultiIndex"
  },
  "pandas.MultiIndex.to_flat_index": {
    "new_func": "hierarchical_index_flatten",
    "description": "Transforms a hierarchical index into a standard index composed of tuples with level values. Output: an index object with the multi-tier data represented in tuple form.",
    "class": "MultiIndex"
  },
  "pandas.MultiIndex.to_frame": {
    "new_func": "hierarchical_index_to_table",
    "description": "Generates a table with the tiers of the hierarchical index as its columns. The order of columns follows the table constructor's rules when data is given as a dictionary. Options include setting the new table's index to match the original hierarchical index, renaming index levels, and allowing/disallowing duplicate column titles. Input: maintain_index (boolean), new_names (list/sequence of strings), permit_duplicates (boolean). Output: a table with index levels as columns.",
    "class": "MultiIndex"
  },
  "pandas.MultiIndex.swaplevel": {
    "new_func": "hierarchical_index_interchange",
    "description": "Exchanges two levels in a hierarchical index without altering the value sequence. Levels to be swapped can be identified by their integer position or name, and the types can be mixed. Input: level_one (integer or string), level_two (integer or string). Output: a new hierarchical index with the specified levels interchanged.",
    "class": "MultiIndex"
  },
  "pandas.MultiIndex.truncate": {
    "new_func": "compress_indices",
    "description": "Cuts the composite index from a specified start to end point and provides a new composite index containing only the relevant subset. This method is useful for extracting a particular range of an index using partial or full labels or tuples. Inputs: before (label or tuple, optional) - Initial label or tuple, with a default setting that initializes from the start. after (label or tuple, optional) - Terminal label or tuple, with a default setting that initializes from the end. Output: A new composite index consisting of the subset within the specified range.",
    "class": "MultiIndex"
  },
  "pandas.Period": {
    "new_func": "time_span",
    "description": "Creates an object representing a span of time, which could range from a fraction of a second to multiple years. This object encapsulates the entire duration, rather than any specific start or end point. Inputs: value (various types, optional) - A representation of the time span, such as a string or a date-time object. freq (string, optional) - A code or object that specifies the duration's granularity. ordinal (integer, optional) - A numerical offset from a standardized epoch. year, month, quarter, day, hour, minute, second (integers, optional) - Specific components of the time span. Outputs: An object that embodies the specified span of time with the given granularity.",
    "class": "Period"
  },
  "pandas.Period.day": {
    "new_func": "monthly_moment",
    "description": "Retrieves the numeric day within a month on which the time span occurs. Output: An integer representing the day of the month.",
    "class": "Period"
  },
  "pandas.Period.day_of_week": {
    "new_func": "weekly_position",
    "description": "Determines the weekday position for the time span, considering the starting point for frequencies less than a day and the ending point for frequencies greater than a day. Output: An integer indicating the weekday, with Monday assigned the value of 0 and Sunday a value of 6.",
    "class": "Period"
  },
  "pandas.Period.asfreq": {
    "new_func": "frequency_conversion",
    "description": "Transforms the time span to a specified granularity, choosing either the commencement or the conclusion of the time span as a reference point. Inputs: freq (string or BaseOffset) - The target granularity code or object. how (string, default 'end') - A specifier for the reference point, either the commencement ('start') or conclusion ('end') of the time span. Output: A new time span object adjusted to the desired granularity.",
    "class": "Period"
  },
  "pandas.Period.day_of_year": {
    "new_func": "annual_sequence_position",
    "description": "This attribute indicates the ordinal number indicating the position of a specific date within a calendar year. The returned integer spans from 1 for January 1st to either 365 or 366, depending on whether the year is a leap year or not. Parameters: None. Returns: int - Ordinal day within the year.",
    "class": "Period"
  },
  "pandas.Period.days_in_month": {
    "new_func": "monthly_capacity",
    "description": "Calculates the quantity of days for the month associated with the given time span. Parameters: None. Returns: int - Total number of days for that month.",
    "class": "Period"
  },
  "pandas.Period.dayofyear": {
    "new_func": "yearly_ordinal",
    "description": "Retrieves the sequential number that represents a date's position throughout the year, ranging from 1 for January 1st to 365 or 366 in the case of a leap year. Parameters: None. Returns: int - The position of the date within the year.",
    "class": "Period"
  },
  "pandas.Period.end_time": {
    "new_func": "terminus_timestamp",
    "description": "Acquires the point in time that denotes the conclusion of the specified interval. Parameters: None. Returns: Timestamp - The exact moment when the interval ends.",
    "class": "Period"
  },
  "pandas.Period.daysinmonth": {
    "new_func": "month_duration",
    "description": "Determines the complete count of days contained within the month corresponding to the particular interval. Parameters: None. Returns: int - The total day count of the month.",
    "class": "Period"
  },
  "pandas.Period.freq": {
    "new_func": "timeframe_unit",
    "description": "Retrieves the temporal resolution unit for a given time-span object. This attribute indicates the granularity of the time-span being represented. Parameters: None. Returns: A string denoting the granularity of the time-span object.",
    "class": "Period"
  },
  "pandas.Period.freqstr": {
    "new_func": "temporal_granularity_notation",
    "description": "Provides a textual characterization of the temporal resolution for a specific time-span object. This method converts the time-span's granularity into its string equivalent. Parameters: None. Returns: String representation of the time-span's temporal resolution.",
    "class": "Period"
  },
  "pandas.Period.dayofweek": {
    "new_func": "period_weekday_index",
    "description": "Determines the index of the weekday for a specified time-span, where the index aligns with standard international convention, beginning with 0 for Monday and ending with 6 for Sunday. The computation of the index is based on the start of the time-span for sub-daily frequencies and the end of the time-span for super-daily frequencies. Parameters: None. Returns: An integer indicating the weekday index.",
    "class": "Period"
  },
  "pandas.Period.minute": {
    "new_func": "hourly_minute_component",
    "description": "Extracts the minute portion from the hour division within a specific time-span. This method yields the minute value as an integer ranging from 0 to 59. Parameters: None. Returns: Minute component as an integer within the standard minute range.",
    "class": "Period"
  },
  "pandas.Period.month": {
    "new_func": "calendar_month_extractor",
    "description": "Identifies the calendar month during which a particular time-span occurs. The method outputs the month as a numeric value, corresponding to the month's position within the year. Parameters: None. Returns: Numeric value representing the month (1 through 12) of the given time-span.",
    "class": "Period"
  },
  "pandas.Period.hour": {
    "new_func": "get_period_day_fraction",
    "description": "Retrieves the hour component from the time span division, indicating the hour within a 24-hour day. The value is presented as an integer ranging from 0 to 23.",
    "class": "Period"
  },
  "pandas.Period.is_leap_year": {
    "new_func": "check_annum_bissextile",
    "description": "Evaluates if the annum within the time span belongs to a bissextile cycle, commonly known as a leap year.",
    "class": "Period"
  },
  "pandas.Period.quarter": {
    "new_func": "extract_trimester",
    "description": "Determines the trimester segment within which the time span resides, returning an integer from 1 to 4.",
    "class": "Period"
  },
  "pandas.Period.to_timestamp": {
    "new_func": "convert_to_point_in_time",
    "description": "Transforms the time span into a precise point on the timeline. The conversion can be tuned by specifying the target cadence and the exact part of the time span to consider, with options indicating commencement or cessation. Inputs: cadence (string or DateOffset, optional) - The desired granularity of time. By default, it is 'D' for week-or-longer spans and 'S' otherwise. aspect (string, default 'S') - The part of the time span to target, with alternatives such as 'S', 'E', or their case-insensitive long forms. Outputs: a discrete moment on the timeline.",
    "class": "Period"
  },
  "pandas.Period.start_time": {
    "new_func": "initial_moment",
    "description": "Acquires the precise initial moment for the time span, returned as a discrete point on the timeline.",
    "class": "Period"
  },
  "pandas.Period.ordinal": {
    "new_func": "sequential_position",
    "description": "Retrieves the position of a time period within a chronologically ordered list, starting from the ordinal number one. This position is determined by the period's relationship to a predefined calendar era.",
    "class": "Period"
  },
  "pandas.Period.weekofyear": {
    "new_func": "annual_week_index",
    "description": "Determines the index of the week within the year that the specified time period falls under. The index is an integer reflecting the week's order in the year.",
    "class": "Period"
  },
  "pandas.Period.qyear": {
    "new_func": "fiscal_annum",
    "description": "Identifies the financial year associated with the given time span, considering the quarter in which the time span starts. The financial year may differ from the calendar year depending on the alignment of fiscal and calendar quarters.",
    "class": "Period"
  },
  "pandas.Period.year": {
    "new_func": "period_annual_cycle",
    "description": "Extracts the calendar year in which the specified time period is located.",
    "class": "Period"
  },
  "pandas.PeriodDtype": {
    "new_func": "time_span_type",
    "description": "Represents a data type specifically designed for time intervals, characterized by a certain frequency. This type is analogous to a typical data type but specifically caters to temporal divisions.",
    "class": "PeriodDtype"
  },
  "pandas.PeriodIndex.asfreq": {
    "new_func": "interval_transform_frequency",
    "description": "This method alters the temporal resolution of the PeriodIndex to a different frequency. It changes each element's span within the PeriodIndex to match the desired frequency, either anchoring them to the start or the end of the respective intervals. Parameters: freq (str) - The target frequency for conversion. how (str) {\u2018E\u2019, \u2018S\u2019} - Determines whether to align the new frequency to the end or start of the period. Returns: PeriodArray - The modified PeriodArray with the adjusted frequency.",
    "class": "PeriodIndex"
  },
  "pandas.PeriodIndex.day": {
    "new_func": "period_day_component",
    "description": "Accesses the day component of each element within the index. This attribute extracts the day number from each period in the collection. Returns: array-like - An array containing the day numbers corresponding to each period.",
    "class": "PeriodIndex"
  },
  "pandas.PeriodIndex.day_of_week": {
    "new_func": "weekday_sequence",
    "description": "Retrieves the index position of the weekdays for the periods, starting with Monday as 0 through Sunday as 6. This attribute is useful for ordinal representation of weekdays within the index. Returns: array-like - An array of integers indicating the day of the week for each period.",
    "class": "PeriodIndex"
  },
  "pandas.PeriodIndex.day_of_year": {
    "new_func": "annual_day_sequence",
    "description": "Provides the sequential day number within the year for each period in the index. This attribute is useful to determine the position of the day within a given year. Returns: array-like - An array of integers with the day of the year for each period.",
    "class": "PeriodIndex"
  },
  "pandas.PeriodIndex.dayofyear": {
    "new_func": "yearly_ordinal_day",
    "description": "Obtains the day's position within the calendar year from each period in the index. It indicates the count of days from the start of the year. Returns: array-like - An array representing the ordinal day number within the year for each period.",
    "class": "PeriodIndex"
  },
  "pandas.PeriodIndex": {
    "new_func": "time_span_series",
    "description": "Constructs an immutable array-like structure preserving time spans, with elements corresponding to specific, regular intervals. These elements are translated into objects that contain additional metadata, such as the interval's frequency. The structure is used for indexing purposes and is foundational for time series data manipulation. Parameters: data - Optional 1-dimensional array of period-like data or an equivalent PeriodArray. copy - Whether to duplicate the provided array. freq - The granularity of the period, either as a string or a corresponding period object. Additional parameters allow the specification of various time components, such as the year, month, quarter, day, hour, minute, and second, with integers, arrays, or Series. These parameters are deprecated and the 'time_span_series.from_fields' method is recommended instead. The 'dtype' argument specifies the data type or an explicit PeriodDtype.",
    "class": "PeriodIndex"
  },
  "pandas.PeriodIndex.days_in_month": {
    "new_func": "period_index_month_length",
    "description": "Yields the count of days for the month within the specified period.",
    "class": "PeriodIndex"
  },
  "pandas.PeriodIndex.from_fields": {
    "new_func": "assemble_from_components",
    "description": "Generates an index based on the individual time components such as year, quarter, month, day, hour, minute, and second, along with the frequency. Each component is provided separately to form a complete time period.",
    "class": "PeriodIndex"
  },
  "pandas.PeriodIndex.from_ordinals": {
    "new_func": "create_from_positions",
    "description": "Creates an index from an array of ordinal positions, with the option to specify a frequency and a name for the index.",
    "class": "PeriodIndex"
  },
  "pandas.PeriodIndex.month": {
    "new_func": "period_component_monthly",
    "description": "Extracts the calendar month component from the data structure, where January corresponds to 1 and December to 12. Input: None. Returns: Integer array - An array of integers representing the month component of each period.",
    "class": "PeriodIndex"
  },
  "pandas.PeriodIndex.is_leap_year": {
    "new_func": "intercalary_annual_check",
    "description": "Determines whether the dates within the structure occur within an intercalary year, commonly known as a leap year. Input: None. Returns: Boolean array - An array of boolean values indicating the leap year status of each period.",
    "class": "PeriodIndex"
  },
  "pandas.PeriodIndex.qyear": {
    "new_func": "fiscal_year_component",
    "description": "Retrieves the fiscal year designation for each period, useful for financial and tax calculations. Input: None. Returns: Integer array - An array of integers indicating the fiscal year for each period.",
    "class": "PeriodIndex"
  },
  "pandas.PeriodIndex.second": {
    "new_func": "period_component_seconds",
    "description": "Obtains the seconds portion of the time from the period data, facilitating precise time-based operations. Input: None. Returns: Integer array - An array of integers representing the seconds component of each period.",
    "class": "PeriodIndex"
  },
  "pandas.PeriodIndex.strftime": {
    "new_func": "format_period_as_string",
    "description": "Transforms the periods into a formatted string array according to a specified pattern, adhering to standard time formatting conventions. Input: date_format (string) - A pattern denoting the desired string format for the output (e.g., '%Y-%m-%d'). Returns: String array - An array of strings containing the periods formatted as per the provided pattern.",
    "class": "PeriodIndex"
  },
  "pandas.PeriodIndex.week": {
    "new_func": "period_ordinal_sequence",
    "description": "Retrieves the sequential number representing the week within the year for each element in the index.",
    "class": "PeriodIndex"
  },
  "pandas.PeriodIndex.weekofyear": {
    "new_func": "period_index_annual_week_sequence",
    "description": "Acquires the sequential number denoting the week's position within its respective year for each element in the index.",
    "class": "PeriodIndex"
  },
  "pandas.PeriodIndex.year": {
    "new_func": "annual_cycle_component",
    "description": "Yields the component representing the calendric full-year cycle for each element within the index.",
    "class": "PeriodIndex"
  },
  "pandas.RangeIndex.step": {
    "new_func": "stride_value",
    "description": "Provides the interval magnitude between consecutive numbers in the range.",
    "class": "RangeIndex"
  },
  "pandas.RangeIndex.start": {
    "new_func": "commencement_point",
    "description": "Returns the initial numeric point of the range sequence.",
    "class": "RangeIndex"
  },
  "pandas.RangeIndex.stop": {
    "new_func": "termination_point",
    "description": "Accesses the final integer value (exclusive) that the index will generate. It signifies the upper boundary of the sequence generated by the index object. Parameters: None. Returns: int - The terminal value of the index sequence.",
    "class": "RangeIndex"
  },
  "pandas.Series.T": {
    "new_func": "mirror_axis",
    "description": "Retrieves the reflection of the data structure across its diagonal axis, which effectively does not alter the original structure as it is one-dimensional. Parameters: None. Returns: The same one-dimensional structure, unmodified.",
    "class": "Series"
  },
  "pandas.RangeIndex.from_range": {
    "new_func": "construct_from_interval",
    "description": "Generates an ordered numerical index given a Python range object. The created index is immutable and represents a sequence of integers. Parameters: data (range) - The range object to convert. name (str, optional) - The name for the index. dtype (data type, optional) - The data type to enforce. Returns: A new ordered numerical index instance.",
    "class": "RangeIndex"
  },
  "pandas.RangeIndex": {
    "new_func": "immutable_sequential_index",
    "description": "Creates an immutable index that is a special case for representing sequential integers efficiently. This object can enhance computation performance and is the default index for data structures when no explicit index is specified. Parameters: start (int, optional) - The starting integer value. stop (int, optional) - The final integer value (exclusive). step (int, optional) - The increment between values in the index. dtype (data type, optional) - The data type for the index, typically an integer type. copy (bool, optional) - Whether to copy the object, usually irrelevant for this index type. name (object, optional) - An optional name for the index. Returns: An immutable sequential numerical index.",
    "class": "RangeIndex"
  },
  "pandas.Series": {
    "new_func": "labeled_array",
    "description": "Constructs a one-dimensional labeled array capable of holding any data type. The labels, which are immutable and unique, are used for indexing and alignment, allowing for operations between differently indexed data. Parameters: data (varied types) - The data to be stored in the array. index (sequence of hashable items, optional) - The sequence of labels for the data. If not provided, a default sequence is created. dtype (data type, optional) - Specifies the desired data type for the array. name (hashable, optional) - An optional identifier for the array. copy (bool, optional) - Indicates whether to copy the data, applicable for array or sequence inputs. Returns: A one-dimensional labeled array with axis labels.",
    "class": "Series"
  },
  "pandas.Series.__array__": {
    "new_func": "series_to_array",
    "description": "This method converts the elements within the calling data structure into an array compatible with a well-known numerical computing library. It typically should not be invoked directly by users, but rather through conversion functions provided by the said library. Parameters: dtype (str or data type, optional) - The data type desired for the resulting array. If omitted, the data type is deduced from the data. copy (bool or None, optional) - This argument is not utilized. Returns: array - An array containing the data structure's elements in the specified data type.",
    "class": "Series"
  },
  "pandas.Series.aggregate": {
    "new_func": "collate_operations",
    "description": "This method consolidates the data by applying one or multiple operations across a given dimension. Parameters: func (callable, str, list, or dict) - The operation or operations to apply. This can be a callable, a string indicating a method name, a list of operations and/or method names, or a dictionary mapping labels to operations or method names. axis ({0 or 'index'}) - This parameter is for compatibility and is not used. *args - Additional positional arguments to pass to the operation(s). **kwargs - Additional keyword arguments to pass to the operation(s). Returns: The result varies based on the input operation(s) and may be a single value, a data structure of the same type with transformed values, or a structure containing the results of multiple operations.",
    "class": "Series"
  },
  "pandas.Series.add_suffix": {
    "new_func": "append_string_to_labels",
    "description": "This method attaches a specified string to the end of each label within the data structure. For a one-dimensional labeled array, it affects the row labels, while for a two-dimensional labeled array, it affects the column labels. Parameters: suffix (str) - The string to concatenate to the end of each label. axis ({0 or 'index', 1 or 'columns', None}, default None) - The dimension along which the suffix should be added; introduced in version 2.0.0. Returns: A new data structure with modified labels.",
    "class": "Series"
  },
  "pandas.Series.add_prefix": {
    "new_func": "prepend_string_to_labels",
    "description": "This method attaches a specified string to the beginning of each label within the data structure. For a one-dimensional labeled array, it affects the row labels, while for a two-dimensional labeled array, it affects the column labels. Parameters: prefix (str) - The string to concatenate to the beginning of each label. axis ({0 or 'index', 1 or 'columns', None}, default None) - The dimension along which the prefix should be added; introduced in version 2.0.0. Returns: A new data structure with modified labels.",
    "class": "Series"
  },
  "pandas.Series.__iter__": {
    "new_func": "iterate_series_elements",
    "description": "This method provides a mechanism to traverse through each element within the data structure. Each element is returned in its respective scalar type, which may include basic Python types or specific types from this library for date and time related objects. Returns: An iterator yielding each element in the data structure.",
    "class": "Series"
  },
  "pandas.Series.array": {
    "new_func": "values_wrapper",
    "description": "Retrieves the underlying data structure for the given one-dimensional data structure. It provides direct access to the actual data representation, be it a specialized extension or a lightweight encapsulation of a native array. This property differs from the one that provides data in a potentially converted form, making it suitable for direct data manipulation without additional transformations.\n\nReturns:\nThe encapsulated data representation.",
    "class": "Series"
  },
  "pandas.Series.asfreq": {
    "new_func": "time_series_reindexer",
    "description": "Transforms a time series to a new specified temporal interval, aligning the data points accordingly. If the original time index is period-based, then the transformation is a one-to-one conversion; otherwise, a new time range is created to match the desired frequency. Data points not present in the original series will be filled with null values unless a filling strategy is specified. This operation is distinct from more complex resampling, which involves data aggregation.\n\nParameters:\nTarget frequency (date offset or string)\nFilling method (optional)\nAlignment option (optional)\nNormalization flag (boolean, optional)\nValue for missing data points (optional)\n\nReturns:\nReindexed series or data structure.",
    "class": "Series"
  },
  "pandas.Series.astype": {
    "new_func": "convert_datatype",
    "description": "Alters the data type of the calling object to the specified new type. A variety of input types can be used, including strings representing data types, as well as more complex mappings for column-wise conversion. A boolean parameter determines whether a new copy is created, and an error-handling parameter dictates the behavior on encountering invalid conversion data.\n\nParameters:\nTarget data type\nCopy flag (optional)\nError handling strategy (optional)\n\nReturns:\nThe transformed object with the new data type.",
    "class": "Series"
  },
  "pandas.Series.asof": {
    "new_func": "last_valid_entry",
    "description": "Fetches the final row without missing values up to the specified point in time. If no such entry exists, a missing value is returned. When the data structure is multi-dimensional, it is possible to specify a subset of columns to consider for determining the presence of missing values.\n\nParameters:\nLookup point (date or sequence of dates)\nSubset of columns for consideration (optional)\n\nReturns:\nA scalar, a one-dimensional data structure, or a multi-dimensional data structure, depending on the input configuration.",
    "class": "Series"
  },
  "pandas.Series.at_time": {
    "new_func": "select_temporal_values",
    "description": "Isolates entries at a specified clock time, such as 9:30 AM. This function is applicable when the index is time-aware, allowing for the selection of values at a particular point within the day.\n\nParameters:\nDesired time for selection (datetime.time or string)\nAxis specification (unused for one-dimensional data structures, defaults to index)\n\nReturns:\nA subset of the original data structure containing only the entries at the specified time.\n\nRaises:\nA specific exception if the index does not support time-based operations.",
    "class": "Series"
  },
  "pandas.Series.at": {
    "new_func": "retrieve_single_element",
    "description": "This property enables access to an individual datum within a one-dimensional array or a two-dimensional tabular structure based on a unique row and column identifier. It is intended for scenarios where only one item is of interest, thereby optimizing retrieval or modification operations. Errors may arise if the specified identifiers do not exist within the structure or if the provided identifiers do not comply with the expected formats.",
    "class": "Series"
  },
  "pandas.Series.autocorr": {
    "new_func": "self_correlation_by_shift",
    "description": "This method calculates the statistical relationship of an array with a version of itself that has been shifted by a specified number of intervals. The calculation is based on the Pearson coefficient, assessing the degree of linear correlation at the defined displacement. Input Arguments: delay (integer, default is 1) - the number of intervals by which the array is offset before the correlation calculation. Return Value: numeric - the calculated Pearson correlation coefficient following the specified shift.",
    "class": "Series"
  },
  "pandas.Series.attrs": {
    "new_func": "dataset_characteristics",
    "description": "This property stores a mapping of key-value pairs that represent global descriptors for the dataset. It should be noted that this feature is in a provisional phase and may undergo changes without prior notice.",
    "class": "Series"
  },
  "pandas.Series.backfill": {
    "new_func": "subsequent_value_imputation",
    "description": "This method replaces all missing entries within an array utilizing the subsequent valid data point. While this operation is scheduled for deprecation, it remains functional, allowing for the propagation of later values backward to fill absences. Output: a copy of the array with replenished values or None if the operation modifies the array in place.",
    "class": "Series"
  },
  "pandas.Series.between": {
    "new_func": "range_membership_indicator",
    "description": "This method generates a vector of logical values indicating whether each entry in an array falls within a specified interval. The output signals 'True' for elements lying within the bounds, with an option to treat boundary values as inclusive or exclusive. Input Parameters: lower_bound (single value or collection) - defines the lower limit of the interval, upper_bound (single value or collection) - sets the upper limit, edge_inclusion (string) - specifies which boundary points are considered part of the interval. Output: a vector with 'True' for elements within the defined range and 'False' otherwise.",
    "class": "Series"
  },
  "pandas.Series.between_time": {
    "new_func": "time_interval_filter",
    "description": "Filters entries based on whether their timestamp falls within a specified interval during the day. It can also retrieve entries outside of this interval by setting the initial time limit after the final time limit. Input arguments include two time points to define the interval and a parameter to determine if the interval bounds are inclusive. The function operates on either the index or columns. The output is a subset of the data within the defined time span. Only data with a time-based index is accepted. Input: start time (time or string), end time (time or string), inclusivity (string, with 'both' as default), and axis (0 or 'index', 1 or 'columns'). Output: A subset of the original data within the time range.",
    "class": "Series"
  },
  "pandas.Series.bool": {
    "new_func": "single_truth_value",
    "description": "Extracts the truth value from a one-element data structure. This method is not recommended for future use and may be removed in later updates. It verifies that the data contains a single true or false value and raises an error for any other number of elements or non-logical data types. The output is the truth value of the single element. Note: This function is deprecated and the suggested alternative is to use the item method.",
    "class": "Series"
  },
  "pandas.Series.case_when": {
    "new_func": "conditional_replacement",
    "description": "Applies specified transformations based on conditional evaluations. Accepts a list of condition-replacement pairs. The conditions should be array-like or callable expressions returning boolean results. When true, the corresponding replacement is applied, which can be a scalar, array-like, or callable returning a scalar or the same data type. The output is the modified data with replacements made. Input: A list of (condition, replacement) tuples. Output: The modified data with applied conditions and replacements.",
    "class": "Series"
  },
  "pandas.Series.bfill": {
    "new_func": "backward_value_propagation",
    "description": "Replaces missing entries with the subsequent non-null value found in the data. The filling can be limited to a certain number of consecutive missing entries and can be restricted to only fill within a certain range of valid values. The method can be performed in-place or return a new modified data structure. Input Arguments: Axis (0 or 'index', 1 or 'columns'), in-place modification flag (boolean), maximum number of consecutive fills (integer), fill area limitation (None, 'inside', 'outside'). Output: The data with missing values filled or None if the operation is done in-place.",
    "class": "Series"
  },
  "pandas.Series.cat.add_categories": {
    "new_func": "enhance_classification",
    "description": "Incorporates additional classes into the classification scheme of the categorical data. The new classes are appended to the end of the existing categories and are not immediately assigned to any data point. The method ensures that the new classes do not duplicate existing ones and are valid as per category definitions. Input: A single new category or a list-like collection of new categories. Output: The categorical data with the new classes added, provided there are no duplications or validation errors.",
    "class": "Series"
  },
  "pandas.Series.cat": {
    "new_func": "categorical_attributes_accessor",
    "description": "Provides access to properties specific to categorical data within a one-dimensional array-like object or a categorical index.",
    "class": "Series"
  },
  "pandas.Series.cat.as_ordered": {
    "new_func": "impose_hierarchy",
    "description": "Modifies the categorical object to reflect a hierarchical order among its elements. The modified object reflects a sequence that has a meaningful sort order. No additional arguments are required. The result is an analogous object with the order property set.",
    "class": "Series"
  },
  "pandas.Series.cat.ordered": {
    "new_func": "hierarchy_status",
    "description": "Indicates if the elements within the categorical object have an established hierarchical sequence.",
    "class": "Series"
  },
  "pandas.Series.cat.codes": {
    "new_func": "category_encodings",
    "description": "Retrieves a one-dimensional array-like object containing the integer codes that represent the actual data points' category membership.",
    "class": "Series"
  },
  "pandas.Series.cat.remove_unused_categories": {
    "new_func": "prune_idle_categories",
    "description": "Eliminates any categories from the categorical object that are not represented in the data. It returns a similar object with these extraneous categories excluded.",
    "class": "Series"
  },
  "pandas.Series.cat.set_categories": {
    "new_func": "reclassify_labels",
    "description": "Alters the existing labels to specified new labels for a categorical series. It allows the inclusion of additional labels or the removal of existing ones, which may cause unrepresented labels or assign null values to some entries respectively. The method can simultaneously add, remove, and reorder labels, making it more efficient than individual label operations. However, it does not perform checks which might lead to unexpected alterations, particularly with different string data types. Parameters: new_labels (Index-like) - The labels in the desired sequence. preserve_order (bool, default False) - Dictates whether the categorical should maintain an order. relabel (bool, default False) - Determines whether the new_labels are a relabeling or reordering of the old labels. Returns: Categorical with reclassified labels. Raises: ValueError - If new_labels do not qualify as valid labels.",
    "class": "Series"
  },
  "pandas.Series.clip": {
    "new_func": "boundary_restrain",
    "description": "Limits the values within a series to a specified range, setting values beyond the range to the nearest boundary. This operation can handle single-value thresholds or perform the thresholding element-wise if an array-like threshold is provided. Parameters: lower_bound (float or array-like, default None) - The minimum boundary value. All entries below this value are adjusted to it. upper_bound (float or array-like, default None) - The maximum boundary value. All entries above this value are adjusted to it. axis_alignment (0 or 'index', 1 or 'columns', None, default None) - Specifies the axis along which to align the series when applying thresholds. modify_original (bool, default False) - If set to True, the operation modifies the series in place. Returns: Modified series with values confined within the specified range, or None if modify_original is True.",
    "class": "Series"
  },
  "pandas.Series.compare": {
    "new_func": "differential_inspection",
    "description": "Scrutinizes and exhibits the discrepancies between two series. It allows for the comparison to be aligned either vertically or horizontally and can optionally retain the shape of the original series or only the differing elements. Parameters: comparison_target (Series) - The series to be compared against. axis_alignment ({0 or 'index', 1 or 'columns'}, default 1) - The axis on which to base the comparison. preserve_dimensions (bool, default False) - When set to true, retains the full structure of the series. include_matches (bool, default False) - If true, keeps identical values in the output. label_names (tuple, default ('self', 'other')) - Assigns names to the series in the output for differentiation. Returns: A series or DataFrame detailing the differences, with the structure dependant on the axis_alignment parameter.",
    "class": "Series"
  },
  "pandas.Series.convert_dtypes": {
    "new_func": "optimal_type_transformation",
    "description": "Transforms columns to the most suitable data types, preferring types that support null values. Various conversions for different data types can be toggled. Parameters: evaluate_objects (bool, default True) - Determines if object data types should be converted to more specific types. string_conversion (bool, default True) - Converts object data types to a string data type when applicable. integer_conversion (bool, default True) - Allows conversion to integer data types if suitable. boolean_conversion (bool, default True) - Converts object data types to a boolean data type when applicable. floating_conversion (bool, default True) - Allows conversion to floating data types, prioritizing integer data types if no precision would be lost. data_type_system ({'numpy_nullable', 'pyarrow'}, default 'numpy_nullable') - The data type system to use for the resulting series. Returns: A copy of the input with converted data types.",
    "class": "Series"
  },
  "pandas.Series.cat.categories": {
    "new_func": "label_inventory",
    "description": "Retrieves or assigns new values to the existing categorical labels, effectively renaming them. The new labels should be unique and their count must match the count of the current labels. Raises: ValueError - If the new labels are not unique or their count does not match the existing labels.",
    "class": "Series"
  },
  "pandas.Series.combine": {
    "new_func": "fusion_with_function",
    "description": "Merges two series or a series with a scalar, using a specified merger function to dictate the output for each paired element. Where an element is absent in one, a predefined placeholder takes its place. Inputs: other (Series or scalar) - The partner for merging. merger (callable) - A function accepting two scalar values and returning a single result. placeholder (scalar, optional) - A substitute for missing elements, with a default that depends on the series data type. Outputs: A new series comprised of merged results.",
    "class": "Series"
  },
  "pandas.Series.copy": {
    "new_func": "replicate_structure",
    "description": "Creates a duplicate of the series, including its index and values. If the replication is deep, the data and index are fully copied, allowing independent modifications without affecting the original. With a shallow replication, only references are copied, meaning changes to the original are mirrored in the duplicate and vice versa. Inputs: replication_depth (bool, default True) - Indicates whether the replication should be deep or shallow. Outputs: A new series or DataFrame, matching the type of the calling object.",
    "class": "Series"
  },
  "pandas.Series.corr": {
    "new_func": "statistical_association",
    "description": "Calculates the statistical association measure between the series and another, ignoring missing data. Alignment is performed before computation if the series lengths differ. Inputs: companion (Series) - The series to compare with. correlation_method (string or callable, default 'pearson') - The algorithm for association calculation, with options including 'pearson', 'kendall', 'spearman', or a custom function. minimum_observations (int, optional) - The minimum number of observations required for a valid result. Outputs: A numerical value representing the association strength.",
    "class": "Series"
  },
  "pandas.Series.count": {
    "new_func": "non_missing_tally",
    "description": "Calculates the quantity of entries in the series that are not null or NA. Outputs: An integer representing the count of non-missing entries.",
    "class": "Series"
  },
  "pandas.Series.cov": {
    "new_func": "mutual_variance",
    "description": "Determines the mutual variance measure between the series and another, disregarding missing data. Prior to computation, differing lengths of series are aligned. Inputs: counterpart (Series) - The series to compare against. minimum_observations (int, optional) - The lowest number of observations needed for a valid outcome. degrees_of_freedom (int, default 1) - The adjustment to the divisor in the calculation, with the total number of elements reduced by this value. Outputs: A numerical value indicating the normalized mutual variance.",
    "class": "Series"
  },
  "pandas.Series.drop_duplicates": {
    "new_func": "Series_unique_filter",
    "description": "This method returns a modified version of the data with redundant entries eliminated. It allows specifying which occurrences to retain when an item appears more than once. Additionally, it can modify the current data structure directly or return a new one, with an option to recalibrate the index values to a consecutive range starting from zero. Parameters: keep (str or bool) - Strategy for retaining unique values. inplace (bool) - If set to true, the original data will be changed instead of creating a new one. ignore_index (bool) - If true, the index is reset to a continuous range. Returns: A new data structure with only the selected unique values, or None if the operation was applied in place.",
    "class": "Series"
  },
  "pandas.Series.dt.as_unit": {
    "new_func": "Series_datetime_unit_conversion",
    "description": "Alters the temporal resolution of datetime values within a data structure to a specified frequency. It adjusts the precision of time-related information according to the provided arguments. Returns: The data structure with its datetime values converted to the desired temporal resolution.",
    "class": "Series"
  },
  "pandas.Series.dt": {
    "new_func": "Series_datetime_properties",
    "description": "Provides an interface to access special attributes and methods applicable to date and time values within the data structure. This accessor facilitates the extraction and manipulation of temporal data. Returns: An object that acts as a gateway to datetime-specific operations.",
    "class": "Series"
  },
  "pandas.Series.dt.ceil": {
    "new_func": "Series_datetime_ceil_adjustment",
    "description": "Executes a ceiling operation on temporal data points, rounding up to the nearest defined frequency. This method deals with time series data by aligning it upwards to the specified cycle. Parameters: freq (str or Offset) - The temporal frequency to round up to. ambiguous (Union[str, array, 'NaT']) - Defines how to handle ambiguous times during daylight saving time transitions. nonexistent (Union[str, timedelta]) - Specifies how to adjust or label times that do not exist in certain time zones due to daylight saving time shifts. Returns: An index or series with adjusted datetime values. Raises: ValueError if the frequency is not recognized.",
    "class": "Series"
  },
  "pandas.Series.dropna": {
    "new_func": "Series_missing_value_omit",
    "description": "Generates a new data sequence absent of any missing or NA values. It can also perform this modification directly on the existing data. An additional option allows reindexing after the removal process. Parameters: axis (int or str) - An unused parameter, present for compatibility with a related data structure method. inplace (bool) - Determines if the operation should replace the current data. ignore_index (bool) - If enabled, the index is reset to a sequential range starting from zero. Returns: A modified data sequence free from NA values, or None if the operation was performed in place.",
    "class": "Series"
  },
  "pandas.Series.dt.day": {
    "new_func": "datetime_element_extraction",
    "description": "Extracts the day component from each datetime object in the series, yielding the numerical day of the month for each entry. Parameters: None. Returns: A series or index with integer values representing the day of the month for each timestamp.",
    "class": "Series"
  },
  "pandas.Series.dt.date": {
    "new_func": "series_extract_calendar_date",
    "description": "Retrieves the calendar date from each datetime entry, excluding any time or timezone components, and returns an array of date objects. Parameters: None. Returns: An array consisting of date objects corresponding to the date component of each timestamp within the series.",
    "class": "Series"
  },
  "pandas.Series.dt.day_of_week": {
    "new_func": "series_weekday_indexer",
    "description": "Determines the position of the week that each datetime falls into, starting with Monday as the first day (index 0) and ending with Sunday (index 6). Parameters: None. Returns: A series or index containing integer values, each denoting the index of the weekday for the corresponding datetime.",
    "class": "Series"
  },
  "pandas.Series.dt.day_of_year": {
    "new_func": "annual_day_number",
    "description": "Calculates the position of each date in the series within the annual calendar, returning the day count starting from January 1st as day 1. Parameters: None. Returns: A series or index with integer values representing the sequential day number in the year for each date.",
    "class": "Series"
  },
  "pandas.Series.dt.components": {
    "new_func": "timestamp_decomposition",
    "description": "Breaks down each datetime entry into its constituent parts, such as year, month, day, hour, etc., and presents this information in a tabular format. Parameters: None. Returns: A dataframe where each row corresponds to a datetime entry and each column represents a specific component of the datetime.",
    "class": "Series"
  },
  "pandas.Series.dt.dayofyear": {
    "new_func": "ordinal_day",
    "description": "Extracts the sequential day number of the year from a datetime sequence. This attribute reflects the position of the date within the calendar year, from 1 (January 1st) to 365 or 366 (December 31st, depending on leap years). Input: Series or DatetimeIndex with datetime data. Output: Series or Index with integer values representing the ordinal day of the year.",
    "class": "Series"
  },
  "pandas.Series.dt.dayofweek": {
    "new_func": "series_weekday_index",
    "description": "Retrieves the index of the weekday from a datetime sequence where the week starts with Monday as 0 and concludes with Sunday as 6. Input: Series or DatetimeIndex with datetime data. Output: Series or Index with integer values where each number corresponds to a weekday, ranging from 0 (Monday) to 6 (Sunday).",
    "class": "Series"
  },
  "pandas.Series.dt.day_name": {
    "new_func": "series_weekday_label",
    "description": "Provides the name of the weekday from a datetime sequence in a specified language. Parameter: 'locale' (optional, string) - A locale code that determines the language of the returned day names, with the default being 'en_US.utf8'. Input: Series or DatetimeIndex with datetime data. Output: Series or Index containing the names of the weekdays, influenced by the chosen locale setting.",
    "class": "Series"
  },
  "pandas.Series.dt.days_in_month": {
    "new_func": "series_month_length",
    "description": "Calculates the total count of days in the corresponding month for each date in the datetime sequence. Input: Series or DatetimeIndex with datetime data. Output: Series or Index with integer values indicating the number of days in each respective month.",
    "class": "Series"
  },
  "pandas.Series.dt.days": {
    "new_func": "duration_in_days",
    "description": "Determines the span measured in days for each element of a timedelta sequence. Input: Series or TimedeltaIndex. Output: Series or Index with numerical values representing the duration in whole days.",
    "class": "Series"
  },
  "pandas.Series.dt.daysinmonth": {
    "new_func": "monthly_day_count",
    "description": "Retrieves the count of days in the corresponding month for each date in the series. Input: None. Return: An integer representing the day count for the month of each date.",
    "class": "Series"
  },
  "pandas.Series.dt.end_time": {
    "new_func": "period_terminus",
    "description": "Acquires the concluding timestamp of the time period for each datetime instance in the series. Input: None. Return: Timestamp indicating the end of the period for each datetime instance.",
    "class": "Series"
  },
  "pandas.Series.dt.freq": {
    "new_func": "temporal_interval",
    "description": "Obtains the granularity of the time series, specifying the interval at which data points occur. Input: None. Return: A string or DateOffset object that describes the frequency of the datetime instances.",
    "class": "Series"
  },
  "pandas.Series.dt.hour": {
    "new_func": "hour_of_day",
    "description": "Extracts the hour component from each datetime element, representing it as an integer. Input: None. Return: An integer array where each element denotes the hour part from the corresponding datetime value.",
    "class": "Series"
  },
  "pandas.Series.dt.floor": {
    "new_func": "truncate_to_frequency",
    "description": "Applies a downward rounding operation on datetime data, aligning it to the nearest specified frequency level. Parameters: freq - The frequency string or DateOffset to round down to. ambiguous - Strategy to handle ambiguous times during Daylight Saving Time transitions. nonexistent - Strategy to deal with times that do not exist due to DST shifts or other reasons. Returns: A similar index class or Series, with datetime values rounded down to the nearest specified frequency. Raises: ValueError if the frequency cannot be accommodated.",
    "class": "Series"
  },
  "pandas.Series.dt.is_leap_year": {
    "new_func": "series_calendar_extra_day_check",
    "description": "Determines if each date in a series occurs within a year that contains an additional day, specifically the 29th of February. Such years are typically every fourth year, with an exception for centennial years not divisible by 400. Input: Series with datetime-like values. Output: A Series or array of boolean values indicating the presence of an extra day in the year for each date.",
    "class": "Series"
  },
  "pandas.Series.dt.is_month_end": {
    "new_func": "terminal_day_indicator",
    "description": "Evaluates whether each date in a series corresponds to the final day of its respective month. Input: Series with datetime-like values. Output: A Series or array with boolean values, with each element signifying whether its corresponding date is the last of the month.",
    "class": "Series"
  },
  "pandas.Series.dt.is_year_start": {
    "new_func": "commencement_day_of_year",
    "description": "Assesses if each date in a series coincides with the initial day of the year. Input: Series with datetime-like values. Output: A Series or DatetimeIndex, depending on the input type, filled with boolean values denoting if the dates are the first day of their respective years.",
    "class": "Series"
  },
  "pandas.Series.dt.is_month_start": {
    "new_func": "inauguration_day_of_month",
    "description": "Determines if each date in a series is the inaugural day of its corresponding month. Input: Series with datetime-like values. Output: A Series or array containing boolean values, each indicating whether its corresponding date marks the start of a month.",
    "class": "Series"
  },
  "pandas.Series.dt.is_quarter_end": {
    "new_func": "culmination_day_of_quarter",
    "description": "Checks whether each date in a series aligns with the concluding day of a quarter of the year. Input: Series with datetime-like values. Output: A Series or DatetimeIndex, based on the input type, populated with boolean values reflecting whether the dates are the final days of their respective quarters.",
    "class": "Series"
  },
  "pandas.Series.dt.is_quarter_start": {
    "new_func": "initial_quarter_day_check",
    "description": "Determines if the given dates correspond to the commencement day of any quarter in a year, returning a series of truth values. Input: data (Series or DatetimeIndex) - The set of timestamps to evaluate. Output: Boolean series or index - An object of the same type as the input, filled with True for dates that are quarter starting points, otherwise False. The series retains the original name and index structure.",
    "class": "Series"
  },
  "pandas.Series.dt.is_year_end": {
    "new_func": "final_annual_day_mark",
    "description": "Evaluates whether each date in the series or index signifies the terminal day of the calendar year. Input: data (Series or DatetimeIndex) - The collection of dates for inspection. Output: Boolean series or index - A structure analogous to the input, populated with True for dates that mark the year's conclusion, and False otherwise. Maintains the original naming and indexing.",
    "class": "Series"
  },
  "pandas.Series.dt.isocalendar": {
    "new_func": "iso_week_calendar",
    "description": "Converts dates into their corresponding ISO 8601 standard week-based calendar components. Input: None. Output: DataFrame - A table with three columns: 'iso_year', 'iso_week', and 'iso_weekday' representing the year, week number, and day of the week, respectively, as per the ISO standard.",
    "class": "Series"
  },
  "pandas.Series.dt.microsecond": {
    "new_func": "subsecond_component",
    "description": "Extracts the sub-second time portion from each timestamp, specifically the microsecond fraction. Input: None. Output: Series - A series where each value represents the microsecond part of the corresponding timestamp.",
    "class": "Series"
  },
  "pandas.Series.dt.month": {
    "new_func": "month_of_year",
    "description": "Retrieves the ordinal number of the month from each timestamp, where January is denoted as 1 and December as 12. Input: None. Output: Series - A series containing the month numbers for each date in the original series.",
    "class": "Series"
  },
  "pandas.Series.dt.normalize": {
    "new_func": "series_reset_to_midnight",
    "description": "Transforms the time components of date-time objects to the start of the day. It essentially sets the hour, minute, and second to zero without changing the date or timezone. This operation maintains the original length and structure of the data. Suitable for scenarios where the specific time of day is irrelevant. Returns the same type of object as input with identical name and index for Series or name for DatetimeArray/Index.",
    "class": "Series"
  },
  "pandas.Series.dt.quarter": {
    "new_func": "periodic_quadrant",
    "description": "Retrieves the fiscal quarter of the year from date-time data as an integer value ranging from 1 to 4.",
    "class": "Series"
  },
  "pandas.Series.dt.qyear": {
    "new_func": "year_of_quarter",
    "description": "Obtains the year in which the quarter of each date-time value falls. The output reflects the year portion corresponding to the quarter of the date.",
    "class": "Series"
  },
  "pandas.Series.dt.seconds": {
    "new_func": "daytime_seconds",
    "description": "Calculates the number of seconds that have elapsed since the last midnight for each time instance, yielding an integer between 0 and 86400 exclusive.",
    "class": "Series"
  },
  "pandas.Series.dt.strftime": {
    "new_func": "format_datetime_strings",
    "description": "Generates an array of strings from date-time values formatted according to a specified pattern. The pattern complies with the conventions used in the Python standard library. The method returns an array where each element is a text representation of the date-time object, formatted in accordance with the provided pattern. Input: date_format (str) - A string representing the desired date format (e.g., '%Y-%m-%d'). Output: An array of string objects with the formatted date representations.",
    "class": "Series"
  },
  "pandas.Series.dt.time": {
    "new_func": "temporal_components_extract",
    "description": "Extracts the temporal portions from datetime objects within a series, providing an array of time components without any date information.",
    "class": "Series"
  },
  "pandas.Series.dt.second": {
    "new_func": "extract_partial_seconds",
    "description": "Retrieves the second units from the time component of datetime objects within a series.",
    "class": "Series"
  },
  "pandas.Series.dt.round": {
    "new_func": "timeframe_adjustment",
    "description": "Adjusts the datetime objects within a series to the nearest specified frequency level. This method is applied to a series with a datetime-like index, rounding the times according to a specified frequency. Input Parameters: freq - The frequency level to adjust the index to. ambiguous - Strategy for handling ambiguous times during daylight saving time transitions. nonexistent - Strategy for handling times that do not exist in a particular timezone due to daylight saving time transitions. Returns: A series or index of the same type with adjusted times.",
    "class": "Series"
  },
  "pandas.Series.dt.to_period": {
    "new_func": "convert_to_time_period",
    "description": "Transforms datetime objects within a series into period representations at a specified frequency. Parameters: freq - The target frequency for the period conversion. Returns: An array or index of period objects. If the conversion is not possible due to irregular values, a ValueError is raised.",
    "class": "Series"
  },
  "pandas.Series.dt.timetz": {
    "new_func": "timezone_aware_time_extract",
    "description": "Retrieves an array of timezone-aware time components from datetime objects within a series, excluding any date-related information.",
    "class": "Series"
  },
  "pandas.Series.dt.unit": {
    "new_func": "time_granularity",
    "description": "Retrieves the temporal resolution of the datetime data in a Series object. It provides the specific detail level at which time is recorded, such as seconds, minutes, or hours.",
    "class": "Series"
  },
  "pandas.Series.dt.tz_localize": {
    "new_func": "series_assign_time_zone",
    "description": "Adjusts a Series without time zone information to include the specified time zone details without altering the original times. This function can also remove time zone information, effectively making the Series time zone unaware by setting the time zone to None. Input parameters include the desired time zone and instructions on how to handle ambiguous or non-existent times due to daylight saving transitions. The output is of the same type with the time zone either assigned or removed based on the input.",
    "class": "Series"
  },
  "pandas.Series.dt.tz_convert": {
    "new_func": "shift_time_zone",
    "description": "Transforms the times in a Series from one time zone to another specified time zone. If the input is time zone unaware, the function will default to Coordinated Universal Time (UTC) and remove the time zone information. The result is an array or index with the times adjusted to the new time zone. An error is raised if the original Series does not already have time zone information.",
    "class": "Series"
  },
  "pandas.Series.dt.weekday": {
    "new_func": "week_day_number",
    "description": "Returns an array or index representing the days of the week derived from a datetime Series or DatetimeIndex. The days are numbered starting with Monday as 0 through to Sunday as 6.",
    "class": "Series"
  },
  "pandas.Series.dt.year": {
    "new_func": "series_annual_cycle",
    "description": "Extracts the calendar year from each date entry in the Series or DatetimeIndex, returning an array or index of these year values.",
    "class": "Series"
  },
  "pandas.Series.dtypes": {
    "new_func": "data_kinds",
    "description": "Retrieves the data type of the elements within the collection. This attribute provides information on the type of data each element in the collection holds.",
    "class": "Series"
  },
  "pandas.Series.empty": {
    "new_func": "series_is_void",
    "description": "A property to determine if a data structure has any elements. The result is a Boolean value, with a positive outcome indicating a completely void data structure.",
    "class": "Series"
  },
  "pandas.Series.dtype": {
    "new_func": "singular_data_kind",
    "description": "Retrieves the data type of the single-dimensional array. This attribute indicates the type of data that the array contains.",
    "class": "Series"
  },
  "pandas.Series.eq": {
    "new_func": "is_equal_to",
    "description": "Compares the elements of a series with another series or a scalar value on an element-by-element basis. The function allows substituting a specified value for any missing elements before the comparison. The result is a new series indicating the equality outcomes.\n\nInput Arguments:\n- other (Series or scalar): The series or value to compare against.\n- level (int or name, optional): Level for broadcasting across a MultiIndex.\n- fill_value (scalar, optional): The value to use for filling missing entries before the comparison.\n- axis (int, optional): Axis for the function to be applied on.\n\nReturns:\n- Series: A series indicating True where elements are equal and False where they are not.",
    "class": "Series"
  },
  "pandas.Series.duplicated": {
    "new_func": "repeated_instances",
    "description": "Flags each element in the series as True if it is a repetition of an element that has occurred earlier in the series. The method allows for different strategies in marking repetitions, by either preserving the first occurrence, the last occurrence, or marking all instances of a duplicated element.\n\nParameters:\n- keep (str or bool, default 'first'): Strategy to apply when marking duplicates.\n\nReturns:\n- Series of bool: A series where each True represents a duplicate occurrence according to the specified strategy.",
    "class": "Series"
  },
  "pandas.Series.ewm": {
    "new_func": "series_exponential_weight",
    "description": "Calculates exponentially decaying weights for elements to emphasize more recent observations. Offers customization for the decay rate through various parameters. One and only one decay specifier (center of mass, span, halflife, or direct smoothing factor) must be chosen unless a specific time series is provided. It also supports handling of missing data and adjustment factors for the weighting calculation. The result is an object that can perform multiple calculations with this weighting scheme.\nParameters: com (float, optional), span (float, optional), halflife (float, str, timedelta, optional), alpha (float, optional), min_periods (int, default 0), adjust (bool, default True), ignore_na (bool, default False), axis ({0, 1}, default 0), times (array-like, default None), method (str {'single', 'table'}, default 'single').\nReturns: ExponentialMovingWindow object.",
    "class": "Series"
  },
  "pandas.Series.filter": {
    "new_func": "series_subset_selector",
    "description": "Selects a subset of the data structure based on specified index labels. It can select based on direct matches, partial string matches, or regular expression pattern matches. It does not consider the data content but only the index labels.\nParameters: items (list-like), like (string), regex (string), axis ({0 or 'index', 1 or 'columns', None}, default None).\nReturns: Object of the same type as the input.",
    "class": "Series"
  },
  "pandas.Series.ffill": {
    "new_func": "series_forward_fill",
    "description": "Replaces missing values by carrying forward the last observed non-null value. Can be limited to a certain number of replacements or to certain areas based on the positioning of valid values. Offers in-place modification if desired.\nParameters: axis ({0 or 'index'}), inplace (bool, default False), limit (int, default None), limit_area ({None, 'inside', 'outside'}, default None), downcast (dict, deprecated).\nReturns: Object with missing values filled, or None if inplace is True.",
    "class": "Series"
  },
  "pandas.Series.first": {
    "new_func": "series_initial_period",
    "description": "Retrieves the initial segment of a time series as specified by a date offset. This function is deprecated and will be removed in future versions, with the recommendation to use indexing methods instead.\nParameters: offset (str, DateOffset, or dateutil.relativedelta).\nReturns: Subset of the original object.",
    "class": "Series"
  },
  "pandas.Series.ge": {
    "new_func": "series_at_least",
    "description": "Compares elements to another array-like or scalar, determining if they are greater than or equal to the counterpart. It permits substitution of a specific value for missing data before the comparison.\nParameters: other (Series or scalar value), level (int or name, optional), fill_value (None or float value, default None), axis ({0 or 'index'}, unused).\nReturns: Series indicating the comparison results.",
    "class": "Series"
  },
  "pandas.Series.first_valid_index": {
    "new_func": "initial_non_missing_locator",
    "description": "Identifies the position of the first occurrence where a value is present and not null. If all entries are null, it returns None. This can be particularly useful for quickly finding the first available data point in a dataset with missing entries.\nReturns: index type - The index of the first non-null value.",
    "class": "Series"
  },
  "pandas.Series.flags": {
    "new_func": "attributes_accessor",
    "description": "Accesses the attributes linked with the series, which provides metadata and behavior controls. It currently includes the ability to check if duplicate labels are permitted within the data structure.\nReturns: Flags object containing the attribute allows_duplicate_labels.",
    "class": "Series"
  },
  "pandas.Series.floordiv": {
    "new_func": "elementwise_integer_divide",
    "description": "Computes the element-by-element integer division between the series and another array-like or scalar. Supports replacement of NaN values with a specified number before the operation. It's the counterpart of the '//' operator tailored for datasets with potential missing data.\nParameters: divisor (Series or scalar), level (int or index name), substitute (float, default NaN), which_axis (0 or 'index')\nReturns: Series - The quotient after division, with integer values.",
    "class": "Series"
  },
  "pandas.Series.groupby": {
    "new_func": "collector_by_criteria",
    "description": "Organizes the series into groups based on the provided criteria, enabling combined operations such as split-apply-combine workflows. This function is powerful for aggregating data and performing group-specific transformations or calculations.\nParameters: grouping_criteria (mapping, function, label, or list), along_axis (0 or 'index', deprecated for 1), hierarchy_level (int or name), maintain_index (bool), order_by_keys (bool), include_group_keys (bool), visibility_of_categories (bool, deprecated), ignore_na_groups (bool)\nReturns: GroupBy object - An object encapsulating the grouping information, ready for further analysis.",
    "class": "Series"
  },
  "pandas.Series.hasnans": {
    "new_func": "null_presence_check",
    "description": "Checks the existence of null (NaN) values within the series. If any are found, it returns True, indicating that there are missing data points. This is useful for precondition checks and optimizing performance by identifying datasets that require cleaning.\nReturns: bool - True if NaNs are present, otherwise False.",
    "class": "Series"
  },
  "pandas.Series.head": {
    "new_func": "initial_elements",
    "description": "Retrieves a specified number of rows from the beginning of the sequence based on their position. It can be utilized for preliminary verification of data types within the sequence. Providing a negative count will exclude a corresponding number of rows from the end. If the specified count exceeds the total rows, the entire sequence is returned. Input: count (int) - default 5, the number of initial rows to obtain. Output: A sequence of the same structure as the original, containing the specified number of initial rows.",
    "class": "Series"
  },
  "pandas.Series.get": {
    "new_func": "retrieve_element",
    "description": "Obtains an element from the sequence using the specified identifier. If the identifier is not present, a default value is returned instead. Input: key (object) - the identifying element. Output: An element of the same type contained within the sequence.",
    "class": "Series"
  },
  "pandas.Series.gt": {
    "new_func": "element_wise_supremacy",
    "description": "Compares elements between two sequences or a sequence and a scalar, determining whether each element in the primary sequence is greater than its counterpart. It allows for a replacement value to be set for missing elements prior to comparison. Inputs: comparator (sequence or scalar), level (int or name), replacement_value (None or float), axis (0 or 'index'). Output: A new sequence containing the results of the comparison.",
    "class": "Series"
  },
  "pandas.Series.iat": {
    "new_func": "single_position_access",
    "description": "Provides access to a specific element based on its integer index within the sequence. This method is appropriate when only one element needs to be retrieved or set. An IndexError is raised if the integer index is out of range.",
    "class": "Series"
  },
  "pandas.Series.hist": {
    "new_func": "distribution_visualization",
    "description": "Generates a visual representation of the frequency distribution of the sequence's elements, using a bar chart. It allows customization of the graph, such as grouping, axis labeling, and bin sizes. Inputs include various parameters for graphical adjustments and layout preferences. The output is a visual plot depicting the element distribution.",
    "class": "Series"
  },
  "pandas.Series.idxmax": {
    "new_func": "peak_finder_label",
    "description": "Identifies the position identifier for the highest datum within the dataset. If there are multiple occurrences with the same highest value, it outputs the identifier for the first occurrence. Excludes missing or null data points if specified. Returns an error if called on an empty dataset. Parameters: axis (int or 'index') - Unused, exists for compatibility. skipna (bool) - Whether to ignore missing values, defaults to True. *args, **kwargs - Placeholder for additional arguments without effect. Returns: The label corresponding to the peak value.",
    "class": "Series"
  },
  "pandas.Series.idxmin": {
    "new_func": "trough_finder_label",
    "description": "Determines the position identifier for the smallest datum in the dataset. Should there be more than one instance of the minimal value, the identifier of the first instance is given. Null data points can be disregarded if chosen. If the dataset is void of data, it triggers an error. Parameters: axis (int or 'index') - Unused, for compatibility purposes. skipna (bool) - Option to exclude NA values, defaults to True. *args, **kwargs - Accepts additional arguments without impact. Returns: The label linked to the minimal value.",
    "class": "Series"
  },
  "pandas.Series.iloc": {
    "new_func": "positional_indexer",
    "description": "Allows data selection based on numerical positions within the dataset. Accepts various forms of integers, arrays, or slice objects to specify the position. A boolean array or a callable for conditional selection is also permitted. If attempting to access beyond the bounds, except with slice object, an error will be raised. Returns: The selected data based on the input positional arguments.",
    "class": "Series"
  },
  "pandas.Series.index": {
    "new_func": "axis_label_inspector",
    "description": "Retrieves the set of position markers associated with each data point. These markers are immutable, and they serve as a key for accessing and aligning the entries. Returns: A collection of position identifiers.",
    "class": "Series"
  },
  "pandas.Series.is_monotonic_decreasing": {
    "new_func": "sequential_fall_checker",
    "description": "Evaluates whether the elements in the sequence are in a non-increasing order, i.e., each element is less than or equal to the preceding one. Returns: A boolean indicating the outcome of this assessment.",
    "class": "Series"
  },
  "pandas.Series.infer_objects": {
    "new_func": "deduce_element_types",
    "description": "This method attempts to upgrade the data types of columns holding generic objects to more specific ones by analyzing the data contained within. It leaves columns with non-generic objects or those that cannot be converted as is. By default, it duplicates the data unless specified otherwise. This operation follows similar rules as when initially constructing the data structure. Parameters: copy - A boolean argument, defaulting to True, indicating whether to duplicate the data for columns that remain unaltered or for the entire data structure. Returns: An object of the same class as the input with possibly upgraded data types for some columns.",
    "class": "Series"
  },
  "pandas.Series.interpolate": {
    "new_func": "fill_missing_via_estimation",
    "description": "This method fills in missing values using various estimation techniques, which can be linear or based on various methods of interpolation, such as time, numerical index values, and others. It can be performed along a specific axis, with the ability to set a maximum number of consecutive missing values to fill and the direction in which to fill them. It can also limit the filling to certain areas and allows for the option to modify the data in place. Parameters: method - A string indicating the estimation technique. axis - The axis along which to fill missing values. limit - An optional integer to specify the maximum number of consecutive missing values to fill. inplace - A boolean to update the data in place. limit_direction - An optional string to specify the direction in which to fill missing values. limit_area - An optional area restriction for filling missing values. downcast - Optional argument for downcasting data types if possible. **kwargs - Additional keyword arguments for the estimation function. Returns: The modified object of the same type as the caller with estimated values filled in, or None if inplace is set to True.",
    "class": "Series"
  },
  "pandas.Series.is_monotonic_increasing": {
    "new_func": "ascends_strictly",
    "description": "This property assesses whether the elements of the object ascend in a strict sequence without decreasing at any point. Returns: A boolean indicating the result of the assessment.",
    "class": "Series"
  },
  "pandas.Series.items": {
    "new_func": "enumerate_entries",
    "description": "This method provides an iterator that yields pairs of indices and their corresponding values, allowing for lazy evaluation of the sequence. Returns: An iterator that produces tuples consisting of an index and its associated value.",
    "class": "Series"
  },
  "pandas.Series.isin": {
    "new_func": "exists_in_sequence",
    "description": "This function checks for the presence of the object's elements within a specified collection, yielding a boolean sequence that indicates whether each element has a corresponding match in the provided set or list-like structure. Parameters: values - A set or sequence-like object containing the elements to compare against. Returns: A sequence of booleans reflecting the presence of each element within the provided values. Raises: A TypeError if the input values constitute a single string instead of a collection.",
    "class": "Series"
  },
  "pandas.Series.is_unique": {
    "new_func": "distinctiveness_checker",
    "description": "Evaluates whether all elements in a sequence are distinct from one another. It returns a single truth value indicating the absence of duplicate entries. Parameters: None. Returns: A single boolean indicating true if all entries are distinct, false otherwise.",
    "class": "Series"
  },
  "pandas.Series.isnull": {
    "new_func": "absence_detector",
    "description": "Evaluates each element in a sequence to check for absence of data, mapping missing or 'not available' entries to a truth value. Parameters: None. Returns: A sequence of boolean values, where each corresponds to whether an element is missing.",
    "class": "Series"
  },
  "pandas.Series.keys": {
    "new_func": "identifier_retriever",
    "description": "Provides an alias for the identifiers of the sequence, typically an index in a data structure. Parameters: None. Returns: The index object representing the identifiers of the elements.",
    "class": "Series"
  },
  "pandas.Series.kurt": {
    "new_func": "tail_heaviness_measurer",
    "description": "Computes the degree of peakedness of the distribution of the data in the sequence, relative to a normal distribution. This statistical measure is normalized and is unbiased. Parameters: axis (fixed at 0 for a sequence), skipna (boolean, default True to exclude missing data), numeric_only (boolean, default False, not applicable to sequences), **kwargs (additional arguments). Returns: A scalar representing the kurtosis measurement.",
    "class": "Series"
  },
  "pandas.Series.isna": {
    "new_func": "void_checker",
    "description": "Scans each element in a sequence to identify if they are void of data, mapping such entries to true. Parameters: None. Returns: A sequence of boolean values, each reflecting the presence or absence of data in the corresponding element.",
    "class": "Series"
  },
  "pandas.Series.loc": {
    "new_func": "series_label_access",
    "description": "Enables retrieval of specific subsets of rows and columns within a data structure using their unique identifiers, or through logical vectors. Acceptable inputs include a singular identifier, a collection of identifiers, a range slice with identifiers, a logical vector with matching length, or a callable that generates a suitable output for selection. The method ensures inclusive retrieval for both the beginning and ending identifiers in a range. An error is raised if the requested labels are not present or if there is a misalignment in the index.",
    "class": "Series"
  },
  "pandas.Series.max": {
    "new_func": "series_peak_value",
    "description": "Calculates the highest value across a specified axis, excluding any missing or null entries by default. The method can be limited to consider only numeric data. Arguments include an axis indicator, a boolean to skip null values, a flag for numeric data only, and additional keyword arguments for extended functionality. The output is a single value representing the peak of the dataset.",
    "class": "Series"
  },
  "pandas.Series.mask": {
    "new_func": "series_value_substitute",
    "description": "Enables substitution of data points within the structure based on a specified condition. When the condition evaluates to true, the original data is replaced by the provided alternative; otherwise, the original data remains. Conditions can be given as a logical series, an array-like structure, or a function returning a boolean result. The 'other' parameter determines the substitute values, and can also be a scalar, series, or function. Can optionally be performed in place, and supports alignment along a specified axis or level. The output is the modified data structure, or none if the operation was done in place.",
    "class": "Series"
  },
  "pandas.Series.median": {
    "new_func": "series_middle_value",
    "description": "Determines the central value in the dataset along the requested axis, which is the value separating the higher half from the lower half of the data. It disregards null entries by default and can be constrained to only consider numeric data. Arguments include an axis indicator, a boolean to skip null values, a flag for numeric data only, and additional keyword arguments. The result is a single value that represents the midpoint value of the dataset.",
    "class": "Series"
  },
  "pandas.Series.mean": {
    "new_func": "series_average_value",
    "description": "Computes the arithmetic average across the specified axis, while optionally excluding missing or null data and restricting the calculation to numeric data types. Parameters include an axis indicator, a boolean to omit null values, a flag for numeric data only, and additional keyword arguments. The result returned is a single value representing the average.",
    "class": "Series"
  },
  "pandas.Series.memory_usage": {
    "new_func": "series_storage_footprint",
    "description": "Calculates the amount of space required to store the data structure, with the option to account for the size of the data structure's indexing and a more thorough inspection of object data types for an accurate measurement. Parameters: index (bool, default True) - Determines if the size of the index should be considered. deep (bool, default False) - When set to True, performs a more detailed analysis of memory consumption for data types that are objects. Returns: int - The amount of memory in bytes.",
    "class": "Series"
  },
  "pandas.Series.min": {
    "new_func": "series_floor_value",
    "description": "Determines the smallest value across the specified axis, excluding any null entries. To obtain the position of the smallest value, the corresponding 'idxmin' should be used instead. Parameters: axis (0 or 'index', default 0) - The axis along which to calculate the smallest value. skipna (bool, default True) - Whether to ignore null values in the calculation. numeric_only (bool, default False) - If set to True, only numerical data will be considered. **kwargs - Additional arguments passed to the function. Returns: The smallest value, either as a scalar or within a Series.",
    "class": "Series"
  },
  "pandas.Series.nbytes": {
    "new_func": "series_byte_size",
    "description": "Retrieves the total number of bytes allocated for the data within the data structure. Returns: int - The size of the data in bytes.",
    "class": "Series"
  },
  "pandas.Series.ne": {
    "new_func": "series_mismatch",
    "description": "Compares elements between two data structures and returns a boolean series indicating whether elements are not equal, with the ability to substitute a specified value for any missing data before the comparison. Parameters: other (Series or scalar) - The data structure or scalar to compare with. level (int or name, optional) - Used to broadcast across a specified level for MultiIndex. fill_value (None or float, optional) - The value used to fill missing data prior to comparison. axis (0 or 'index', default 0) - Axis for the operation, with 0 corresponding to the index. Returns: A series indicating the inequality of elements.",
    "class": "Series"
  },
  "pandas.Series.name": {
    "new_func": "series_identifier",
    "description": "Accesses the identifier label of the data structure, which doubles as the column name when integrated into a two-dimensional data structure. This label is also utilized for display purposes in an interactive environment. Returns: A hashable object representing the identifier.",
    "class": "Series"
  },
  "pandas.Series.mod": {
    "new_func": "series_elementwise_remainder",
    "description": "Computes the remainder of division between corresponding elements in the series and another array or a scalar value. This operation is similar to the modulus operator. It also allows for the replacement of missing values in the series or the input array before the operation. Parameters: other (Series or scalar) - The divisor in the operation. level (int or name) - Level to broadcast across a MultiIndex. fill_value (None or float) - Value to replace missing data before computation. Returns: Series - The remainder after division.",
    "class": "Series"
  },
  "pandas.Series.ndim": {
    "new_func": "data_dimensions",
    "description": "Provides the number of axes / array dimensions of the data structure, which is always 1 for a one-dimensional array. Returns: int - The number of dimensions.",
    "class": "Series"
  },
  "pandas.Series.nlargest": {
    "new_func": "top_elements",
    "description": "Identifies the specified number of highest values in the array, sorted in descending order. It allows the selection of how to handle ties. Parameters: n (int) - The number of elements to return. keep ({'first', 'last', 'all'}) - Determines which elements to keep when there are duplicates. Returns: Series - An array of the top values.",
    "class": "Series"
  },
  "pandas.Series.notnull": {
    "new_func": "non_missing_indicator",
    "description": "Generates a boolean array indicating whether each element is non-missing. True represents the presence of a non-missing (valid) value, while False indicates missing data. Returns: Series - An array of boolean values reflecting the non-missing status of each element.",
    "class": "Series"
  },
  "pandas.Series.mul": {
    "new_func": "elementwise_product",
    "description": "Calculates the product of corresponding elements in the series and another array or scalar. This operation supports the replacement of missing values before performing the calculation. Parameters: other (Series or scalar) - The multiplier in the operation. level (int or name) - Level for broadcasting across a MultiIndex. fill_value (None or float) - Value to substitute missing data before computation. Returns: Series - The product of the elements.",
    "class": "Series"
  },
  "pandas.Series.notna": {
    "new_func": "is_present",
    "description": "Generates a boolean Series indicating the presence of non-null values in the original Series. True is returned where the elements are not considered null, and False where they are. Elements that are empty strings or infinite are not treated as null by default. Parameters: None. Returns: Series - A boolean Series indicating the presence of non-null values.",
    "class": "Series"
  },
  "pandas.Series.mode": {
    "new_func": "most_frequent_values",
    "description": "Identifies the most commonly occurring value(s) within the Series. There can be multiple values returned if there is a tie for the most frequent. The result is always a Series, even if there is only one mode. Parameters: dropna (bool, default True) - Excludes null values from the count. Returns: Series - The mode(s) of the Series, sorted.",
    "class": "Series"
  },
  "pandas.Series.nsmallest": {
    "new_func": "least_values",
    "description": "Retrieves the specified number of smallest values from the Series, sorted in ascending order. When duplicates are present, the 'keep' parameter determines which occurrences to return. Parameters: n (int, default 5) - The number of values to return. keep ({'first', 'last', 'all'}, default 'first') - Specifies which duplicates to keep when the count exceeds n. Returns: Series - A Series containing the minimum n values in ascending order.",
    "class": "Series"
  },
  "pandas.Series.nunique": {
    "new_func": "series_distinct_count",
    "description": "Calculates the total number of distinct entries in the Series, excluding any null values by default. Parameters: dropna (bool, default True) - Option to exclude nulls from the count. Returns: int - The count of unique entries.",
    "class": "Series"
  },
  "pandas.Series.pad": {
    "new_func": "propagate_last",
    "description": "Fills missing entries by carrying forward the last observed non-null value. This method is set to be replaced by a recommended alternative. Parameters: axis (optional), inplace (bool, default False), limit (optional), downcast (optional) - Controls the filling behavior. Returns: Series/DataFrame or None - The object with filled missing values, or None if 'inplace' is set to True.",
    "class": "Series"
  },
  "pandas.Series.pct_change": {
    "new_func": "series_relative_variation",
    "description": "Calculates the unit change between the current and a prior element within the data series. This method is typically utilized for assessing the proportional change in a sequence of values. By default, the comparison is made with the direct predecessor in the sequence. To convert these values to a percentage, a multiplication by 100 is required. Input arguments include a shift period, a method for handling null values, a limit on consecutive null values to fill, and an optional frequency increment for time series data. The output is an object of the same type as the caller, containing the calculated changes.",
    "class": "Series"
  },
  "pandas.Series.pipe": {
    "new_func": "series_flow",
    "description": "Enables the application of a sequence of transform functions that are compatible with data series or frames. Users can input a function, along with positional and keyword arguments, which will be passed to the specified function. The output is determined by the return type of the applied function.",
    "class": "Series"
  },
  "pandas.Series.plot": {
    "new_func": "visual_representation",
    "description": "Generates graphical representations for a data series or frame. It allows a variety of plot types such as line, bar, histogram, and more, utilizing the default or specified graphical backend. Options include axis labels, plot kind, subplot configuration, axis sharing, layout, figure size, index utilization, title, grid visibility, legend placement, line style, log scaling, tick values, axis limits, axis labels, rotation, font size, colormap, colorbar, table, error bars, stacking, secondary y-axis, and additional backend options. The result is a graphical axis object or an array of such objects.",
    "class": "Series"
  },
  "pandas.Series.plot.bar": {
    "new_func": "vertical_representation",
    "description": "Creates a vertical graphical representation of categorical data, where the length of each bar correlates to the value it signifies. This visualization is beneficial for comparing discrete categories. Parameters allow customization of plot attributes including the axis labels, color, and additional styling options. The method returns a graphical axes object or an array of these objects when multiple subplots are requested.",
    "class": "Series"
  },
  "pandas.Series.plot.area": {
    "new_func": "cumulative_distribution",
    "description": "Illustrates quantitative data with a stacked graphical representation by default. The method encapsulates the area plotting capabilities of the underlying graphical library. Users can specify the axis coordinates, whether to stack the plots, and other styling parameters. The output is a graphical axes object or an array of such objects if multiple areas are plotted simultaneously.",
    "class": "Series"
  },
  "pandas.Series.plot.box": {
    "new_func": "quartile_visualization",
    "description": "Displays a chart that graphically represents groups of numerical data through quartiles. It illustrates the spread and skewness via quartiles and uses lines, known as whiskers, to display variability outside the upper and lower quartiles. Outliers are depicted as individual points. Parameters: by (str or sequence, optional) - Column to group data by. **kwargs - Additional keyword arguments for further customization. Returns: An object representing an axis or an array of axes.",
    "class": "Series"
  },
  "pandas.Series.plot.density": {
    "new_func": "smooth_probability_distribution",
    "description": "Creates a smoothed representation of a variable's probability distribution, based on a Gaussian kernel estimation method. This visualization helps to understand the underlying distribution shape of the data. Parameters: bw_method (str, scalar or callable, optional) - Defines the method for bandwidth estimation. ind (array or int, optional) - Specifies the evaluation points for the density estimation. **kwargs - Additional keyword arguments for plotting customization. Returns: An axis object or an array of axis objects.",
    "class": "Series"
  },
  "pandas.Series.plot.barh": {
    "new_func": "horizontal_comparison_chart",
    "description": "Generates a graph with horizontal bars representing the magnitude of data points, facilitating the comparison of different categories or values. Parameters: x (label or position, optional) - The label or position for the x-axis. y (label or position, optional) - The label or position for the y-axis. color (str, array-like, or dict, optional) - Customization options for the color of the bars. **kwargs - Additional keyword arguments for plot customization. Returns: An axis object or an array of axis objects when multiple subplots are present.",
    "class": "Series"
  },
  "pandas.Series.plot.hist": {
    "new_func": "frequency_distribution_chart",
    "description": "Renders a frequency distribution diagram, where data is partitioned into specified intervals (bins), showing the number of occurrences in each bin. Parameters: by (str or sequence, optional) - Column to group the data by. bins (int, default 10) - Determines the number of intervals. **kwargs - Additional keyword arguments for the plot. Returns: An axis object representing the histogram.",
    "class": "Series"
  },
  "pandas.Series.pop": {
    "new_func": "extract_and_remove_value",
    "description": "Retrieves and simultaneously removes the specified element from the series. If the element does not exist, a KeyError is raised, signaling that the key was not found. Parameters: item (label) - The index label of the element to be removed. Returns: The removed value from the series.",
    "class": "Series"
  },
  "pandas.Series.prod": {
    "new_func": "series_aggregate_multiplication",
    "description": "Calculates the cumulative multiplication of elements along a specific axis, excluding any null values. This operation requires at least a minimum count of non-null values to proceed; otherwise, the result is null. Extra arguments can be passed to modify the behavior of the calculation. It outputs a single number or a single number per column when applied to data structures with multiple series.",
    "class": "Series"
  },
  "pandas.Series.plot.line": {
    "new_func": "visualize_trajectory",
    "description": "Renders a graphical representation of data points as a connected path. The method takes optional arguments to specify the horizontal and vertical coordinates, with the default being the data structure's index for the horizontal axis. One can customize the appearance of the path, including its color, by passing additional arguments. The output is a visual representation of the data, which can be an Axes object or an array of Axes objects if multiple plots are created.",
    "class": "Series"
  },
  "pandas.Series.product": {
    "new_func": "cumulative_product",
    "description": "Computes the total multiplication result of data points, considering only valid entries and ignoring any missing values. The function necessitates a minimum quantity of non-null data points to perform the calculation, or else the outcome will be considered null. This operation supports additional parameters to fine-tune its execution. The output is either a single number or a single number per column, depending on the data structure's dimensionality.",
    "class": "Series"
  },
  "pandas.Series.plot.kde": {
    "new_func": "density_curve_estimator",
    "description": "Creates a smooth curve that represents the estimated density of a dataset using a non-parametric technique with Gaussian bases. It allows for the selection of a method to determine the optimal width of the Gaussian kernels. By default, a predefined number of evaluation points are used, but this can be customized either by specifying a different number of points or by providing an array of specific points for evaluation. The visualization output is either a single plot or an array of plots if multiple densities are estimated.",
    "class": "Series"
  },
  "pandas.Series.pow": {
    "new_func": "elemental_exponentiation",
    "description": "Performs an element-by-element exponential operation between the data points and another specified series or scalar. It includes the capability to fill in missing data points with a specified value before the operation is executed. While it is primarily designed to handle single-dimensional data, it retains compatibility with multi-dimensional structures. The result is a new series containing the exponentiated values.",
    "class": "Series"
  },
  "pandas.Series.rdiv": {
    "new_func": "elemental_inverse_divide",
    "description": "Executes element-wise reciprocal division between a scalar or series-like structure and this data structure. It allows for an optional value to be specified, which will replace NaN occurrences before the computation. The division operation is performed as the reciprocal of the standard division: the other value divided by elements from this data structure. Input arguments: other (scalar or series-like) - The dividend in the reciprocal division. level (optional) - The level in a MultiIndex to broadcast across. fill_value (float, optional) - The value to use for replacing NaN before the calculation. axis (integer or 'index', defaulted to 0) - An axis parameter for compatibility, not used in Series. Returns: A new series containing the result of reciprocal division.",
    "class": "Series"
  },
  "pandas.Series.reindex_like": {
    "new_func": "series_align_indices",
    "description": "Produces a new data structure whose indices are aligned with those of another reference object. It can optionally introduce NaNs where indices do not overlap or employ various methods to fill in gaps in the indices. If the indices are the same and copying is not requested, the original object may be returned. Input arguments: other (object of same data type) - Its indices are used for alignment. method (optional) - Specifies the method for filling gaps in the reindexed object. copy (boolean, optional) - If set to True, a new object is always created. limit (integer, optional) - The maximum number of consecutive indices to fill for non-exact matches. tolerance (optional) - The maximum distance between original and new labels for non-exact matches. Returns: A new object of the same type with altered indices.",
    "class": "Series"
  },
  "pandas.Series.rename": {
    "new_func": "alter_identifiers",
    "description": "Modifies the labels of the index or the name attribute of this data structure. A transformation can be applied to the index, or the name attribute can be directly altered using a scalar value. This modification can be made in place or return a new modified object. Input arguments: index (optional) - A transformation to apply to the index or a scalar value to alter the .name attribute. copy (boolean, optional) - Indicates if the data should be copied. inplace (boolean, defaulted to False) - If set to True, the operation will modify the data structure without returning a new one. level (optional) - Specifies the level in case of a MultiIndex. errors ('ignore' or 'raise', optional) - Handling of errors during the renaming process. Returns: A new object with altered index labels or name, or None if modified in place.",
    "class": "Series"
  },
  "pandas.Series.reindex": {
    "new_func": "refit_indices",
    "description": "Adjusts the data structure to a new set of labels, optionally employing a method to determine how to treat gaps. Places default or specified values where no prior value exists. The result may be the original object if the index is unchanged and copying is not requested. Input arguments: index (array-like, optional) - The new set of labels for the index. method (optional) - The method to use for populating new, unfilled entries. copy (boolean, optional) - Whether to return a new object if indices match. level (optional) - If provided, reindexing will be performed on this MultiIndex level. fill_value (optional) - The value to use for unfilled entries. limit (integer, optional) - The max number of consecutive elements to forward or backward fill. tolerance (optional) - The maximum distance for index matching with inexact labels. Returns: A new object with the specified index.",
    "class": "Series"
  },
  "pandas.Series.rename_axis": {
    "new_func": "relabel_axis",
    "description": "Sets a new name for the axis of the index or modifies its labels. The transformation can be a scalar, list-like, or function applied to the axis' values. The alteration can be performed in place or return a new modified object. Input arguments: mapper (optional) - Value to set the axis name. index (optional) - Transformations to apply to the axis' values. axis (0 or 'index', optional) - The axis to rename, defaults to 0 for Series. copy (boolean, optional) - Whether to copy the underlying data. inplace (boolean, defaulted to False) - If True, modifies the object directly instead of creating a new one. Returns: The same type as the caller or None if modified in place.",
    "class": "Series"
  },
  "pandas.Series.replace": {
    "new_func": "series_value_substitution",
    "description": "Enables the substitution of a series of values with alternative ones based on specified criteria. It can dynamically change values without needing the exact position. The criteria for substitution can be a single value, a list of values, a regular expression, or a dictionary detailing which values should be replaced with which corresponding new values. When applied to a DataFrame, different values can be specified for different columns. It can perform the substitution in place and can also handle a maximum size gap for forward or backward filling, which is now deprecated. The method parameter is also deprecated and was used to determine the method for replacement when certain conditions were met. The output is the modified object, unless the operation was performed in place.",
    "class": "Series"
  },
  "pandas.Series.resample": {
    "new_func": "time_series_restructuring",
    "description": "This method is used for frequency conversion and restructuring of data points based on time intervals. An object with a datetime-like index or a specified datetime-like label or level must be provided. The method involves specifying a rule to define the target frequency for conversion. Additional parameters determine how bins are labeled and closed, the origin for adjustments, and whether to include group keys in the result. It returns a Resampler object which can be further processed to obtain the resampled data.",
    "class": "Series"
  },
  "pandas.Series.round": {
    "new_func": "series_decimal_precision_adjustment",
    "description": "Modifies all numerical values in a sequence, adjusting their precision to the specified number of decimal places. If the number of decimals specified is negative, the precision is adjusted to the left of the decimal point. The method returns a new sequence with each value rounded to the desired precision. Additional arguments are accepted for compatibility purposes but have no effect on the operation.",
    "class": "Series"
  },
  "pandas.Series.rmul": {
    "new_func": "series_scaler_multiplication",
    "description": "Computes the element-wise product of the sequence and another sequence or scalar, following the reverse multiplication protocol. It has the capability to replace missing values with a specified substitute value before the computation. The operation is broadcasted across a specified level for MultiIndex sequences. The result is a new sequence containing the products.",
    "class": "Series"
  },
  "pandas.Series.rpow": {
    "new_func": "series_scaler_exponentiation",
    "description": "Calculates the element-wise exponential power where the sequence is raised to the power of another sequence or scalar, conforming to the reverse exponentiation protocol. Similar to other operations, it can accommodate a fill value to substitute missing entries. The computation can be broadcast across a level in a MultiIndex sequence. It yields a new sequence with the results of the exponentiation.",
    "class": "Series"
  },
  "pandas.Series.rolling": {
    "new_func": "SlidingWindowCalculator",
    "description": "Provides calculations over a specified sliding segment of data. The segment size can be a fixed number of data points or a time-based interval for datetime-indexed data. It supports custom window boundary definitions with a subclass, and permits adjustments for minimum data points within a segment, segment centering, weighting type, and specific column calculation for data frames. The segment can be evaluated at intervals using a step and can employ single or table method execution strategy. It returns an object that can handle various aggregation operations for the defined sliding segment.",
    "class": "Series"
  },
  "pandas.Series.rsub": {
    "new_func": "ReverseElementWiseSubtraction",
    "description": "Performs element-wise subtraction between a scalar or series and the data series, effectively reversing the subtraction order. It allows for a fill-in value to replace missing data before the operation. The subtraction operation is broadcasted level-wise if a multi-index level is provided. The result is a new series with the difference of the provided values and the original data points.",
    "class": "Series"
  },
  "pandas.Series.sample": {
    "new_func": "RandomSelection",
    "description": "Selects a random subset of items from the data series. The subset size can be specified as a fixed number of items or a fraction of the total. It allows replacement to enable or disable the possibility of selecting an item more than once. Weights can be provided for non-uniform selection probabilities. A random seed parameter ensures reproducibility. If instructed, the resulting data series will have a reset index. This method returns a new series of the same type containing the randomly chosen items.",
    "class": "Series"
  },
  "pandas.Series.set_axis": {
    "new_func": "RenameIndices",
    "description": "Alters the index of the data series to the provided label list, allowing for the modification of row labels. The alteration can be made without copying the underlying data if specified. The result of this operation is a data series with the updated index.",
    "class": "Series"
  },
  "pandas.Series.sem": {
    "new_func": "MeanStandardError",
    "description": "Calculates the unbiased standard error of the dataset mean, considering the specified delta degrees of freedom for normalization. It can exclude null values during computation and is restricted to numerical data. The function returns a scalar value representing the standard error.",
    "class": "Series"
  },
  "pandas.Series.set_flags": {
    "new_func": "apply_attributes",
    "description": "Produces a new object mirroring the original with modified attributes. This method allows setting the behavior for permitting or disallowing duplicate indices. Additionally, it offers a choice to either produce a cloned instance or modify the original directly. In an upcoming major release, the default behavior for cloning will be deferred until necessary, and the explicit parameter for cloning will be phased out. Input arguments include a boolean indicating whether to clone the object and a boolean option to enable or disable duplicate index labels. The output is a new instance of the same type with the specified attributes adjusted.",
    "class": "Series"
  },
  "pandas.Series.rtruediv": {
    "new_func": "reciprocal_elementwise_divide",
    "description": "Conducts element-wise reciprocal division between the series and another array or scalar. If there is absent data in either input, a specified value can be used as a substitute before the calculation. Input parameters are the divisor, which can be another similar type or a scalar, an optional level for alignment across a certain index level, a fill value to replace missing entries, and an axis which is kept for compatibility purposes. The result is a new series containing the division outcomes.",
    "class": "Series"
  },
  "pandas.Series.searchsorted": {
    "new_func": "ordered_insertion_indices",
    "description": "Determines the indices at which elements should be inserted into the sorted series to maintain the series order. The series is expected to be sorted in ascending order for accurate results. Inputs include the values to be inserted, a choice of which side ('left' or 'right') the insertion index should favor, and an optional sorter array that specifies the sorting order. The function returns indices where new elements should be placed to keep the series in order.",
    "class": "Series"
  },
  "pandas.Series.shift": {
    "new_func": "translate_indices",
    "description": "Modifies the index of the series by a specified number of intervals, which can either be positive or negative. An optional frequency parameter allows for the index to be shifted in time, assuming the index is of a temporal nature. Without frequency, the index shifts without data realignment. Inputs include the number of intervals to shift, the frequency of shifting, the axis along which to shift, a value to fill missing data introduced by the shift, and a suffix for labeling the shifted data. The function returns a copy of the series with its index shifted as specified.",
    "class": "Series"
  },
  "pandas.Series.size": {
    "new_func": "count_elements",
    "description": "Calculates the total number of entries within the data structure. This property does not take any input arguments and returns an integer representing the count of elements.",
    "class": "Series"
  },
  "pandas.Series.shape": {
    "new_func": "dimensions",
    "description": "Returns a tuple representing the dimensions of the underlying array.",
    "class": "Series"
  },
  "pandas.Series.sparse": {
    "new_func": "sparse_accessor",
    "description": "Provides access to specialized methods and properties for sparse matrices.",
    "class": "Series"
  },
  "pandas.Series.skew": {
    "new_func": "asymmetry_measure",
    "description": "Computes the degree of asymmetry in the distribution along the given axis. Excludes null values by default and optionally includes only numerical data. The result is normalized by N-1. Parameters: axis (int, default 0) - Axis along which the calculation is performed. skipna (bool, default True) - Whether to skip null values. numeric_only (bool, default False) - Whether to include only numerical data. Returns: scalar - The calculated asymmetry metric.",
    "class": "Series"
  },
  "pandas.Series.sort_index": {
    "new_func": "order_by_index",
    "description": "Arranges the data by its associated labels. Can sort in both ascending and descending order and allows for sorting at a specific hierarchical index level. An in-place sort option is available. Parameters: level (int, optional) - Index level to sort. ascending (bool or list of bools, default True) - Direction of sort. inplace (bool, default False) - Whether to perform the operation in-place. Returns: Series or None - The sorted series or None if 'inplace' is True.",
    "class": "Series"
  },
  "pandas.Series.sparse.density": {
    "new_func": "occupancy_rate",
    "description": "Calculates the ratio of non-default entries over the total number of possible entries in the sparse array, represented as a decimal.",
    "class": "Series"
  },
  "pandas.Series.str.center": {
    "new_func": "symmetric_padding",
    "description": "Expands each element in the collection to a specified width by adding a specified character symmetrically on both sides. If the item's length is less than the defined width, the padding character is used to fill in the space equally on the left and right until the total length matches the desired width. Parameters: target_width (int) - The desired width of the elements after padding. padding_char (str) - The character used for padding, with a default of a single space. Returns: A new collection where each element has been symmetrically padded to the specified width.",
    "class": "Series"
  },
  "pandas.Series.str.decode": {
    "new_func": "text_unscrambling",
    "description": "Converts byte string elements in a collection into a character string using the specified character set encoding. This operation is commonly required for data that has been encoded to bytes in a particular character encoding and needs to be read as text. Parameters: charset (str) - The encoding in which to interpret the byte strings. fault_handling (str, optional) - Specifies how to handle encoding errors. Returns: A new collection with elements as decoded text.",
    "class": "Series"
  },
  "pandas.Series.str.count": {
    "new_func": "pattern_repetition_tally",
    "description": "Calculates the frequency of a specified regular expression pattern within each element of a collection. It is used to quantify the presence of specific substrings or patterns within text data. Parameters: regex_pattern (str) - A valid regular expression pattern to search for. regex_flags (int, default 0) - Modifier flags that affect the regular expression search. For a full list, refer to the regular expressions module documentation. Returns: A new collection with counts of how often the pattern occurs in each element.",
    "class": "Series"
  },
  "pandas.Series.sparse.sp_values": {
    "new_func": "nondefault_elements",
    "description": "Retrieves an array of elements from a specialized array-like structure that excludes the predefined 'empty' value, which is used to represent sparsity in the data. Parameters: None. Returns: An array of elements that are not equal to the 'empty' value defined for sparsity.",
    "class": "Series"
  },
  "pandas.Series.str.encode": {
    "new_func": "text_bit_coding",
    "description": "Transforms character string elements in a collection to their respective byte representation using the specified character set encoding. This process is commonly used when preparing text data for storage or transmission that requires a byte format. Parameters: charset (str) - The encoding to use for converting strings to bytes. fault_handling (str, optional) - Specifies how to handle errors during encoding. Returns: A new collection with elements converted to byte string format.",
    "class": "Series"
  },
  "pandas.Series.str.isdecimal": {
    "new_func": "check_numeric_characters",
    "description": "Evaluates each element in a sequence to determine if every character is a valid decimal number. Returns a corresponding array of logical values indicating the result for each element. An empty sequence will yield a value of False for the evaluation. Parameters: None. Returns: An array of boolean values, each corresponding to an element in the input sequence, indicating whether the element contains only decimal number characters.",
    "class": "Series"
  },
  "pandas.Series.str.isdigit": {
    "new_func": "assess_digit_presence",
    "description": "Inspects each element in a collection to verify if all characters are digits. Produces an array of logical values that signify the outcome of the verification per element. If an element is an empty sequence, the function returns False for that element. Parameters: None. Returns: An array of boolean values that correspond in size to the input collection, with each value representing the digit-only character status of each element.",
    "class": "Series"
  },
  "pandas.Series.str.isspace": {
    "new_func": "evaluate_whitespace_content",
    "description": "Determines if every character within each element of a sequence is a whitespace character. Yields an array of boolean values reflecting this determination. For elements with no characters, a False value is returned. Parameters: None. Returns: An array of boolean values that matches the length of the original sequence, indicating the presence of only whitespace characters in each element.",
    "class": "Series"
  },
  "pandas.Series.str.join": {
    "new_func": "concatenate_with_delimiter",
    "description": "Merges elements within a collection that are lists themselves, using a specified string as the delimiter. This operation concatenates list items with the delimiter interspersed. Parameters: delimiter (str) - The string to insert between list items. Returns: A new collection with the joined strings, or raises an AttributeError if the original collection does not contain strings or lists.",
    "class": "Series"
  },
  "pandas.Series.str.isnumeric": {
    "new_func": "verify_numeric_content",
    "description": "Scrutinizes each element in an array to ensure all characters fall within numeric categories, including numbers in any script, not just those used in the decimal system. Returns a boolean array with results for each element. Empty strings result in a False outcome. Parameters: None. Returns: A boolean array of the same size as the input array, indicating whether each element is composed entirely of numeric characters.",
    "class": "Series"
  },
  "pandas.Series.str.len": {
    "new_func": "series_element_measure",
    "description": "Calculates the number of items in each member of a one-dimensional array-like object. This operation is suitable for handling various types of sequences, including text, tuples, lists, or dictionaries, and results in a collection of integers representing the counts of items in each sequence.",
    "class": "Series"
  },
  "pandas.Series.str.ljust": {
    "new_func": "series_text_pad_right",
    "description": "Expands the text within each element of a one-dimensional array-like object to a specified width by appending a specified character to the right side. This transformation ensures that each text element reaches a minimum width, with the padding character filling any shortfall. The result is a collection of text elements, each with uniform width. Parameters: target_width (int) - The minimum width for the text elements; text_fill (str, default ' ') - The character used for padding. Returns: A collection of text elements.",
    "class": "Series"
  },
  "pandas.Series.str.lower": {
    "new_func": "series_text_to_lowercase",
    "description": "Transforms all text elements within a one-dimensional array-like object to their lowercase form. This modification is applied uniformly to each text element in the collection. The outcome is a collection with each text element converted to lowercase.",
    "class": "Series"
  },
  "pandas.Series.str.isupper": {
    "new_func": "series_all_caps_check",
    "description": "Evaluates each text element within a one-dimensional array-like object to determine if all characters are in uppercase format. The operation returns a collection of boolean values, with each value indicating whether the corresponding text element is entirely composed of uppercase characters.",
    "class": "Series"
  },
  "pandas.Series.str.match": {
    "new_func": "series_pattern_anchor",
    "description": "Assesses each text element in a one-dimensional array-like object to ascertain whether it commences with a sequence that aligns with a specified regular expression pattern. The operation yields a collection of boolean values indicating the presence or absence of the pattern at the start of each text element. Parameters: regex_pattern (str) - The regular expression pattern to match; sensitivity (bool, default True) - Toggles case sensitivity; regex_flags (int, default 0) - Flags from the regex module; missing_fill (scalar, optional) - Value to use for missing data, with defaults varying by data type.",
    "class": "Series"
  },
  "pandas.Series.str.removeprefix": {
    "new_func": "strip_start_sequence",
    "description": "Trims the specified leading characters from each element in a series. If the specified sequence of characters is not found at the beginning of an element, the element is returned unchanged. Input: prefix (string) - The series of characters to be removed from the start of each element. Output: A series or index with the specified starting sequence of characters removed from each element.",
    "class": "Series"
  },
  "pandas.Series.str.repeat": {
    "new_func": "amplify_elements",
    "description": "Creates a new series or index by replicating each element a specified number of times. Input: repeats (integer or sequence of integers) - The number of times to replicate each element; can be a uniform value for all elements or vary for each element. Output: A series or index with each original element duplicated the specified number of times.",
    "class": "Series"
  },
  "pandas.Series.str.rfind": {
    "new_func": "locate_substring_reverse",
    "description": "Searches for the highest index position of a specified substring within each element, considering optional boundaries. If the substring is not found, returns -1. Input: sub (string) - The substring to locate within each element. start (integer) - The starting index position to search. end (integer) - The ending index position to search. Output: A series or index of integers indicating the highest index positions where the substring is found within the boundaries.",
    "class": "Series"
  },
  "pandas.Series.str.replace": {
    "new_func": "substitute_pattern",
    "description": "Alters elements by substituting occurrences of a defined pattern with a specified replacement. This transformation can consider case sensitivity and utilize regular expressions. Input: pat (string or compiled regex) - The pattern to identify for substitution. repl (string or callable) - The replacement for each pattern occurrence. n (integer) - The number of substitutions to perform, defaulting to all. case (boolean) - Whether the substitution is case sensitive. flags (integer) - Flags from the regex module to modify the pattern search. regex (boolean) - Interprets the pattern as a regular expression if set to true. Output: A series or index with the pattern occurrences replaced as specified. Raises a ValueError under certain conditions related to the parameters.",
    "class": "Series"
  },
  "pandas.Series.str.rjust": {
    "new_func": "expand_strings_left",
    "description": "Enhances the length of strings by padding them on the left side up to a specified width, using a defined character for padding. Input: width (integer) - The minimum width of the resulting string. fillchar (string) - The character used for padding, defaulting to a space. Output: A series or index of strings with left-side padding applied to reach the desired width.",
    "class": "Series"
  },
  "pandas.Series.str.rindex": {
    "new_func": "string_terminus_search",
    "description": "Retrieves the highest position indices in each element of the series or index where a specific substring is fully contained within the specified boundaries. This method raises an exception if the specified substring is not detected. Input arguments: 'sub' (substring to locate), 'start' (integer specifying the left boundary), 'end' (integer specifying the right boundary). Output: A series or index containing the end-most index of the substring within each string element.",
    "class": "Series"
  },
  "pandas.Series.str.rsplit": {
    "new_func": "rightward_string_division",
    "description": "Divides string elements in the series or index from the right side using the provided separator. The method allows limiting the number of divisions and can optionally expand the results into a multi-dimensional structure. Input arguments: 'pat' (optional separator), 'n' (maximum number of splits; defaults to all), 'expand' (boolean indicating whether to expand results into separate columns). Output: Depending on 'expand', either a series/index with lists of strings or a DataFrame/MultiIndex with separated strings.",
    "class": "Series"
  },
  "pandas.Series.str.rpartition": {
    "new_func": "suffix_string_segmentation",
    "description": "Segments the string elements at the last occurrence of the specified separator, outputting three components: the segment before the separator, the separator itself, and the segment following it. If the separator is absent, the method outputs two empty strings followed by the original string element. Input arguments: 'sep' (separator string; defaults to whitespace), 'expand' (boolean determining the structure of the return value). Output: Either a DataFrame/MultiIndex or a series/index, depending on 'expand'.",
    "class": "Series"
  },
  "pandas.Series.str.rstrip": {
    "new_func": "trim_trailing_characters",
    "description": "Eliminates specified trailing characters or whitespaces from the right side of each element in the series or index. Non-string elements are replaced with NaN values. Input arguments: 'to_strip' (characters to remove; defaults to None which signifies whitespace). Output: A series or index with trailing characters removed from each element.",
    "class": "Series"
  },
  "pandas.Series.str.startswith": {
    "new_func": "initial_pattern_match",
    "description": "Evaluates whether the beginning of each string element corresponds with the provided pattern. The method returns an indicator for each element reflecting the presence of the pattern at the start. Input arguments: 'pat' (character sequence or tuple of strings), 'na' (default value used when an element is not a string). Output: A series or index composed of boolean values indicating the match status for each element.",
    "class": "Series"
  },
  "pandas.Series.take": {
    "new_func": "series_extract_positions",
    "description": "Retrieves elements at specified positions from a data structure. It does not consider the data's index values but uses the actual position within the data structure. Input arguments include a collection of integer indices indicating the required positions and an optional axis parameter to specify the dimension for selection. The axis can be 0 for rows or 1 for columns, although the latter is irrelevant for 1-dimensional structures. The result is an array-like structure of the same type containing the extracted elements.",
    "class": "Series"
  },
  "pandas.Series.to_csv": {
    "new_func": "series_export_delimited",
    "description": "Exports the content of a data structure to a delimited text file, typically as a CSV. It supports various parameters to customize the output, including file path, separator character, missing data representation, and optional inclusion of headers and index labels. Compression and encoding options are also available. The function can write the data structure to a file or return a string if no file path is provided.",
    "class": "Series"
  },
  "pandas.Series.to_clipboard": {
    "new_func": "copy_series_to_clipboard",
    "description": "Transfers a text representation of a data structure to the system clipboard, facilitating easy pasting into other applications such as spreadsheets. It can output in a tabular text format if the 'excel' parameter is True. The 'sep' parameter allows specifying a custom field delimiter. Additional keyword arguments are supported for further customization.",
    "class": "Series"
  },
  "pandas.Series.sum": {
    "new_func": "total_values",
    "description": "Calculates the aggregate of values along the specified dimension. It can optionally exclude missing values and consider only numerical data. The 'min_count' parameter sets the minimum number of valid values required for the operation. The function returns an aggregated scalar result.",
    "class": "Series"
  },
  "pandas.Series.to_dict": {
    "new_func": "convert_series_to_mapping",
    "description": "Transforms the data structure into a mapping of labels to values. You can specify the type of mutable mapping to be used for the output, including but not limited to a standard dictionary or a defaultdict. The result is a key-value pair representation of the data structure.",
    "class": "Series"
  },
  "pandas.Series.swaplevel": {
    "new_func": "interchange_indices",
    "description": "This method interchanges two levels in a hierarchical index of a data series. By default, the last two levels are exchanged, but specific levels can be targeted using their integer positions or names. A new series is returned with the modified index structure. If requested, the data can be duplicated, but future versions will implement a lazy copying mechanism by default. Parameters: i, j (int or str) - The positions or names of the index levels to interchange. copy (bool) - Whether to duplicate the data. Returns: A new series with the altered index hierarchy.",
    "class": "Series"
  },
  "pandas.Series.to_frame": {
    "new_func": "series_to_tabular",
    "description": "This method transforms a data series into a tabular data structure with a single column. If a name is provided, it replaces the series' name as the column label. Parameters: name (object, optional) - The label to assign to the column. Returns: A new tabular structure containing the series data.",
    "class": "Series"
  },
  "pandas.Series.to_json": {
    "new_func": "serialize_to_json",
    "description": "This method serializes a data series into a JSON-formatted string. Special considerations are applied to null values and datetime objects, which are converted to null and UNIX timestamps respectively. Various customization options for the JSON output are available, including formatting, precision, and compression. Parameters: Multiple parameters are available to customize the JSON output, including path_or_buf (str or file-like object), orient (str), date_format (str), double_precision (int), and others. Returns: If no file path is provided, a string in JSON format; otherwise, None after writing to the specified file or buffer.",
    "class": "Series"
  },
  "pandas.Series.to_hdf": {
    "new_func": "persist_to_hierarchical",
    "description": "This method saves the series data to a file in the Hierarchical Data Format (HDF5), allowing for efficient storage and retrieval of complex data collections. The method supports various options for compression, format, and indexing, enabling customization of the storage process. Parameters: path_or_buf (str or HDFStore object), key (str), mode (str), and other options related to compression, data formatting, and indexing. Returns: None. The series data is written to the specified HDF5 file.",
    "class": "Series"
  },
  "pandas.Series.to_excel": {
    "new_func": "series_export_to_spreadsheet",
    "description": "This method exports a series to a spreadsheet in an Excel file. It allows for writing to different sheets, customizing the representation of missing data, and formatting of numbers. Users can specify various parameters to control the export process. Parameters: excel_writer (path-like or ExcelWriter object), sheet_name (str), na_rep (str), float_format (str), and other options for controlling the layout and formatting in the spreadsheet. Returns: None. The series data is written to the specified Excel sheet.",
    "class": "Series"
  },
  "pandas.Series.to_latex": {
    "new_func": "series_format_to_tabular_text",
    "description": "This method transforms a series into a tabulated text format suitable for inclusion in a LaTeX document environment. It supports various customization options for table appearance, such as cell formatting, header and index inclusion, and special LaTeX features like longtable and multirow adjustments. The output can be directly integrated into a LaTeX file or saved to a separate file for inclusion with LaTeX commands. Input arguments include options for buffer, column selection, formatting preferences, and file encoding, among others. The output can be either a string or written directly to a file, depending on whether the buffer argument is provided.",
    "class": "Series"
  },
  "pandas.Series.to_list": {
    "new_func": "series_elements_to_array",
    "description": "This method converts the elements within the series to a standard Python list, with each element retaining its original scalar data type. This can include Python scalars such as strings, integers, and floats, as well as scalar types from the library like timestamps and intervals. The method returns a list containing these elements.",
    "class": "Series"
  },
  "pandas.Series.to_markdown": {
    "new_func": "series_to_bullet_points",
    "description": "This method converts the series data into a text format that is compatible with Markdown syntax. It allows for various customizations, including whether to include index labels and additional parameters for Markdown table formatting. The generated Markdown text can either be returned as a string or saved to a specified buffer. This method facilitates the representation of data for display in Markdown viewers or documentation files.",
    "class": "Series"
  },
  "pandas.Series.to_pickle": {
    "new_func": "series_serialize_to_file",
    "description": "This method serializes the series object, storing it in a binary format in a specified file path. The serialization process can utilize a variety of compression protocols and is compatible with different storage options, making it suitable for efficient long-term storage or data exchange. The method accepts parameters for the file path, compression method, serialization protocol, and options specific to the storage medium.",
    "class": "Series"
  },
  "pandas.Series.to_numpy": {
    "new_func": "series_convert_to_array",
    "description": "This method creates and returns an array representation of the series using a specified data type. It offers the option to make a copy of the data and allows for handling of missing values according to the needs of the user. The method can pass additional keyword arguments to the underlying array conversion method, supporting customization for more complex data types or extension arrays.",
    "class": "Series"
  },
  "pandas.Series.to_period": {
    "new_func": "timeframe_conversion",
    "description": "Transforms a series with date or time indices to one that uses specified time spans. This enables a change from timestamps to time-related intervals. It takes an optional frequency parameter to determine the type of time span and a boolean indicating whether to make a new copy. The outcome is a series indexed by time spans.",
    "class": "Series"
  },
  "pandas.Series.to_sql": {
    "new_func": "record_database_export",
    "description": "Transmits data contained within a series to a table in a relational database. This procedure is compatible with databases that accommodate SQLAlchemy and allows for the creation, appending, or replacement of tables. It accepts several parameters, such as the table name, database connection, transaction behavior, indexing preferences, and more. The operation may return the number of affected rows or None, depending on the insertion method utilized.",
    "class": "Series"
  },
  "pandas.Series.to_string": {
    "new_func": "textual_representation",
    "description": "Generates a textual layout of a data series, capable of writing to a provided buffer or returning a string if no buffer is specified. It allows customization of NaN representations, float formatting, and can optionally include data type, length, and series name information. The output can be truncated to a specific number of rows, with a minimum row threshold for truncation display.",
    "class": "Series"
  },
  "pandas.Series.to_timestamp": {
    "new_func": "datetime_index_cast",
    "description": "Converts a series indexed by intervals into one indexed by date and time markers, specifically at the commencement or conclusion of the interval. An optional frequency parameter defines the periodicity of the time index. The process may produce a duplicate depending on a boolean parameter. The result is a series indexed by date and time markers.",
    "class": "Series"
  },
  "pandas.Series.transform": {
    "new_func": "data_application",
    "description": "Applies a specified operation to the data within the series, producing a result with an identical axis dimension. The operation can be a function, a recognized string function name, or a combination of both in a list-like or dict-like structure. The outcome is a series of the same length as the original, and an error is raised if this condition is not met.",
    "class": "Series"
  },
  "pandas.Series.update": {
    "new_func": "refresh_values",
    "description": "Alters the calling object in-place by substituting non-null entries from the provided argument. It aligns the data based on the index labels. Input argument: other (Series or compatible object) - The data source for updating the current object's values.",
    "class": "Series"
  },
  "pandas.Series.unique": {
    "new_func": "distinct_elements",
    "description": "Retrieves an array of distinct elements from the object, maintaining their initial order of occurrence. The method employs a hashing technique and does not sort the results. Returns: An array - The distinct elements extracted.",
    "class": "Series"
  },
  "pandas.Series.unstack": {
    "new_func": "pivot_levels",
    "description": "Transforms a Series with a hierarchical index into a DataFrame by pivoting a level of the index. Inputs: level (int, str, list) - Index level(s) to pivot (default is last level), fill_value (scalar) - Value to replace missing values with, sort (bool) - Whether to sort the resulting MultiIndex columns. Returns: A DataFrame - The result of unstacking the specified levels.",
    "class": "Series"
  },
  "pandas.Series.value_counts": {
    "new_func": "tally_occurrences",
    "description": "Produces an object that tallies the frequency of unique elements, arranged in descending order of occurrence by default, and can exclude null values. Inputs: normalize (bool) - Whether to return relative frequencies, sort (bool) - Whether to sort by frequency or preserve original order, ascending (bool) - Whether to sort in ascending order, bins (int) - Optional grouping into bins for numeric data, dropna (bool) - Whether to ignore null values. Returns: An object - The frequency count of each unique element.",
    "class": "Series"
  },
  "pandas.Series.var": {
    "new_func": "dispersion_measure",
    "description": "Calculates the dispersion of the data points around their mean, normalized by N-ddof where N is the number of non-null entries. Inputs: axis (unused for Series, default 0), skipna (bool) - Whether to skip null values, ddof (int) - Delta Degrees of Freedom, numeric_only (bool) - Restricts to numeric data (not applicable for Series). Returns: A scalar or object - The variance if no level is specified.",
    "class": "Series"
  },
  "pandas.Series.values": {
    "new_func": "obtain_elements",
    "description": "Extracts the elements of the series as an array or an array-like structure, depending on the data type. Note: It is advisable to utilize the 'to_array' or 'to_array' methods for guaranteed references to the data or a structured array representation, respectively. Returns an array or an array-like object.",
    "class": "Series"
  },
  "pandas.Series.view": {
    "new_func": "reinterpret_cast",
    "description": "Generates a new object that is a reinterpretation of the series's memory block, with an optional specification of a different data type. Caution: This method is deprecated as of version 2.2.0. To change the data type without deprecation concerns, use the 'cast_dtype' method instead. The reinterpretation is subject to the constraint that the new data type maintains the same byte size to avoid misaligning the indices. Input: dtype (data type object or string) - The intended new data type for the reinterpretation. Returns a new object that shares the same data in memory.",
    "class": "Series"
  },
  "pandas.Series.xs": {
    "new_func": "extract_section",
    "description": "Extracts a specific segment from the given series or data matrix based on the provided key. Particularly useful for obtaining data from a certain level within a multi-level index structure. Inputs: key (label or tuple) - The label(s) present within the index, or partially in a multi-level index. axis (integer or string) - The axis along which the section is to be retrieved. level (object) - Specifies the levels to be considered, applicable when dealing with multi-level indices. drop_level (boolean) - If set to False, the returned object retains the same levels as the original. Outputs: A segment of the original series or matrix corresponding to the chosen index levels.",
    "class": "Series"
  },
  "pandas.Series.where": {
    "new_func": "conditional_replace",
    "description": "Substitutes values in the series where the specified condition is not satisfied. Inputs: cond (boolean series/matrix, array-like, or callable) - Determines which values to retain or replace. When False, values are replaced by those from 'other'. If callable, it should evaluate to a boolean series/matrix or array. other (scalar, series/matrix, or callable) - Provides the replacement values for where 'cond' is False. If callable, it should yield a scalar or a series/matrix. If omitted, NULL values are used for substitution. inplace (boolean) - If True, the operation modifies the data in place. axis (integer) - The alignment axis, if applicable. For series, this is redundant. level (integer) - The alignment level, if necessary. Output: The modified series, or None if operation was in-place.",
    "class": "Series"
  },
  "pandas.SparseDtype": {
    "new_func": "CompressedType",
    "description": "Specifies the data type for arrays that store data efficiently by only storing non-default values. This data type is compliant with the extension data type interface. Inputs: dtype (string, extension data type, structured array data type, or type) - The data type of the non-default values in the array. fill_value (scalar) - The value that is not stored in the array, which varies based on the specified data type. The default fill value is dependent on the data type, for instance, 0 for integers and 'NaT' for datetime-like types. Output: An instance of the compressed data type with specified characteristics.",
    "class": "SparseDtype"
  },
  "pandas.Timedelta.components": {
    "new_func": "duration_element_extract",
    "description": "Retrieves a structure similar to a named tuple that encapsulates the individual time duration units such as days, hours, minutes, seconds, milliseconds, microseconds, and nanoseconds from a time duration instance.",
    "class": "Timedelta"
  },
  "pandas.Timedelta.ceil": {
    "new_func": "duration_round_up",
    "description": "Produces a new time duration instance that is rounded upwards to the nearest increment specified by a resolution string parameter. This method adheres to the upward rounding convention commonly known as 'ceiling'. Parameters: resolution (str) - A string denoting the frequency resolution to round up to. Returns: A new time duration instance modified according to the specified resolution.",
    "class": "Timedelta"
  },
  "pandas.Timedelta.microseconds": {
    "new_func": "subsecond_portion_micro",
    "description": "Acquires the microseconds part of the time duration, which falls within the range of 0 to 999999, signifying the sub-second components that are larger than a millisecond and smaller than a second. Returns: An integer representing the microseconds component.",
    "class": "Timedelta"
  },
  "pandas.Timedelta.max": {
    "new_func": "maximum_duration",
    "description": "Indicates the upper limit for a time duration value which the system can handle, equivalent to 106751 days, 23 hours, 47 minutes, and approximately 16.854775807 seconds. Returns: The maximum time duration boundary.",
    "class": "Timedelta"
  },
  "pandas.Timedelta.nanoseconds": {
    "new_func": "subsecond_portion_nano",
    "description": "Retrieves the number of nanoseconds encapsulated in the time duration where the value is non-negative and less than one microsecond. Returns: An integer denoting the nanoseconds component.",
    "class": "Timedelta"
  },
  "pandas.Timedelta.resolution": {
    "new_func": "minimum_unit",
    "description": "Obtains the smallest representable time unit for a duration object. This minimal unit is equivalent to one nanosecond. Input and return types are not required as this represents a constant value.",
    "class": "Timedelta"
  },
  "pandas.Timedelta.round": {
    "new_func": "duration_nearest_quantum",
    "description": "Adjusts the duration object to the nearest specified temporal quantum. Input: quantum_string (str) - A string denoting the temporal granularity to which the duration should be adjusted. Output: A new duration object adjusted to the nearest specified quantum. An error will be signaled if the quantum string is not interpretable.",
    "class": "Timedelta"
  },
  "pandas.Timedelta.min": {
    "new_func": "smallest_span",
    "description": "Represents the smallest possible duration that can be represented, which is significantly negative, suggesting a large duration in the past. Input and return types are not required as this represents a constant value.",
    "class": "Timedelta"
  },
  "pandas.Timedelta.seconds": {
    "new_func": "total_seconds_count",
    "description": "Calculates the entire count of seconds encapsulated within the duration, excluding days and microseconds. Output: total_seconds (int) - The sum of all seconds contained in the duration.",
    "class": "Timedelta"
  },
  "pandas.Timedelta.isoformat": {
    "new_func": "standard_duration_notation",
    "description": "Converts the duration into a standardized string format in accordance with the international standard for duration representation. Output: formatted_duration (str) - The formatted string depicting the duration as per the standard.",
    "class": "Timedelta"
  },
  "pandas.Timedelta.floor": {
    "new_func": "minimum_interval_snap",
    "description": "Returns a new duration object snapped down to the specified frequency resolution. Supports the same frequency abbreviations as the duration constructor. Parameters: freq (string): The frequency resolution string to which the duration will snap. Returns: A new snapped duration object.",
    "class": "Timedelta"
  },
  "pandas.Timedelta.to_numpy": {
    "new_func": "duration_to_array",
    "description": "Transforms the duration into a high-precision numpy timedelta64. This is a synonymous method for converting to timedelta64. The parameters dtype and copy are present for compatibility purposes but do not influence the outcome. Returns: A timedelta64 representation of the duration.",
    "class": "Timedelta"
  },
  "pandas.Timedelta.unit": {
    "new_func": "smallest_duration_unit",
    "description": "Acquires the smallest representational unit of the duration object.",
    "class": "Timedelta"
  },
  "pandas.Timedelta.to_pytimedelta": {
    "new_func": "duration_to_standard_delta",
    "description": "Converts the duration object to a standard python datetime.timedelta object. Internally, duration objects are stored as a specialized datetime datatype. This conversion method turns them into a general object datatype. Returns: A python datetime.timedelta or an array of datetime.timedelta objects.",
    "class": "Timedelta"
  },
  "pandas.Timedelta.total_seconds": {
    "new_func": "complete_duration_in_seconds",
    "description": "Calculates the entire span of the duration in terms of seconds.",
    "class": "Timedelta"
  },
  "pandas.TimedeltaIndex.inferred_freq": {
    "new_func": "interval_guess_rhythm",
    "description": "Attempts to deduce the interval regularity as a character sequence that represents its periodicity. If unable to determine, it returns a null value. Parameters: None. Returns: string or None - The inferred interval regularity or null if undetectable.",
    "class": "TimedeltaIndex"
  },
  "pandas.TimedeltaIndex.floor": {
    "new_func": "interval_base_align",
    "description": "Executes a downward rounding of index values to conform with a specified granularity level. Arguments: freq - The granularity to round down to, must be a fixed interval like 'S' (indicative of one second). ambiguous - Strategy for handling daylight saving time transitions, with options including 'infer', boolean arrays, 'NaT', or raising an error. nonexistent - Policy for handling non-existing times due to daylight saving shifts, with options including 'shift_forward', 'shift_backward', 'NaT', timedelta, or raising an error. Returns: Index-like - An index of the same type with rounded down values. Raises: ValueError if the granularity cannot be recognized.",
    "class": "TimedeltaIndex"
  },
  "pandas.TimedeltaIndex.nanoseconds": {
    "new_func": "nano_interval_part",
    "description": "Retrieves the nanosecond component of the index values, which is a non-negative count confined to the range of 0 to less than one microsecond. Parameters: None. Returns: array - An array of integers representing the nanosecond components.",
    "class": "TimedeltaIndex"
  },
  "pandas.TimedeltaIndex.microseconds": {
    "new_func": "micro_interval_part",
    "description": "Obtains the microsecond fraction of each index value, which is a non-negative integer that is at least 0 and less than one second. Parameters: None. Returns: array - An array of integers representing the microsecond portions.",
    "class": "TimedeltaIndex"
  },
  "pandas.TimedeltaIndex.components": {
    "new_func": "interval_breakdown",
    "description": "Extracts a tabular representation of the individual time span elements of the indices. The breakdown includes days, hours, minutes, seconds, milliseconds, microseconds, and nanoseconds as columns. Parameters: None. Returns: DataFrame - A table with columns for each time component.",
    "class": "TimedeltaIndex"
  },
  "pandas.TimedeltaIndex.ceil": {
    "new_func": "time_delta_round_up",
    "description": "Rounds up each entry in the index to the nearest specified frequency level. Parameters: frequency (str or Offset) - The frequency to round up to. Must be a fixed frequency like 'S' for second. ambiguity_resolution (str or bool-array or 'NaT', default 'raise') - Strategy to resolve ambiguous times due to daylight saving transitions. nonexistence_resolution (str or timedelta, default 'raise') - Strategy to handle times that do not exist due to daylight saving time transitions. Returns: Same type as input - An index with each entry rounded up to the specified frequency.",
    "class": "TimedeltaIndex"
  },
  "pandas.TimedeltaIndex.to_pytimedelta": {
    "new_func": "to_standard_delta",
    "description": "Converts the index to an array of standard library timedelta objects. Returns: array of datetime.timedelta - Standard timedelta objects array.",
    "class": "TimedeltaIndex"
  },
  "pandas.TimedeltaIndex.to_series": {
    "new_func": "index_to_ordered_collection",
    "description": "Generates a serialized collection from the index, preserving the order. Parameters: alternative_index (Index, optional) - Index of the resulting collection. If not provided, defaults to the original one. series_name (str, optional) - Designation of the resulting collection. If not provided, inherits the name of the original index. Returns: Serialized Collection - The data type will reflect the index's entries.",
    "class": "TimedeltaIndex"
  },
  "pandas.Timestamp.as_unit": {
    "new_func": "time_as_division",
    "description": "Transforms the internal integer representation to a designated time unit. Parameters: division_unit (str) - The time unit for conversion. exact_rounding (bool, default True) - If false and conversion requires rounding, an error is raised. Returns: Adjusted Timestamp - The timestamp represented in the specified time unit.",
    "class": "Timestamp"
  },
  "pandas.Timestamp": {
    "new_func": "chronological_instant",
    "description": "Constructs an object representing a specific point in time, equivalent to python's built-in datetime. It accepts various types of temporal inputs to create a point in time that can be used in time-series data structures. Parameters: temporal_input (datetime-like, str, int, float) - The value to convert into a time point. year, month, day (int) - Numeric representations of the date. time_units (hour, minute, second, microsecond) - Numeric representations of the time, defaulting to zero. timezone_info (datetime.tzinfo, optional) - Timezone information for the time point. fractional_second (int, optional) - Nanosecond component of the time. timezone (str or timezone object) - Time zone designation. conversion_unit (str) - Unit for conversion if the input is numerical. daylight_saving_fold (int, optional) - Indicator of the occurrence during daylight saving time transitions, with 0 or 1 representing the first or second occurrence respectively. Returns: Temporal Object - An instance representing the specified point in time.",
    "class": "Timestamp"
  },
  "pandas.Timestamp.asm8": {
    "new_func": "epoch64_nanosecond_cast",
    "description": "Converts a timestamp object to its equivalent in a 64-bit integer representation based on the epoch time in nanoseconds.",
    "class": "Timestamp"
  },
  "pandas.Timestamp.ceil": {
    "new_func": "timestamp_round_up",
    "description": "Adjusts the moment to the next closest specified temporal frequency boundary. This operation is akin to rounding numbers upwards, but applied to time points. Input: freq (string) - A temporal frequency specification. ambiguous (bool or {'raise', 'NaT'}) - Policy for handling ambiguous times during daylight saving time transitions. nonexistent ({'raise', 'shift_forward', 'shift_backward', 'NaT', timedelta}) - Policy for handling times that do not exist due to daylight saving time transitions. Output: A new, adjusted timestamp.",
    "class": "Timestamp"
  },
  "pandas.Timestamp.astimezone": {
    "new_func": "timezone_transition",
    "description": "Alters the time zone reference for a timestamp without changing the actual time, effectively re-basing it in a different time zone. Input: tz (string, timezone object, or None) - The desired time zone to convert to, or None to use UTC. Output: A timestamp referenced to the new time zone.",
    "class": "Timestamp"
  },
  "pandas.Timestamp.ctime": {
    "new_func": "formatted_time_string",
    "description": "Generates a string representation of the timestamp in a traditional 'ctime' format commonly used in Unix. No parameters. Returns: A string representing the formatted time.",
    "class": "Timestamp"
  },
  "pandas.Timestamp.date": {
    "new_func": "timestamp_extract_calendar_date",
    "description": "Retrieves the calendar date component from a timestamp, discarding any time-of-day information. Returns: A standard date object with the same year, month, and day as the original timestamp.",
    "class": "Timestamp"
  },
  "pandas.Timestamp.days_in_month": {
    "new_func": "month_total_days",
    "description": "Retrieves the total count of days present within the month of a specific date instance. The outcome is an integer representing this quantity.",
    "class": "Timestamp"
  },
  "pandas.Timestamp.dst": {
    "new_func": "daylight_savings_shift",
    "description": "Acquires the daylight saving time adjustment, if any, applicable to the date instance. This adjustment can vary depending on regional daylight saving policies.",
    "class": "Timestamp"
  },
  "pandas.Timestamp.dayofyear": {
    "new_func": "annual_day_index",
    "description": "Calculates the position of the date within the year, providing the index as an integer starting from the first day of the year.",
    "class": "Timestamp"
  },
  "pandas.Timestamp.daysinmonth": {
    "new_func": "month_day_quantity",
    "description": "Yields an integer value indicating the count of days that compose the month for the given date instance.",
    "class": "Timestamp"
  },
  "pandas.Timestamp.day_name": {
    "new_func": "timestamp_weekday_label",
    "description": "Produces the name of the weekday corresponding to the date object. The language for the name can be specified and defaults to English if not provided. The output is a string representing the weekday name.",
    "class": "Timestamp"
  },
  "pandas.Timestamp.isoformat": {
    "new_func": "standardized_datetime_representation",
    "description": "Converts the datetime object to a string following the international standard representation of dates and times. The default separator between the date and time portions can be customized, and the precision of the time component can be altered to include anywhere from just the hour up to nanosecond precision. If the object includes timezone information, the offset from UTC is appended to the string. Parameters: sep (str, default 'T') - Separator between date and time elements. timespec (str, default 'auto') - Level of precision for time component. Values include 'auto', 'hours', 'minutes', 'seconds', 'milliseconds', 'microseconds', and 'nanoseconds'. Returns: str - The formatted datetime string.",
    "class": "Timestamp"
  },
  "pandas.Timestamp.is_year_end": {
    "new_func": "final_day_check",
    "description": "Evaluates whether the provided date falls on the last day of the calendar year. Returns: bool - True if the date is the final day of the year, False otherwise.",
    "class": "Timestamp"
  },
  "pandas.Timestamp.max": {
    "new_func": "maximum_possible_instant",
    "description": "Represents the furthest future datetime that can be represented, which is equivalent to '2262-04-11 23:47:16.854775807'. No parameters. Returns: Timestamp - The latest possible datetime.",
    "class": "Timestamp"
  },
  "pandas.Timestamp.isoweekday": {
    "new_func": "weekday_number",
    "description": "Calculates the numerical day of the week the datetime falls on, with Monday as 1 and Sunday as 7. No parameters. Returns: int - The number corresponding to the day of the week.",
    "class": "Timestamp"
  },
  "pandas.Timestamp.isocalendar": {
    "new_func": "week_based_date_components",
    "description": "Provides a tuple containing the year, week number, and weekday according to the ISO week date system. No parameters. Returns: namedtuple - A tuple with three components: the ISO year, ISO week number, and ISO weekday.",
    "class": "Timestamp"
  },
  "pandas.Timestamp.microsecond": {
    "new_func": "subsecond_units",
    "description": "Retrieves the sub-second time component of a temporal data point, specifically in microseconds. This attribute represents the fraction of a second that has elapsed.",
    "class": "Timestamp"
  },
  "pandas.Timestamp.min": {
    "new_func": "earliest_moment",
    "description": "Provides the earliest representable point in time for the data type, equivalent to the 21st of September, 1677 at 00:12:43.145224193.",
    "class": "Timestamp"
  },
  "pandas.Timestamp.minute": {
    "new_func": "sixtieth_of_hour",
    "description": "Extracts the minute segment from a temporal data point, which is the part that denotes the count of minutes past the hour.",
    "class": "Timestamp"
  },
  "pandas.Timestamp.month_name": {
    "new_func": "name_of_month",
    "description": "Produces the full name of the month for the given date in a specified language locale. The default language is English if no other locale is provided. Input: locale (str, optional) - Language locale code. Output: A string representing the month name.",
    "class": "Timestamp"
  },
  "pandas.Timestamp.normalize": {
    "new_func": "timestamp_reset_to_midnight",
    "description": "Adjusts a datetime object to the start of the day (00:00:00) while keeping the same time zone information.",
    "class": "Timestamp"
  },
  "pandas.Timestamp.now": {
    "new_func": "current_moment",
    "description": "Generates a new timestamp object representing the present moment, adjusted to a specified timezone if provided. Input Argument: tz (string or timezone object, optional) - The timezone to which the current time should be localized. Default is None which means the local timezone is used. Return Value: A timestamp object reflecting the present moment localized to the given timezone.",
    "class": "Timestamp"
  },
  "pandas.Timestamp.is_year_start": {
    "new_func": "inaugural_day_check",
    "description": "Checks if the timestamp corresponds to the initial day of a calendar year. Return Value: A boolean value indicating whether the date is the first day of the year or not.",
    "class": "Timestamp"
  },
  "pandas.Timestamp.replace": {
    "new_func": "substitute_components",
    "description": "Creates a new timestamp with one or more components modified according to the provided arguments. Input Arguments: year, month, day, hour, minute, second, microsecond, nanosecond (all ints, optional) - The components to be modified. tzinfo (timezone-convertible, optional) - The timezone information to apply. fold (int, optional) - Used to disambiguate times during a repeated interval. Return Value: A new timestamp with the specified fields altered.",
    "class": "Timestamp"
  },
  "pandas.Timestamp.nanosecond": {
    "new_func": "subsecond_fragment",
    "description": "Acquires the nanosecond component of the timestamp. Return Value: An integer representing the nanosecond part of the timestamp.",
    "class": "Timestamp"
  },
  "pandas.Timestamp.quarter": {
    "new_func": "fiscal_period",
    "description": "Retrieves the fiscal division of the year in which the timestamp falls. Return Value: An integer indicating which quarter of the year the timestamp is in.",
    "class": "Timestamp"
  },
  "pandas.Timestamp.round": {
    "new_func": "temporal_nearest",
    "description": "Adjusts the date-time object to the closest specified temporal resolution. Arguments include a frequency string to determine the accuracy of the adjustment, and options to handle ambiguous or non-existent times caused by daylight saving time transitions. The method will return a new date-time object adjusted to the desired accuracy.",
    "class": "Timestamp"
  },
  "pandas.Timestamp.month": {
    "new_func": "extract_period",
    "description": "Retrieves the month component as an integer from the date-time instance.",
    "class": "Timestamp"
  },
  "pandas.Timestamp.resolution": {
    "new_func": "minimal_interval",
    "description": "Represents the smallest time duration that can be represented within the date-time object, expressed as a Timedelta object equivalent to one nanosecond.",
    "class": "Timestamp"
  },
  "pandas.Timestamp.strftime": {
    "new_func": "format_to_text",
    "description": "Converts the date-time object into a string according to a specified format pattern. The method accepts a format string parameter that determines how the conversion should be performed, adhering to standard date and time representation directives.",
    "class": "Timestamp"
  },
  "pandas.Timestamp.second": {
    "new_func": "obtain_subminute_unit",
    "description": "Acquires the seconds portion of the date-time instance, returning it as an integer.",
    "class": "Timestamp"
  },
  "pandas.Timestamp.timestamp": {
    "new_func": "posix_seconds",
    "description": "Converts a given date and time to a floating-point number representing seconds since the Unix epoch.",
    "class": "Timestamp"
  },
  "pandas.Timestamp.timetuple": {
    "new_func": "localtime_structure",
    "description": "Provides a tuple representation of the instance, which is compatible with the standard library's localtime() function from the time module.",
    "class": "Timestamp"
  },
  "pandas.Timestamp.strptime": {
    "new_func": "parse_datetime",
    "description": "Intended to create a datetime instance from a string and a format, however, the method is not available. Instead, users should employ the alternative function designed for converting strings to datetime objects.",
    "class": "Timestamp"
  },
  "pandas.Timestamp.timetz": {
    "new_func": "time_with_timezone",
    "description": "Returns a time object reflecting the same time as the original instance, including timezone information if present.",
    "class": "Timestamp"
  },
  "pandas.Timestamp.to_numpy": {
    "new_func": "datetime_to_array",
    "description": "Transforms the date and time information into a NumPy datetime64 object. The parameters for data type and copying are included for syntactic compatibility, but they do not influence the outcome.",
    "class": "Timestamp"
  },
  "pandas.Timestamp.to_datetime64": {
    "new_func": "convert_to_datetime_ns_precision",
    "description": "Transforms the object into a datetime representation with nanosecond precision, based on the NumPy library's datetime64 data type. This allows for high-precision time data handling.",
    "class": "Timestamp"
  },
  "pandas.Timestamp.to_pydatetime": {
    "new_func": "transform_to_native_datetime",
    "description": "Transfers the object into a standard Python datetime structure. Optionally emits a warning when the object contains non-zero nanoseconds which can't be represented by the Python datetime type. Parameters: warn (bool, default True) - Whether to warn on nanoseconds precision loss.",
    "class": "Timestamp"
  },
  "pandas.Timestamp.to_julian_date": {
    "new_func": "timestamp_to_astro_numeric_scale",
    "description": "Calculates the astronomical numeric value corresponding to the instance's point in time, using the Julian calendar system. The reference point is the noon of January 1st, 4713 BC on the Julian calendar.",
    "class": "Timestamp"
  },
  "pandas.Timestamp.to_period": {
    "new_func": "convert_to_time_span",
    "description": "Turns the point in time into a span based on a specified frequency. This span represents the time block where the given moment falls. Parameters: freq (str, optional) - The frequency indicating the type of span to be returned.",
    "class": "Timestamp"
  },
  "pandas.Timestamp.today": {
    "new_func": "current_localized_moment",
    "description": "Retrieves the present moment's information adjusted to the specified or local time zone. This method provides the functionality to obtain the current time with time zone awareness, unlike the typical method of getting the current time without any time zone data. Parameters: tz (timezone object or str, optional) - The time zone to which the current time should be localized.",
    "class": "Timestamp"
  },
  "pandas.Timestamp.tzname": {
    "new_func": "time_zone_identifier",
    "description": "This method retrieves the designation of the time zone linked with a particular time point. It provides the common name that represents the time zone info. Input: None. Returns: String representing time zone name.",
    "class": "Timestamp"
  },
  "pandas.Timestamp.utcfromtimestamp": {
    "new_func": "universal_time_from_posix",
    "description": "This class method creates a date and time object that is timezone-aware and set to Coordinated Universal Time (UTC), based on the given POSIX timestamp value. Parameters: ts (float) - POSIX timestamp. Returns: A timezone-aware datetime object representing the given timestamp in UTC.",
    "class": "Timestamp"
  },
  "pandas.Timestamp.tz_localize": {
    "new_func": "timestamp_assign_time_zone",
    "description": "This method assigns a specific time zone to a naive datetime object or converts the object to naive local time if no time zone is specified. It handles ambiguous or nonexistent times caused by daylight saving time transitions according to specified rules. Parameters: tz (time zone object or None) - The time zone to assign. ambiguous (bool, 'NaT', or 'raise') - Specifies how to handle ambiguous times. nonexistent (str, timedelta, or 'raise') - Specifies how to handle nonexistent times. Returns: A datetime object with the new time zone context. Raises: AmbiguousTimeError or NonExistentTimeError in case of ambiguity or nonexistence, respectively.",
    "class": "Timestamp"
  },
  "pandas.Timestamp.utcnow": {
    "new_func": "current_universal_time",
    "description": "This class method yields a new datetime object that represents the current day and time in UTC. Input: None. Returns: A datetime object in UTC.",
    "class": "Timestamp"
  },
  "pandas.Timestamp.utcoffset": {
    "new_func": "utc_difference",
    "description": "This method calculates the time difference between the stored datetime object and UTC. Input: None. Returns: A timedelta object representing the UTC offset.",
    "class": "Timestamp"
  },
  "pandas.Timestamp.unit": {
    "new_func": "time_label_denotation",
    "description": "Retrieves the abbreviated label linked with the time resolution of the object.",
    "class": "Timestamp"
  },
  "pandas.Timestamp.value": {
    "new_func": "epoch_integral",
    "description": "Obtains the numerical representation of the timestamp, typically in a format that counts the time elapsed from a particular epoch.",
    "class": "Timestamp"
  },
  "pandas.Timestamp.weekday": {
    "new_func": "day_of_week_index",
    "description": "Determines the index corresponding to the day of the week for the given date instance. The index starts with 0 for Monday and ends with 6 for Sunday.",
    "class": "Timestamp"
  },
  "pandas.Timestamp.week": {
    "new_func": "timestamp_annual_week_sequence",
    "description": "Calculates the sequence number of the week within the year to which the date belongs. The outcome is an integer value.",
    "class": "Timestamp"
  },
  "pandas.UInt16Dtype": {
    "new_func": "unsigned_short_integer_type",
    "description": "Defines a data type for storing 16-bit unsigned integers, employing a specific placeholder for missing entries instead of the standard missing value indication used in floating-point arrays.",
    "class": "UInt16Dtype"
  },
  "pandas.UInt32Dtype": {
    "new_func": "PosInt32Type",
    "description": "Defines a data type for positive 32-bit integers that extends the base integer type. The absence of data is indicated by a specific missing value token, different from the standard NaN.",
    "class": "UInt32Dtype"
  },
  "pandas.Timestamp.year": {
    "new_func": "AnnualExtraction",
    "description": "Extracts the calendar year component from a timestamp as an integer value.",
    "class": "Timestamp"
  },
  "pandas.Timestamp.weekofyear": {
    "new_func": "IsoWeekRetriever",
    "description": "Obtains the ISO week number within the given year from a timestamp. The result is an integer indicating the week's position.",
    "class": "Timestamp"
  },
  "pandas.Timestamp.utctimetuple": {
    "new_func": "ZuluTimeStructure",
    "description": "Transforms a timestamp into a structured time tuple in Coordinated Universal Time (UTC) format, suitable for compatibility with the time module's functions.",
    "class": "Timestamp"
  },
  "pandas.UInt64Dtype": {
    "new_func": "PosInt64Type",
    "description": "Defines a data type for positive 64-bit integers that extends the base integer type. This type utilizes a specialized missing value indication distinct from the standard NaN.",
    "class": "UInt64Dtype"
  },
  "pandas.UInt8Dtype": {
    "new_func": "UnsignedTinyIntegerType",
    "description": "Represents an extension data type for 8-bit unsigned integers. It employs a specific sentinel value to represent missing data, which differs from the traditional floating-point NaN.",
    "class": "UInt8Dtype"
  },
  "pandas.api.interchange.from_dataframe": {
    "new_func": "ConstructTabularStructure",
    "description": "Assembles a tabular data structure from any object that adheres to the tabular data interchange protocol, allowing for a memory copy if necessary. Input arguments: dfDataFrameXchg (Object with __dataframe__ method) - The data provider adhering to the interchange protocol. allow_copy (boolean) - A flag indicating whether data copying is permissible. Defaults to True. Return value: A tabular data structure equivalent to the input.",
    "class": "api"
  },
  "pandas.api.types.is_bool_dtype": {
    "new_func": "VerifyLogicalType",
    "description": "Assesses if a given array or data type descriptor corresponds to a logical data type. Input arguments: arr_or_dtype (array-like or dtype) - The entity to evaluate. Returns: A boolean indicating if the input represents a logical data type.",
    "class": "api"
  },
  "pandas.api.types.infer_dtype": {
    "new_func": "DeduceElementType",
    "description": "Determines the descriptive label for the type of individual or collection of values. Input arguments: value (scalar, list, array-like, or data structure) - The value(s) whose type is to be identified. skipna (boolean) - Whether to disregard null values during type determination. Default is True. Returns: A string categorizing the prevalent type among the input data, which could range from various numeric and string types to date/time and more complex data structures. May raise a TypeError if the input is array-like but the type cannot be ascertained.",
    "class": "api"
  },
  "pandas.api.types.is_bool": {
    "new_func": "AssertLogicalValue",
    "description": "Determines if the provided entity is of a logical value type. Returns: A boolean confirming the logical nature of the entity.",
    "class": "api"
  },
  "pandas.api.types.is_float": {
    "new_func": "check_decimal_scalar",
    "description": "Evaluates if the specified object is a decimal number type. It returns a truth value indicating the evaluation result. Input: obj (any) - An object to be evaluated. Output: A boolean indicating if the object is a decimal number type.",
    "class": "api"
  },
  "pandas.api.types.is_float_dtype": {
    "new_func": "verify_decimal_array_type",
    "description": "Assesses if the given array or type specification corresponds to a decimal number data type. Input: arr_or_dtype (array-like or data type) - The entity to be inspected. Output: A boolean indicating whether the entity is of a decimal number data type.",
    "class": "api"
  },
  "pandas.api.types.is_hashable": {
    "new_func": "check_immutable_identity",
    "description": "Determines the ability of an object to be used as a dictionary key or set member by checking if it can be hashed without raising an exception. Input: obj (any) - The object to inspect. Output: A boolean indicating if the object can be hashed.",
    "class": "api"
  },
  "pandas.api.types.is_file_like": {
    "new_func": "assess_streamable_interface",
    "description": "Inspects whether the input adheres to the interface conventions of a streamable object, which includes the presence of read and/or write methods and the capability to be iterated over. Input: obj (any) - The object to be evaluated. Output: A boolean indicating if the object possesses streamable attributes.",
    "class": "api"
  },
  "pandas.api.types.is_int64_dtype": {
    "new_func": "validate_64bit_integer_type",
    "description": "Scrutinizes the specified array or data type definition to confirm if it matches a 64-bit integer data type. Note: This function is planned for deprecation. Input: arr_or_dtype (array-like or data type) - The candidate for verification. Output: A boolean indicating if the entity is a 64-bit integer data type.",
    "class": "api"
  },
  "pandas.arrays.ArrowExtensionArray": {
    "new_func": "ChunkedArrowArray",
    "description": "Constructs an experimental array structure backed by a PyArrow ChunkedArray. This class is intended for advanced users who require integration with Arrow data structures. Users should exercise caution as this array type is experimental and subject to change without notice. A PyArrow Array or ChunkedArray must be provided during instantiation. The resulting array object is returned upon creation. Parameters: values (pyarrow.Array or pyarrow.ChunkedArray) - The Arrow array to be used. Returns: A new array instance representing an Arrow-backed data structure.",
    "class": "arrays"
  },
  "pandas.api.types.is_timedelta64_ns_dtype": {
    "new_func": "check_ns_timedelta_dtype",
    "description": "Validates if the input is specifically a time delta type with nanosecond precision. Unlike broader checks, this function is strict and will not recognize general time delta types. It is useful for precise type validation in time-sensitive contexts. Parameters: arr_or_dtype (array-like or dtype) - The input to be checked for nanosecond precision time delta type. Returns: A boolean indicating whether the input matches the nanosecond precision time delta type.",
    "class": "api"
  },
  "pandas.arrays.FloatingArray": {
    "new_func": "NullableFloatSeries",
    "description": "Constructs an experimental series to hold floating point numbers, which may include optional missing values. This series uses two distinct arrays to manage data and indicate missing values. Users should be aware that this series is experimental and may undergo changes, particularly in how it differentiates between 'NaN' and missing values (NA). Parameters: values (numpy.array) - A one-dimensional array of floating point numbers. mask (numpy.array) - A one-dimensional boolean array indicating missing data. copy (bool, default False) - Whether to create a copy of the arrays. Returns: An array-like object that represents a series of floating point values with optional missing data.",
    "class": "arrays"
  },
  "pandas.arrays.SparseArray": {
    "new_func": "CompactArray",
    "description": "Creates an array that stores data efficiently by only keeping track of non-redundant elements. The space-saving design is achieved by not storing repeated values, which are instead represented by a specified fill value. This array type is beneficial for data with many identical elements. Multiple parameters allow customization of the storage and representation of the sparse data. Parameters: data (array-like or scalar) - The dense array of values to convert into a sparse representation. sparse_index (SparseIndex, optional), fill_value (scalar, optional), kind (str), dtype (np.dtype or SparseDtype, optional), copy (bool, default False). Returns: A new array instance optimized for sparse data storage.",
    "class": "arrays"
  },
  "pandas.arrays.TimedeltaArray": {
    "new_func": "DurationSeries",
    "description": "Provides a specialized array structure for holding durations of time, in an experimental phase. This array type focuses solely on time deltas and is subject to potential changes in its API. It currently accepts only nanosecond-resolution time deltas. Parameters: values (array-like) - The data representing time durations. dtype (numpy.dtype, optional) - The data type, currently limited to nanosecond-resolution time deltas. freq (Offset, optional), copy (bool, default False) - Whether to copy the data. Returns: An array-like object specialized for time duration data.",
    "class": "arrays"
  },
  "pandas.arrays.IntervalArray": {
    "new_func": "ClosedRangeCollection",
    "description": "Constructs a one-dimensional array-like object representing a collection of ranges that can be either open or closed on either end. These intervals can encompass dates, times, or numeric boundaries. The construction of this collection ensures the validity of the intervals based on the provided parameters. Parameters: data (array-like): A sequence containing interval objects to be included in the collection. closed (str, optional): Specifies which ends of the intervals are closed. dtype (optional): The desired data type of the interval endpoints. If not provided, it will be inferred from the data. copy (bool, optional): Indicates whether to create a copy of the input data. verify_integrity (bool, optional): Whether to check the validity of the interval data. Returns: A new array-like collection of intervals.",
    "class": "arrays"
  },
  "pandas.arrays.IntegerArray": {
    "new_func": "OptionalIntegers",
    "description": "Represents an array of integers that can optionally contain missing entries, denoted by a specific missing value placeholder. The array is composed of two underlying arrays: one for the integer values and another indicating the presence of missing entries. Parameters: values (numpy.array): A one-dimensional array of integer values. mask (numpy.array): A one-dimensional boolean array indicating the positions of missing entries. copy (bool, optional): Whether to duplicate the input arrays. Returns: An array object capable of storing integer values with optional missing entries.",
    "class": "arrays"
  },
  "pandas.bdate_range": {
    "new_func": "BusinessDaysSpan",
    "description": "Generates a series of dates spaced according to a specified frequency, with an emphasis on weekdays typically observed as business days. The series can be customized to accommodate specific start and end points, total periods, time zones, and exclusion of certain dates such as holidays. Parameters: start (str or datetime-like, optional): The beginning date of the series. end (str or datetime-like, optional): The ending date of the series. periods (int, optional): The total number of dates to generate. freq (str or datetime.timedelta-like, optional): The interval between dates, defaulting to business days. tz (str, optional): The time zone for the dates. normalize (bool, optional): Adjusts the start and end dates to midnight. name (str, optional): An identifier for the resulting series. weekmask (str, optional): A mask to specify which days of the week are considered business days. holidays (list-like, optional): Specific dates to be excluded as business days. inclusive (str, optional): Determines if the start and end dates are inclusive. Returns: An index object representing a sequence of dates.",
    "class": "main"
  },
  "pandas.crosstab": {
    "new_func": "FactorFrequencyGrid",
    "description": "Computes a grid that summarizes the occurrence of combinations of two or more categorical variables. This grid can be further augmented with additional values and aggregation functions to compute more complex summaries. Parameters: index (array-like or list): Categories or groupings for the rows. columns (array-like or list): Categories or groupings for the columns. values (array-like, optional): Values to aggregate, requiring an aggregation function. rownames (sequence, optional): Names corresponding to the row categories. colnames (sequence, optional): Names corresponding to the column categories. aggfunc (function, optional): Function used to aggregate the values. margins (bool, optional): Whether to include subtotal margins. margins_name (str, optional): The label for the subtotal margins when included. dropna (bool, optional): Exclude columns with all missing values. normalize (bool or str, optional): Normalize the values by the overall sum or by rows or columns. Returns: A tabular summary of the frequency or aggregation results.",
    "class": "main"
  },
  "pandas.arrays.PeriodArray": {
    "new_func": "TemporalElementSeries",
    "description": "Creates an array-like structure designed to store temporal elements, specifically periods, which are spans of time represented by a starting point and a frequency. This structure is typically used for time series data that requires alignment based on temporal intervals. Parameters: values (array-like): The period data to be stored, which can be an array of period objects or integer ordinals. dtype (optional): An instance specifying the desired temporal data type and frequency. freq (str or DateOffset, optional): The frequency of the periods within the array. copy (bool, optional): Specifies whether to copy the input data. Returns: An array-like object specialized in handling temporal period data.",
    "class": "arrays"
  },
  "pandas.factorize": {
    "new_func": "enumerate_distinct_elements",
    "description": "Assigns a unique integer code to each distinct element in a given sequence, effectively categorizing the input values. It returns an array of these codes alongside the array of unique elements. The method can handle missing values as a special case if desired and allows for an optional sorting of the unique elements. Parameters: values (sequence): The sequence to encode. sort (bool, default False): Whether to sort the unique values. use_na_sentinel (bool, default True): If True, missing values are marked by -1. size_hint (int, optional): A hint to the size of the hash table used in encoding. Returns: A tuple with two elements; the first is an array of integer codes, and the second is an array of the unique values from the input sequence.",
    "class": "main"
  },
  "pandas.from_dummies": {
    "new_func": "decode_dummy_variables",
    "description": "Converts a DataFrame with binary indicator variables (also known as 'dummy variables') back into its original categorical representation. This reverse operation is useful for data analysis after categorical variables have been transformed for machine learning models. Parameters: data (DataFrame): The DataFrame containing the dummy variables. sep (str, optional): The separator used in the dummy column names. default_category (optional): The implied category for rows where all dummy indicators are 0. Returns: A DataFrame with the original categorical data. Raises exceptions for NA values, mismatched separators, missing categories for prefixes, multiple category assignments for a row, or lack of category assignment when no default is provided.",
    "class": "main"
  },
  "pandas.infer_freq": {
    "new_func": "deduce_temporal_frequency",
    "description": "Determines the most probable interval frequency of datetime or timedelta values within an index. This function is useful when working with time series data to understand the underlying periodicity. Parameters: index (DatetimeIndex, TimedeltaIndex, Series, or array-like): The data set from which to infer the frequency. Returns: A string representing the deduced frequency or None if the frequency cannot be determined. Raises a TypeError if the index is not datetime-like or a ValueError if there are insufficient values to deduce a frequency.",
    "class": "main"
  },
  "pandas.interval_range": {
    "new_func": "generate_intervals",
    "description": "Creates an index of intervals at a specified frequency, which can be useful for binning and segmenting data. The intervals can be numerical ranges or date/time spans. Parameters: start (optional): The beginning value for the range of intervals. end (optional): The ending value for the range of intervals. periods (int, optional): The total number of intervals to generate. freq (optional): The length or frequency of each interval. name (str, optional): The name given to the resulting object. closed (str, default 'right'): The inclusivity of the interval bounds. Returns: An IntervalIndex consisting of the generated intervals.",
    "class": "main"
  },
  "pandas.io.formats.style.Styler.to_excel": {
    "new_func": "export_styled_to_sheet",
    "description": "Transfers the styled data to a designated Excel sheet, allowing for customization of the output file. This method can target specific sheets within an Excel file and supports various formatting options. Parameters: excel_writer (path-like, file-like, or ExcelWriter object): The target file path or ExcelWriter object. sheet_name (str, default 'Sheet1'): The sheet name to write to. na_rep (str, default ''): Representation for missing data. Other parameters control formatting aspects like floating point format, specified columns, headers, starting row/column, cell merging, and more. Returns: None, but the Excel file is written or modified with the styled data. Raises exceptions for invalid input types, data, or arguments.",
    "class": "io"
  },
  "pandas.get_dummies": {
    "new_func": "categorical_to_indicators",
    "description": "Transforms categorical variables within an array-like structure into a set of binary variables, also known as indicator variables. This method creates a new variable for each unique category present in the original data. The resulting binary variables indicate the presence (1) or absence (0) of each category. When dealing with a tabular structure, the original variable's name is prefixed before each new binary variable's name to maintain clarity. Input arguments include the original data, optional prefixes for the new variables, an option to include a binary variable to represent missing values, a list of specific columns to transform, a choice between dense or sparse representation, and whether to drop the first binary variable to avoid redundancy. The output is a tabular structure with the newly created binary variables.",
    "class": "main"
  },
  "pandas.io.json.build_table_schema": {
    "new_func": "construct_schema_blueprint",
    "description": "Produces a schema representation for a given dataset in a dictionary format. The generated schema includes details about the data's structure and can be used to communicate the data frame's format. Input parameters include the dataset itself, a boolean determining whether the dataset's index should be included, a primary key specification, and a version indicator. The output is a schema dictionary detailing the structure and composition of the dataset.",
    "class": "io"
  },
  "pandas.io.formats.style.Styler.to_html": {
    "new_func": "render_to_html",
    "description": "Exports a styled tabular object to HTML format, enabling visualization with CSS styling. It accepts various parameters to customize the output, such as the destination buffer, unique table identifier, table attributes, sparsity options, header styling, caption, maximum number of rows and columns, character encoding, and the choice to generate full HTML document structure. The function returns either a string containing the HTML or None if the output is written to a buffer.",
    "class": "io"
  },
  "pandas.io.stata.StataReader.data_label": {
    "new_func": "extract_dataset_label",
    "description": "Retrieves the descriptive label attached to a dataset within a Stata file. This label typically contains a brief summary or title for the dataset. No input parameters are required. The function simply returns the descriptive string.",
    "class": "io"
  },
  "pandas.io.formats.style.Styler.to_latex": {
    "new_func": "export_to_latex_format",
    "description": "Facilitates the conversion of a styled tabular object into LaTeX format, which is widely used for typesetting scientific documents. Numerous options are available to tailor the LaTeX table's appearance, including column formatting, table positioning, rule customization, labels, captions, sparsity adjustments, text alignment in hierarchical indexes, and compatibility with the siunitx LaTeX package. The function can return the LaTeX code as a string or write it directly to a file or buffer.",
    "class": "io"
  },
  "pandas.io.stata.StataWriter.write_file": {
    "new_func": "export_dataframe_to_stata",
    "description": "Saves the data structure to a file in Stata dta format, allowing for compatibility with Stata statistical software.",
    "class": "io"
  },
  "pandas.io.stata.StataReader.value_labels": {
    "new_func": "fetch_coded_labels",
    "description": "Provides a mapping between each variable and its corresponding categorical codes and labels, structured as a nested dictionary. Returns: A dictionary associating variable names with their codes and labels.",
    "class": "io"
  },
  "pandas.isnull": {
    "new_func": "detect_absent_values",
    "description": "Determines the presence of absent data elements in an input. This operation can be performed on various types of data structures including scalars and arrays. It returns a boolean scalar or an array composed of boolean values, each representing whether a data point is absent.",
    "class": "main"
  },
  "pandas.json_normalize": {
    "new_func": "flatten_json_structure",
    "description": "Transforms a JSON object into a two-dimensional tabular structure. It can process complex, nested data and convert it into a format suitable for tabular analysis. Arguments include the JSON data, paths for records, metadata, prefix options, error handling configurations, a separator for nested records, and the maximum level of depth to normalize. It outputs a two-dimensional data structure.",
    "class": "main"
  },
  "pandas.lreshape": {
    "new_func": "wide_to_long_transformation",
    "description": "Converts data from wide format to long format, effectively performing the opposite of a pivot. It uses a dictionary that maps new column names to lists of existing column names that will be combined into the new columns. Arguments include the wide-format data structure, the mapping dictionary, and an option to exclude all-NaN columns. The output is a transformed data structure.",
    "class": "main"
  },
  "pandas.melt": {
    "new_func": "unstack_dataframe",
    "description": "This procedure transforms a dataset from a wide to a narrow shape, optionally maintaining a subset of columns as identifiers. It effectively transposes certain columns into rows, creating a new pair of columns representing the transposed variable names and their corresponding values. Parameters: id_vars (scalar, tuple, list, or array, optional) - Columns to retain as identifier variables. value_vars (scalar, tuple, list, or array, optional) - Columns to transform. If not provided, all non-identifier columns are used. var_name (scalar, default None) - Label for the new 'variable' column. If omitted, the default is the existing column names or 'variable'. value_name (scalar, default 'value') - Label for the new 'value' column. col_level (scalar, optional) - If columns have multiple levels, specifies which level to use. ignore_index (bool, default True) - If True, the original index is not transferred to the output. If False, the original index is maintained. Index labels may be duplicated as needed. Returns: DataFrame - The reshaped DataFrame with a narrow format.",
    "class": "main"
  },
  "pandas.isna": {
    "new_func": "identify_absence",
    "description": "This method checks for missing or absent data within an input object, which can be a scalar or collection of values. It identifies elements that are not available, such as NaN for numerical data, None or NaN for object arrays, and NaT for datetime-like data. Parameters: obj (scalar or array-like) - The input to check for absent values. Returns: bool or array-like of bool - For a single value, returns a boolean indicating if it is missing. For a collection, returns an array of booleans indicating the absence status of each element.",
    "class": "main"
  },
  "pandas.io.stata.StataReader.variable_labels": {
    "new_func": "label_retriever",
    "description": "Retrieves a mapping that associates each variable with its respective label from the dataset. Returns: dict - A dictionary where keys are variable names and values are labels.",
    "class": "io"
  },
  "pandas.merge_asof": {
    "new_func": "approximate_combiner",
    "description": "Executes a proximity-based joining operation between two sorted datasets based on a common key. This method prioritizes the closest match of keys within a specified tolerance rather than exact key matches. It supports different searching directions such as backward, forward, and nearest to find the most appropriate pairing for each entry from the first dataset. Parameters: left (DataFrame or named Series) - The left dataset to merge. right (DataFrame or named Series) - The right dataset to merge. on (label) - The key field for merging. left_on (label) - The key field in the left dataset. right_on (label) - The key field in the right dataset. left_index/right_index (bool) - Whether to use the index from the left/right dataset as the merge key. by (column name or list of column names) - Column(s) to match before the merge. suffixes (2-length sequence) - Suffixes to apply to overlapping columns. tolerance (int or Timedelta, optional) - Range within which to search for the closest match. allow_exact_matches (bool) - Whether to allow exact key matches. direction ('backward', 'forward', 'nearest') - The direction to search for the closest key. Returns: DataFrame - The merged dataset with the closest matches based on the key distance.",
    "class": "main"
  },
  "pandas.merge": {
    "new_func": "dataframe_combiner",
    "description": "Combines two datasets or named Series using a specified join method akin to SQL join operations. It aligns data based on common columns or index levels, preserving the specified order and handling overlaps and key null values uniquely. Parameters: left (DataFrame or named Series) - The left dataset for merging. right (DataFrame or named Series) - The right dataset for merging. how ({'left', 'right', 'outer', 'inner', 'cross'}) - The type of join operation to apply. on (label or list) - Names of the columns or index levels to join on. left_on/right_on (label or list, or array-like) - Names of the columns or index levels to join on in the left/right dataset. left_index/right_index (bool) - Whether to use the index from the left/right dataset as the join keys. sort (bool) - Whether to sort the join keys in the result. suffixes (list-like) - Sequence of suffixes for overlapping column names. copy (bool) - If False, avoid copying data if possible. indicator (bool or str) - If True, adds a column indicating the source of each row. validate (str, optional) - Specifies the type of merge to validate. Returns: DataFrame - A DataFrame resulting from the merge operation.",
    "class": "main"
  },
  "pandas.merge_ordered": {
    "new_func": "sequential_combiner",
    "description": "Executes a join operation on two datasets with a focus on maintaining the sequence of the data, such as time series. It allows for optional methods to fill in missing values. One can also perform a merge by grouping the data based on specified keys. Parameters: left (DataFrame or named Series) - Data to merge on the left side. right (DataFrame or named Series) - Data to merge on the right side. on (label or list) - Column names to join on which must be present in both datasets. left_on (label or list, or array-like) - Column names or vectors for join key in left dataset. right_on (label or list, or array-like) - Column names or vectors for join key in right dataset. left_by (column name or list of column names) - Grouping columns for the left dataset for piecewise merging. right_by (column name or list of column names) - Grouping columns for the right dataset for piecewise merging. fill_method ({'ffill', None}) - Method to interpolate missing data. suffixes (list-like) - Sequence of length 2 indicating the suffixes for overlapping columns. how ({'left', 'right', 'outer', 'inner'}) - Type of join operation to perform. Returns: DataFrame - The result of the merging operation.",
    "class": "main"
  },
  "pandas.notnull": {
    "new_func": "validity_checker",
    "description": "Checks for the presence of valid (non-missing) entries within an array-like structure. This operation is applicable to various types of data including numbers, objects, and date/time like values. Parameters: obj (array-like or object value) - The input to inspect for validity. Returns: bool or array-like of bool - For a single value input, a boolean is returned. For an array input, an array of booleans is returned indicating the validity of each entry.",
    "class": "main"
  },
  "pandas.period_range": {
    "new_func": "temporal_sequence_generator",
    "description": "Generates a range of time periods at a specified frequency. This sequence can be specified with a start and end date, or a fixed number of periods. Parameters: start (str, datetime, date, Timestamp, or period-like) - The beginning of the range. end (str, datetime, date, Timestamp, or period-like) - The end of the range. periods (int) - The total number of time periods to produce. freq (str or DateOffset) - The interval between each period. name (str) - The label for the resulting index. Returns: PeriodIndex - An index composed of the generated periods.",
    "class": "main"
  },
  "pandas.notna": {
    "new_func": "non_absence_validator",
    "description": "Identifies and signals the entries in an input that are not absent, i.e., not missing or null. This function is suitable for a variety of data types including numeric and object arrays, as well as date/time like data. Parameters: obj (array-like or object value) - The input to check for non-absence. Returns: bool or array-like of bool - For individual inputs, a single boolean is returned. For array inputs, a corresponding array of booleans is provided, indicating the presence of non-absent values.",
    "class": "main"
  },
  "pandas.pivot": {
    "new_func": "dataframe_reshaper",
    "description": "Transforms the structure of a dataset based on unique values from specified columns. This operation reorganizes data to create a 'pivot' like table without aggregating data. When multiple values exist for certain combinations, the result will have a hierarchical index. Parameters: data (DataFrame) - The dataset to transform. columns (str, object, or list) - Column(s) whose unique values will become the columns of the new dataset. index (str, object, or list, optional) - Column(s) whose unique values will become the index of the new dataset. values (str, object, or list, optional) - Column(s) to populate the new dataset. If not specified, remaining columns are used. Returns: DataFrame - The newly structured dataset. Raises: ValueError - When there are duplicate combinations in the specified index/columns without aggregation.",
    "class": "main"
  },
  "pandas.plotting.autocorrelation_plot": {
    "new_func": "lagged_correlation_chart",
    "description": "Generates a graphical representation of a variable's correlation with itself across different time lags. This visualization is commonly used in signal processing and time series analysis to detect repeating patterns or the presence of a periodic signal. Parameters: series (Series) - The time series data to analyze. ax (matplotlib axis object, optional) - The plot axis to draw on. **kwargs - Additional keyword arguments to pass to the underlying matplotlib plot function. Returns: Axes object - The plot's axes.",
    "class": "plotting"
  },
  "pandas.pivot_table": {
    "new_func": "reshape_and_aggregate_data",
    "description": "Constructs a summarized table from detailed data, similar to the functionality provided by spreadsheet software. It reorganizes the data, grouping it based on column keys, and applies aggregation functions to summarize values. Parameters: data (DataFrame) - The data to be summarized. values (list-like or scalar, optional) - The values to aggregate. index (column, Grouper, array, or list) - The keys for the rows of the summary table. columns (column, Grouper, array, or list) - The keys for the columns of the summary table. aggfunc (function, list, dict) - The function(s) used for aggregation. fill_value (scalar, optional) - The value used to replace missing data. margins (bool, default: False) - Adds subtotal rows/columns if True. dropna (bool, default: True) - Exclude columns with all NaN values. margins_name (str) - The name for the subtotal rows/columns. observed (bool) - Determines if only observed values for categorical groupers should be shown. sort (bool) - Indicates if the result should be sorted. Returns: DataFrame - A table with hierarchical indices and aggregated data.",
    "class": "main"
  },
  "pandas.plotting.boxplot": {
    "new_func": "quartile_range_visualization",
    "description": "Creates a visual summary of one or more sets of numerical data through their quartiles, highlighting the median, interquartile range, and potential outliers. This representation is useful for comparing distributions between several groups or datasets. Parameters: data (DataFrame) - The dataset containing the variables to be visualized. column (str or list, optional) - The specific dataset columns to be summarized. by (str or array-like, optional) - Columns to group data by before plotting. ax (matplotlib axes object, optional) - The axes to plot on. fontsize (float or str) - Size of the text labels. rot (float) - Rotation angle of labels. grid (bool) - Show grid lines if True. figsize (tuple) - Size of the figure. layout (tuple, optional) - The layout of subplots (rows, columns). return_type ('axes', 'dict', 'both', or None) - The type of object to return. **kwargs - Additional keyword arguments for matplotlib boxplot. Returns: Various - The type of returned object depends on return_type.",
    "class": "plotting"
  },
  "pandas.plotting.deregister_matplotlib_converters": {
    "new_func": "unregister_custom_formatters",
    "description": "Reverts modifications made to the matplotlib registry by removing formatters and converters specific to dataframe types. This function is intended to restore the registry to its state prior to customization for compatibility with matplotlib defaults. Parameters: None. Returns: None - The function alters the registry state but does not return any value.",
    "class": "plotting"
  },
  "pandas.plotting.parallel_coordinates": {
    "new_func": "multidimensional_attribute_display",
    "description": "Produces a line plot to visualize multi-dimensional categorical data. Each line represents a sample, with its values across various categories or features, enabling the detection of patterns and clustering. Parameters: frame (DataFrame) - The data containing the attributes to plot. class_column (str) - The name of the column with class information. cols (list, optional) - Specific columns to include in the plot. ax (matplotlib axis, optional) - The axis object to plot on. color (list or tuple, optional) - Colors to represent different classes. use_columns (bool) - Whether columns should be used as x-ticks. xticks (list or tuple, optional) - Specific values for x-ticks. colormap (str or colormap, optional) - Color map for the lines. axvlines (bool) - Whether to add vertical lines at each x-tick. axvlines_kwds (dict, optional) - Options for the vertical lines. sort_labels (bool) - Whether to sort the class labels. **kwargs - Additional plotting options. Returns: Axes object - The plot's axes.",
    "class": "plotting"
  },
  "pandas.plotting.radviz": {
    "new_func": "circular_dimension_plotter",
    "description": "Visualizes high-dimensional data on a two-dimensional, circular layout where each variable is allocated equidistantly along the circumference. Points are plotted within the circle based on their values across the variables, with proximity indicating correlation. This technique is useful for interpreting the relative significance of each dimension in a balanced manner. Parameters: frame (DataFrame) - Data to visualize. class_column (str) - Column denoting data categories. ax (matplotlib.axes.Axes, optional) - The axes to which the plot is added. color (list[str] or tuple[str], optional) - Colors for each category. colormap (str or matplotlib.colors.Colormap, optional) - Colormap for selecting colors. **kwds - Additional keyword arguments for scatter plot. Returns: matplotlib.axes.Axes - The axes object with the plot.",
    "class": "plotting"
  },
  "pandas.plotting.table": {
    "new_func": "tabular_visual_representation",
    "description": "Generates a visual representation of tabular data as a table in a plotting axis. Parameters: ax (matplotlib.axes object) - The plotting area for the table. data (DataFrame or Series) - The data to display in the table. **kwargs - Additional keyword arguments for table customization. Returns: matplotlib.table - The generated table within the plotting area.",
    "class": "plotting"
  },
  "pandas.qcut": {
    "new_func": "quantile_slicer",
    "description": "Segments a one-dimensional array into intervals with approximately equal frequencies, based on quantiles. The intervals are useful for transforming continuous variables into categorical variables. Parameters: x (1d array or Series) - The data to be binned. q (int or list-like of float) - The number of quantiles or specific quantiles. labels (array, optional) - Labels for the resulting categories. retbins (bool, optional) - Whether to return the bin edges. precision (int, optional) - Precision for bin labels. duplicates ({'raise', 'drop'}, optional) - How to handle non-unique bin edges. Returns: out (Categorical or Series or array of integers) - The binned data. bins (array of floats, optional) - The edges of the bins (returned if retbins is True).",
    "class": "main"
  },
  "pandas.read_clipboard": {
    "new_func": "clipboard_to_frame_converter",
    "description": "Retrieves text data from the system clipboard and converts it into a structured data format. It interprets the clipboard contents in a manner similar to CSV file parsing. Parameters: sep (str, default '\\s+') - Delimiter for separating data fields. dtype_backend ({'numpy_nullable', 'pyarrow'}, optional) - Specifies the backend data type for the resulting structure. **kwargs - Additional arguments as per CSV reading functionality. Returns: DataFrame - The structured interpretation of clipboard content.",
    "class": "main"
  },
  "pandas.plotting.scatter_matrix": {
    "new_func": "multi_variable_correlation_grid",
    "description": "Creates a grid of plots illustrating the relationships between each pair of variables in the given data. The grid's diagonal can display a histogram or kernel density estimate of each variable. Parameters: frame (DataFrame) - Data containing variables to plot. alpha (float, optional) - Opacity level for the plots. figsize ((float, float), optional) - Size of the figure. ax (matplotlib.axis object, optional) - Specific axis to draw the grid on. grid (bool, optional) - Whether to display a grid. diagonal ({'hist', 'kde'}) - Type of plot for the diagonal. marker (str, optional) - Marker type for the scatter plots. density_kwds (keywords, optional) - Arguments for the kernel density plot. hist_kwds (keywords, optional) - Arguments for the histogram plot. range_padding (float, optional) - Padding for the axis range. **kwargs - Additional arguments for the scatter plot. Returns: numpy.array - An array of axes with the correlation plots.",
    "class": "plotting"
  },
  "pandas.read_hdf": {
    "new_func": "extract_hierarchical_data",
    "description": "Retrieves structured data from a specified file using the Hierarchical Data Format (HDF). This function allows you to selectively extract data based on specific criteria, with support for partial reading through row selection. Parameters: path_or_buf (str or path object) - File path or object with HDF data. key (str, optional) - Identifier for the group in the file. mode (str) - Access mode for the file, default is 'r' for read-only. where (list, optional) - Conditions for the data extraction. start (int, optional) - Row number to start reading from. stop (int, optional) - Row number to end reading at. columns (list, optional) - Specific column names to extract. iterator (bool) - Whether to return an iterator. chunksize (int, optional) - Number of rows per chunk to read. kwargs - Additional arguments passed to HDFStore. Returns: Extracted data in the form of a DataFrame or Series.",
    "class": "main"
  },
  "pandas.read_html": {
    "new_func": "extract_tabular_webdata",
    "description": "This function extracts tables from a web page and returns them as a list of DataFrames. Parameters: io (str, path object, or file-like object) - The source URL or HTML content. match (str or regex, optional) - Text to search for within the tables. flavor (str or list, optional) - Parsing engine(s) to use. header (int or list, optional) - Row(s) to use as column labels. index_col (int or list, optional) - Column(s) to set as index. skiprows (int, list, or slice, optional) - Rows to skip during parsing. attrs (dict, optional) - Attributes to use to identify the table. parse_dates (bool) - Whether to parse date columns. thousands (str, optional) - Thousands separator. encoding (str, optional) - Character encoding of the HTML. decimal (str) - Decimal separator character. converters (dict, optional) - Functions for converting column values. na_values - Values to treat as NA. keep_default_na (bool) - Whether to include default NA values. displayed_only (bool) - Whether to parse only displayed data. extract_links - Section to extract hyperlinks from. dtype_backend - Backend data type for the resulting DataFrame. storage_options (dict, optional) - Options for storage connection. Returns: A list of DataFrames, each representing a table found in the HTML input.",
    "class": "main"
  },
  "pandas.read_json": {
    "new_func": "deserialize_json_document",
    "description": "Transforms a JSON formatted string into a structured object. Parameters: path_or_buf (str, path, or file-like) - Source of the JSON string. orient (str, optional) - Format of the expected JSON string. typ (str) - Type of object to recover, either 'frame' for DataFrame or 'series' for Series. dtype (bool or dict) - Data type inference for the converted data. convert_axes (bool) - Whether to convert axis labels to the correct type. convert_dates (bool or list) - Conversion of date-like columns. keep_default_dates (bool) - Whether to convert default date-like columns. precise_float (bool) - Use of high precision for floating-point values. date_unit (str) - Unit of timestamp for date conversion. encoding (str) - Encoding of the input string. lines (bool) - Whether the JSON input is structured with one object per line. chunksize (int) - Number of lines per chunk for iteration. compression (str or dict) - Compression type for on-disk data. nrows (int) - Number of lines to read for truncated reading. storage_options (dict) - Options for storage connections. dtype_backend - Backend data type for the resulting object. engine (str) - Parser engine to use. Returns: An object of the specified type containing the deserialized data.",
    "class": "main"
  },
  "pandas.read_orc": {
    "new_func": "ingest_columnar_file",
    "description": "Imports data from an Optimized Row Columnar (ORC) file format into a DataFrame. Parameters: path (str, path object, or file-like object) - The file path or object containing ORC data. columns (list, optional) - Subset of columns to read. dtype_backend - Backend data type for the resulting DataFrame. filesystem (object, optional) - Filesystem interface for file handling. kwargs - Additional arguments passed to underlying reading function. Returns: A DataFrame composed of the requested ORC data.",
    "class": "main"
  },
  "pandas.read_pickle": {
    "new_func": "retrieve_serialized_object",
    "description": "Loads an object saved using serialization from a file. Parameters: filepath_or_buffer (str, path object, or file-like object) - The file path or object where the serialized object is stored. compression (str or dict) - Compression type to be used for decompression of on-disk data. storage_options (dict) - Options for storage connections. Returns: The deserialized object, which could be any type that was originally serialized into the file.",
    "class": "main"
  },
  "pandas.timedelta_range": {
    "new_func": "duration_sequence",
    "description": "Generates a sequence of equally spaced time intervals, starting and ending at specified markers, with a specified number of intervals or frequency. The default unit is days. It creates an index suitable for time-based operations. Parameters: start (str or timedelta-like) - Initial value for the intervals. end (str or timedelta-like) - Final value for the intervals. periods (int) - Total number of intervals to generate. freq (str or timedelta-like) - The gap between intervals. name (str) - Designation for the resulting index. closed (str) - Whether to include start/end points in intervals. unit (str) - Desired time resolution. Returns: TimedeltaIndex - An index of time intervals.",
    "class": "main"
  },
  "pandas.read_sql_query": {
    "new_func": "fetch_frame_from_query",
    "description": "Executes a specified database query and loads the result set into a structured data container. The output format is generally used for data manipulation and analysis. Parameters: sql (str) - The query text to execute. con (connection object) - A connection to the target database. index_col (str or list) - Column(s) to set as index. coerce_float (bool) - Convert non-string, non-numeric types to float. params (list, tuple, dict) - Parameters for SQL execution. parse_dates (list, dict) - Columns to parse as dates. chunksize (int) - Rows per chunk for iteration. dtype (type or dict) - Data type(s) for columns. dtype_backend (str) - Backend data type for DataFrame. Returns: DataFrame or Iterator[DataFrame] - The structured data container or an iterator for large datasets.",
    "class": "main"
  },
  "pandas.to_numeric": {
    "new_func": "cast_to_number",
    "description": "Transforms a data element or collection into a numerical format, with an option to specify the numerical subtype to improve memory efficiency. Be aware that conversion of extremely large values could result in precision loss. Parameters: arg (scalar, list, tuple, array, or Series) - Input to convert. errors (str) - Policy for handling errors during parsing. downcast (str) - Smaller numeric subtype to downcast to, if possible. dtype_backend (str) - Backend data type for DataFrame. Returns: Numeric type (scalar, array, or Series) - The converted numerical representation.",
    "class": "main"
  },
  "pandas.to_timedelta": {
    "new_func": "convert_to_duration",
    "description": "Changes the provided data to a time duration type, which represents the difference between two time points. The function is flexible in handling various input formats. Parameters: arg (str, timedelta, list-like or Series) - Data to convert. unit (str) - Unit of the input if it is numeric. errors (str) - Instruction on how to handle errors. Returns: Timedelta or TimedeltaIndex - The representation of time differences.",
    "class": "main"
  },
  "pandas.read_table": {
    "new_func": "fetch_delimited_data",
    "description": "Loads a dataset from a delimited text file into a structured data container, with options for selective reading and partial loading. Parameters: filepath_or_buffer (str or file-like) - The file path or object to read from. sep (str) - Delimiter to separate fields. header (int, list, or 'infer') - Row(s) to use as column names. names (list) - Explicit column names. index_col (Hashable or list) - Column(s) to set as index. usecols (list or callable) - Subset of columns to read. dtype (type or dict) - Data type(s) for columns. engine (str) - Parser engine choice. converters (dict) - Custom conversion functions for columns. skiprows (int, list, or callable) - Rows to skip. nrows (int) - Number of rows to read. na_values (various) - Additional strings to recognize as NA. iterator (bool) - Return an iterator. chunksize (int) - Number of rows per chunk. Returns: DataFrame or TextFileReader - The structured data container or an iterator for chunked reading.",
    "class": "main"
  },
  "pandas.tseries.api.guess_datetime_format": {
    "new_func": "infer_timestamp_pattern",
    "description": "Infers the pattern of a given date and time character sequence. This automatic detection enables subsequent string-to-date conversions to be more accurate by providing the inferred format string for strftime or strptime functions, unless the pattern cannot be determined, in which case a null value is returned. Parameters: dt_sequence (string): The character sequence representing date and time to analyze. day_first (boolean, default False): If set to True, the function assumes the day precedes the month in the input sequence. Returns: string or None: The inferred date-time pattern or None if the pattern could not be inferred.",
    "class": "tseries"
  },
  "pandas.to_datetime": {
    "new_func": "convert_to_timestamp",
    "description": "Transforms a variety of input data types into a standard datetime object. This process can handle scalars, lists, tuples, arrays, series, or data structures with 'year', 'month', and 'day' fields, interpreting string representations of dates according to the provided format. Parameters: input (various): The data to convert. Supports numerous data types including lists, tuples, and Series. error_behavior ('ignore', 'raise', 'coerce'): Dictates the action upon encountering parsing errors. date_ordering (boolean): Specifies the order of day and month in ambiguous cases. year_first (boolean): Specifies the order of year and month in ambiguous cases. utc (boolean): Determines whether to enforce UTC timezone for conversion. format_pattern (string): The specific format to use for parsing string dates. exactness (boolean): Whether to interpret ambiguous dates strictly. time_unit (string): The time unit for numeric timestamps. infer_format (boolean): Whether to infer the date format of the input. epoch ('unix'): The reference date from which numeric timestamps are calculated. use_cache (boolean): Whether to cache unique datetime conversions. Returns: DateTime: A datetime object or a collection of datetime objects.",
    "class": "main"
  },
  "pandas.read_xml": {
    "new_func": "parse_xml_to_frame",
    "description": "Transforms an XML document into a structured data frame. This parser can handle different file sources and utilize XPath expressions to filter the desired XML nodes. Parameters: source (string or file-like): The XML source, which can be a file path or a file-like object. xpath_query (string): The XPath query for selecting nodes. namespace_map (dict): Prefix-URI mappings for namespaces used in the XPath query. element_filter (boolean): If true, only child elements are parsed. attribute_filter (boolean): If true, only attributes are parsed. column_names (list-like): Custom names for the resulting data frame columns. data_type (type or dict): Data types to apply to the resulting columns. value_converters (dict): Functions to convert values in certain columns. date_parser (various): Specifications for parsing date columns. charset (string): The character encoding of the XML document. parser_type (string): Choice of XML parser. xsl_transform (string or file-like): An XSLT stylesheet for pre-processing XML. iter_parse (dict): Definitions for iterative parsing of large XML files. decompression (string or dict): For handling compressed files. storage_options (dict): Connection options for different storage backends. dtype_backend (string): Choice of backend data type for the resulting data frame. Returns: DataFrame: The structured representation of the XML document.",
    "class": "main"
  },
  "pandas.read_sql_table": {
    "new_func": "fetch_table_to_frame",
    "description": "Retrieves the content of a specified database table and outputs it as a structured data frame. Requires a table name and a connection to the database, without support for DBAPI connections. Parameters: table_identifier (string): The name of the table to query. connection (SQLAlchemy connectable or string): The connection to the database. schema_name (string): The database schema to query. index_column (string or list): The column(s) to set as the index. float_conversion (boolean): Whether to convert non-numeric types to floats. date_parser (list or dict): Specifications for parsing date columns. selected_columns (list): Specific columns to select from the table. batch_size (int): The number of rows per batch to return when using an iterator. dtype_backend (string): Choice of backend data type for the resulting data frame. Returns: DataFrame or Iterator[DataFrame]: The table content as a data frame or an iterator over data frames if batch_size is set.",
    "class": "main"
  },
  "pandas.tseries.offsets.BDay": {
    "new_func": "weekday_increment",
    "description": "Acts as an alias for BusinessDay, signifying the representation of a standard business day or workday increment, typically used for offsetting dates within business or working days only.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BQuarterBegin.copy": {
    "new_func": "duplicate_quarterly_offset",
    "description": "Generates an identical instance of the current quarterly period incrementer.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BQuarterBegin": {
    "new_func": "business_quarter_commencement",
    "description": "Creates an object that advances dates to the next workday at the start of a three-month interval. The commencement month of these intervals can be specified. Arguments include the number of intervals to advance, whether to set the time to 00:00:00, and the initial month for these quarter periods.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BMonthEnd": {
    "new_func": "workday_month_termination",
    "description": "Equivalent to the class that moves dates forward to the last weekday of the current month.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BQuarterBegin.freqstr": {
    "new_func": "periodicity_code",
    "description": "Provides a textual representation of the interval's cadence.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BMonthBegin": {
    "new_func": "workday_month_inception",
    "description": "An alternative designation for the class that shifts dates to the initial workday of a new month.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BQuarterBegin.is_month_end": {
    "new_func": "terminates_monthly_period",
    "description": "Determines if a given point in time coincides with the final day of a month. Parameters: ts (datetime-like) - The point in time to evaluate. Returns: bool - True if the specified time falls on the last day of the month, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BQuarterBegin.is_on_offset": {
    "new_func": "matches_temporal_frequency",
    "description": "Checks if a specific instance in time aligns with a defined temporal frequency. Parameters: dt (datetime.datetime) - The instance in time to be evaluated against the frequency. Returns: bool - True if there is an intersection with the frequency, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BQuarterBegin.is_anchored": {
    "new_func": "singular_frequency_check",
    "description": "Assesses if the frequency represents a singular unit (n=1). Note: This function is deprecated as of version 2.2.0 and will be removed in subsequent versions. It is recommended to use the condition 'obj.n == 1' instead. Parameters: None. Returns: bool - True if the frequency is singular, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BQuarterBegin.is_year_start": {
    "new_func": "BQuarterBegin_commences_annual_cycle",
    "description": "Evaluates whether a given point in time marks the commencement of a new year. Parameters: ts (datetime-like) - The point in time to check. Returns: bool - True if the time instance is the start of a year, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BQuarterBegin.is_quarter_end": {
    "new_func": "concludes_quarterly_phase",
    "description": "Determines if a specific point in time signifies the conclusion of a quarterly cycle. Parameters: ts (datetime-like) - The time instance to assess. Returns: bool - True if the instance corresponds with the end of a quarter, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BQuarterBegin.startingMonth": {
    "new_func": "BQuarterBegin_initial_quarter_month",
    "description": "Retrieves the month in which the business quarter begins. This property is used to determine the specific month that marks the start of the fiscal quarter.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BQuarterBegin.nanos": {
    "new_func": "BQuarterBegin_nano_intervals",
    "description": "Obtains the duration of the business quarter beginning offset in nanoseconds. This attribute gives a precise time span measurement at the nanosecond level.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BQuarterBegin.normalize": {
    "new_func": "standardize_start",
    "description": "Adjusts the business quarter's beginning timestamp to midnight. This method is utilized to reset the time component of the offset to the start of the day.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BQuarterBegin.n": {
    "new_func": "multiplier_value",
    "description": "Accesses the multiplier for the business quarter beginning offset. This attribute signifies the quantity by which the offset is multiplied.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BQuarterBegin.rule_code": {
    "new_func": "regulation_identifier",
    "description": "Provides the code that represents the rule for the business quarter beginning offset. This string is a concise representation of the offset's behavior.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BQuarterEnd.is_month_start": {
    "new_func": "initial_month_check",
    "description": "Determines if a given timestamp coincides with the commencement of a month. Parameters: ts (datetime-like) - The timestamp to evaluate. Returns: bool - True if the timestamp is at the start of the month, False otherwise.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BQuarterEnd.is_on_offset": {
    "new_func": "frequency_coincidence",
    "description": "Evaluates if a given datetime coincides with the specified frequency. Parameters: dt (datetime-like) - The point in time to check for alignment with the frequency. Returns: bool - True if there is an intersection with the frequency, False otherwise.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BQuarterEnd.is_quarter_start": {
    "new_func": "commencing_quarter_verifier",
    "description": "Checks if a given timestamp marks the start of a financial quarter. Parameters: ts (datetime-like) - The timestamp to assess. Returns: bool - True if the timestamp indicates the beginning of a quarter, False otherwise.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BQuarterEnd.is_quarter_end": {
    "new_func": "terminal_quarter_verifier",
    "description": "Ascertain if a timestamp aligns with the closing of a financial quarter. Parameters: ts (datetime-like) - The timestamp to examine. Returns: bool - True if the timestamp signifies the end of a quarter, False otherwise.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BQuarterEnd.is_year_end": {
    "new_func": "annual_termination_point",
    "description": "Determines if a timestamp corresponds with the final day of the calendar year. Parameters: ts (datetime-like) - The timestamp to investigate. Returns: bool - True if the timestamp falls on the last day of the year, False otherwise.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BQuarterEnd.is_year_start": {
    "new_func": "BQuarterEnd_commences_annual_cycle",
    "description": "Determines if a given timestamp coincides with the commencement of the annual cycle. Parameters: ts (Timestamp) - The point in time to assess. Returns: bool - True if the timestamp marks the start of the annual cycle, False otherwise.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BQuarterEnd.nanos": {
    "new_func": "BQuarterEnd_nano_intervals",
    "description": "Retrieves the nanosecond increment specific to the end of a business quarter. Returns: int - The number of nanoseconds.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BQuarterEnd.n": {
    "new_func": "offset_multiplier",
    "description": "Provides the multiplier for the business quarter's end offset. Returns: int - The offset multiplier.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BQuarterEnd.kwds": {
    "new_func": "extra_params",
    "description": "Supplies additional parameters related to the business quarter's end offset. Returns: dict - A dictionary containing the extra parameters.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BQuarterEnd.rule_code": {
    "new_func": "period_identifier",
    "description": "Yields the code that identifies the offset rule for the business quarter's end. Returns: str - The rule code as a string.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BQuarterEnd.startingMonth": {
    "new_func": "BQuarterEnd_initial_quarter_month",
    "description": "Retrieves the month at which the business quarter period commences. This attribute is useful for adjusting or creating custom business quarter offsets based on the specific starting month. Parameters: None. Returns: int - The month number (1-12) indicating the start of the business quarter.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BYearBegin.copy": {
    "new_func": "duplicate_anchored_offset",
    "description": "Produces a replica of the current business year's commencement offset object, ensuring that the original object's state is preserved. Parameters: None. Returns: An identical new instance of the business year's start offset.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BYearBegin.is_month_end": {
    "new_func": "terminates_month",
    "description": "Checks if a given timestamp coincides with the final day of any month. This function is particularly useful to identify if timestamps fall on the concluding day of a month. Parameters: ts (Timestamp) - The point in time to be evaluated. Returns: bool - True if the timestamp is on the last day of a month, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BYearBegin.is_month_start": {
    "new_func": "commences_month",
    "description": "Assesses whether a specified timestamp aligns with the initial day of any month. This function is handy for pinpointing timestamps that represent the beginning of a month. Parameters: ts (Timestamp) - The point in time to be assessed. Returns: bool - True if the timestamp marks the start of a month, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BYearBegin.is_on_offset": {
    "new_func": "aligns_with_frequency",
    "description": "Determines if a given timestamp intersects with the specific frequency of the business year's start. This method is useful for validating alignment with frequency intervals. Parameters: dt (datetime.datetime) - The timestamp to verify for intersection with the frequency. Returns: bool - True if there is an intersection, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BYearBegin.n": {
    "new_func": "fiscal_year_offset_units",
    "description": "Retrieves the number of periods for the offset representing the beginning of a business year.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BYearBegin.month": {
    "new_func": "initial_business_quarter",
    "description": "Accesses the month component of the date offset that marks the commencement of a fiscal year.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BYearBegin.normalize": {
    "new_func": "standardize_initial_business_period",
    "description": "Adjusts the time component of the business year's starting offset to midnight.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BYearBegin.name": {
    "new_func": "alias_for_fiscal_inception",
    "description": "Generates a textual identifier reflecting the foundational frequency of the business year's inception point.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BYearBegin.nanos": {
    "new_func": "nano_interval_business_year_start",
    "description": "Yields the nanosecond count corresponding to the interval for the beginning of a business year time offset.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BYearEnd": {
    "new_func": "FinalBizDayAnnualIncrement",
    "description": "Adjusts date objects to the concluding workday of a given year. It can increment date ranges by a specified number of years, with options to normalize the start and end times to midnight and to select a particular month for the year's end calculations. Parameters: n (int, default 1) - The increment of years to apply. normalize (bool, default False) - Option to set the start and end times to midnight. month (int, default 12) - The month within the year to consider as the final period.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BYearBegin.rule_code": {
    "new_func": "StartOfBizYearIdentifier",
    "description": "Provides a unique code representing the start-of-business-year frequency. No parameters. Returns: str - The unique identifier for the beginning-of-business-year frequency.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BYearEnd.freqstr": {
    "new_func": "AnnualBizClosureFrequencyStr",
    "description": "Generates a textual representation of the business year-end frequency. No parameters. Returns: str - A string that signifies the frequency of the business year-end.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BYearEnd.copy": {
    "new_func": "DuplicateBizYearClosureFrequency",
    "description": "Creates a duplicate of the business year-end frequency object. No parameters. Returns: A new instance that is an identical copy of the original frequency object.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BYearEnd.is_anchored": {
    "new_func": "SingleUnitBizYearEndCheck",
    "description": "Determines if the frequency object stands for a single-unit business year-end interval. This functionality is deprecated and will be removed in future updates. Clients should use obj.n == 1 to achieve equivalent results. No parameters. Returns: bool - True if the frequency is a single-unit interval, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BYearEnd.is_on_offset": {
    "new_func": "aligns_with_cycle",
    "description": "Assesses if a given point in time aligns with the specified periodicity. Parameters: dt (datetime-like) - The temporal measure to scrutinize for alignment. Returns: bool - True if the time point aligns with the defined cycle, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BYearEnd.is_quarter_end": {
    "new_func": "culmination_quarterly_verification",
    "description": "Checks if a given timestamp corresponds with the cessation of a fiscal quarter. Parameters: ts (datetime-like) - The moment in time to inspect. Returns: bool - Indicates the occurrence of the timestamp at the end of a quarter.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BYearEnd.is_month_start": {
    "new_func": "commencement_monthly_check",
    "description": "Evaluates whether a particular timestamp matches the initial day of any month. Parameters: ts (datetime-like) - The timestamp to consider. Returns: bool - True if the timestamp is the first day of a month, False otherwise.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BYearEnd.is_quarter_start": {
    "new_func": "initiation_quarterly_verification",
    "description": "Verifies if a specified timestamp falls on the inception of a quarter. Parameters: ts (datetime-like) - The time instance for evaluation. Returns: bool - Signifies if the timestamp is at the start of a quarter.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BYearEnd.name": {
    "new_func": "annual_closure_identifier",
    "description": "Retrieves the textual representation of the underlying frequency for business year-end.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BYearEnd.nanos": {
    "new_func": "annual_closure_nano_duration",
    "description": "Acquires the nanosecond duration of the business year-end offset.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BYearEnd.normalize": {
    "new_func": "standardize_annual_closure",
    "description": "Adjusts the business year-end offset to midnight, creating a standardized point in time.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BusinessDay.holidays": {
    "new_func": "weekday_vacations",
    "description": "Obtains a list of non-working days within the context of business weekdays.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BusinessDay.copy": {
    "new_func": "duplicate_weekday_frequency",
    "description": "Creates a duplicate of the object representing the interval of a standard business day.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BusinessDay.is_year_end": {
    "new_func": "final_business_period_check",
    "description": "Determines if a given timestamp coincides with the final business interval of the calendar cycle. Parameters: ts (Timestamp) - The point in time to evaluate. Returns: bool - True if the timestamp aligns with the concluding business interval.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BusinessDay.is_year_start": {
    "new_func": "initial_business_period_check",
    "description": "Assesses whether a specific timestamp aligns with the initial business segment of the annual timetable. Parameters: ts (Timestamp) - The moment in time to assess. Returns: bool - True if the timestamp falls on the commencing business segment.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BusinessDay.kwds": {
    "new_func": "extra_offset_parameters",
    "description": "Retrieves a dictionary encapsulating additional arguments pertinent to the business interval computation. Returns: dict - A collection of supplementary keyword arguments.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BusinessDay.name": {
    "new_func": "frequency_label",
    "description": "Provides a textual representation indicative of the foundational rhythm. Returns: str - A label denoting the core temporal cadence.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BusinessDay.nanos": {
    "new_func": "BusinessDay_nano_intervals",
    "description": "Yields the nanosecond-scale quantity corresponding to a single business timeframe. Returns: int - The nanosecond count for the standard business duration.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BusinessHour.calendar": {
    "new_func": "working_time_planner",
    "description": "Retrieves the scheduling system associated with the work time rule, specifying which days are considered as part of the work week.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BusinessHour.freqstr": {
    "new_func": "cycle_notation",
    "description": "Yields a symbolic representation of the recurring cycle that defines the operational hours interval.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BusinessHour.holidays": {
    "new_func": "non_working_dates",
    "description": "Obtains a collection of dates that are excluded from the definition of operational periods.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BusinessHour": {
    "new_func": "work_interval_constructor",
    "description": "Creates an object that signifies a span of operational hours, potentially spanning multiple standard hours, with options to normalize start and end times as well as apply a temporal adjustment. Parameters: hours_count (int, default 1) - The quantity of hours to represent. day_start (str, time, or list of str/time, default '09:00') - The commencement time for the interval. day_end (str, time, or list of str/time, default '17:00') - The conclusion time for the interval. temporal_shift (timedelta, default timedelta(0)) - A temporal adjustment to apply to the interval.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BusinessHour.copy": {
    "new_func": "replicate_cycle",
    "description": "Produces a duplicate of the object that signifies the interval of operational hours.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BusinessHour.is_month_start": {
    "new_func": "commencement_of_month",
    "description": "Evaluates if a given timestamp coincides with the commencement of a month during business hours. The result is a truth value indicating this condition.\n\nParameters:\nts (datetime.datetime) - The timestamp to be evaluated.\n\nReturns: bool - True if the timestamp signifies the start of a month, False otherwise.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BusinessHour.is_on_offset": {
    "new_func": "intersects_business_period",
    "description": "Assesses if a particular datetime intersects with the current business hour frequency.\n\nParameters:\ndt (datetime.datetime) - The datetime to test for intersection.\n\nReturns: bool - True if there is an intersection, False otherwise.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BusinessHour.is_month_end": {
    "new_func": "culmination_of_month",
    "description": "Checks if a specified timestamp aligns with the culmination of a month within business hours. The output is a boolean indicator of this occurrence.\n\nParameters:\nts (datetime.datetime) - The timestamp to check.\n\nReturns: bool - Indicates whether the timestamp is at the end of a month.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BusinessHour.is_year_start": {
    "new_func": "initiation_of_year",
    "description": "Determines if a timestamp falls on the initiation point of a year, specifically within the scope of business hours. A boolean value is returned to indicate this event.\n\nParameters:\nts (datetime.datetime) - Timestamp to evaluate.\n\nReturns: bool - True if the timestamp represents the start of a year, False otherwise.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BusinessHour.is_year_end": {
    "new_func": "final_annual_hour",
    "description": "Determines if a given timestamp occurs on the final hour of the calendar year. Parameters: ts (Timestamp) - The point in time to evaluate. Returns: bool - True if the timestamp corresponds with the closing hour of the year, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BusinessHour.name": {
    "new_func": "frequency_alias",
    "description": "Provides the textual representation of the fundamental time cycle. Returns: str - A string that symbolizes the primary frequency interval.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BusinessHour.is_quarter_start": {
    "new_func": "initial_quarterly_hour",
    "description": "Evaluates if a specific timestamp coincides with the starting hour of a fiscal quarter. Parameters: ts (Timestamp) - The moment in time to check. Returns: bool - True if the timestamp aligns with the inception hour of a quarter, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BusinessHour.nanos": {
    "new_func": "nano_intervals_commercial",
    "description": "retrieves the number of nanoseconds in one interval of the commercial time offset.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BusinessHour.is_quarter_end": {
    "new_func": "terminal_quarter_check",
    "description": "evaluates whether a given timestamp coincides with the final day of a fiscal quarter. Parameters: ts (timestamp) - The point in time to assess. Returns: bool - True if the given timestamp aligns with the quarter's final day, False otherwise.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BusinessHour.rule_code": {
    "new_func": "commercial_period_identifier",
    "description": "provides the standardized abbreviation representing the interval for commercial time calculations.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BusinessMonthBegin": {
    "new_func": "commercial_month_inception",
    "description": "shifts to the subsequent date that marks the initiation of a month's commercial activities. Parameters: n (int, default 1) - The count of months to move forward. normalize (bool, default False) - Whether to set the start and end times to midnight before creating a range of dates. Returns: DateOffset - The offset to the first commercial day of the month.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BusinessHour.normalize": {
    "new_func": "standardize_commercial_time",
    "description": "adjusts the start and end times of a commercial time offset to the standard midnight boundary.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BusinessMonthBegin.is_month_start": {
    "new_func": "initial_day_check",
    "description": "Assesses whether a particular timestamp corresponds to the initial day of a month. Parameters: ts (Timestamp) - The moment in time to analyze. Returns: bool - True if it's the first day of the month, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BusinessMonthBegin.is_quarter_start": {
    "new_func": "commencing_quarter_check",
    "description": "Evaluates whether a certain timestamp aligns with the commencing day of a quarter. Parameters: ts (Timestamp) - The specific date and time to scrutinize. Returns: bool - True if it's the starting day of a quarter, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BusinessMonthBegin.is_year_end": {
    "new_func": "culmination_annual_check",
    "description": "Checks if a provided timestamp is concurrent with the ultimate day of a calendar year. Parameters: ts (Timestamp) - The chronological point to assess. Returns: bool - True if it's the last day of the year, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BusinessMonthBegin.is_year_start": {
    "new_func": "commencement_of_annum",
    "description": "Determines if a specific timestamp marks the initial day of the calendar year. Parameters: ts (datetime-like) - The point in time to evaluate. Returns: bool - True if the supplied moment coincides with the first day of the year, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BusinessMonthBegin.is_on_offset": {
    "new_func": "aligns_with_period",
    "description": "Assesses if a particular temporal point coincides with the established frequency interval. Parameters: dt (datetime.datetime) - The moment in time to scrutinize for alignment with the specified interval. Returns: bool - True if the given datetime intersects with the frequency, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BusinessMonthBegin.name": {
    "new_func": "identifier_label",
    "description": "Provides a textual representation of the foundational periodicity. Returns: str - A label identifying the base temporal frequency.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BusinessMonthBegin.n": {
    "new_func": "period_multiplier",
    "description": "Accesses the multiplier associated with the periodic offset. Returns: int - The integer factor that modifies the base frequency.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BusinessMonthBegin.kwds": {
    "new_func": "offset_parameters",
    "description": "Fetches a mapping of additional configuration options for the temporal offset. Returns: dict - A dictionary containing extra parameters pertinent to the offset.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BusinessMonthBegin.normalize": {
    "new_func": "CommenceWorkMonthStandardize",
    "description": "Adjusts the timestamp associated with the initiation of a work month to the start of the day. This method is useful when one requires a consistent point of comparison for timestamps, ensuring that the time component is set to 00:00:00.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BusinessMonthBegin.nanos": {
    "new_func": "InitiateWorkMonthNanoseconds",
    "description": "Retrieves the nanosecond duration of the business month's starting offset. This enables precise time measurements down to the nanosecond for operations that require such granularity.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BusinessMonthEnd.copy": {
    "new_func": "DuplicateMonthClosure",
    "description": "Produces an exact duplicate of the object that represents the interval between the conclusion of work months. This is particularly useful when one needs to preserve the original object while making adjustments or manipulations to a separate instance.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BusinessMonthEnd": {
    "new_func": "FinalWorkdayOfMonthInterval",
    "description": "Defines a period that jumps to subsequent dates corresponding to the final weekday of the month for business scheduling purposes. It takes into account the number of months to leap and whether to align the resultant dates to the start of the day. Parameters: months_count (int, default 1) - The count of months the offset represents. standardize (bool, default False) - Whether to set the start and end dates to the beginning of the day.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BusinessMonthEnd.freqstr": {
    "new_func": "ClosureMonthFrequencyDescriptor",
    "description": "Yields a textual representation that describes the frequency of the terminus workday of the month's interval. This descriptor is convenient for understanding and communicating the periodic nature of the interval in question.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BusinessMonthBegin.rule_code": {
    "new_func": "commence_monthly_rule_identifier",
    "description": "Retrieves the shorthand code representing the commencement of a business month within a given frequency. This symbol is utilized internally to identify offset aliases.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BusinessMonthEnd.is_anchored": {
    "new_func": "unitary_month_finish_check",
    "description": "Evaluates if the frequency corresponds to a singular unit (n=1). However, this functionality is outdated as of version 2.2.0 and should be replaced by directly checking if the 'n' attribute equals 1.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BusinessMonthEnd.is_month_start": {
    "new_func": "commencement_of_month_verifier",
    "description": "Determines if a given timestamp aligns with the initial day of any month. Input parameter: ts (timestamp/datetime) - The point in time to assess. Output: boolean - True if ts coincides with the start of a month, False otherwise.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BusinessMonthEnd.is_month_end": {
    "new_func": "termination_of_month_verifier",
    "description": "Assesses whether a specific timestamp aligns with the concluding day of any month. Input parameter: ts (timestamp/datetime) - The point in time to evaluate. Output: boolean - True if ts coincides with the end of a month, False otherwise.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BusinessMonthEnd.is_on_offset": {
    "new_func": "frequency_intersection_checker",
    "description": "Analyzes if a particular timestamp intersects with the defined frequency of this object. Parameter: dt (datetime) - The timestamp to test for intersection. Returns: boolean - True if dt intersects with the frequency, False otherwise.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BusinessMonthEnd.n": {
    "new_func": "final_workday_month_count",
    "description": "Retrieves the integer count associated with the final weekday of the month's offset. This value indicates the number of periods the offset represents.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BusinessMonthEnd.name": {
    "new_func": "identifier_frequency",
    "description": "Acquires the textual representation of the foundational frequency for the offset.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CBMonthBegin": {
    "new_func": "customized_workday_month_commence",
    "description": "Serves as an alternate reference to the CustomBusinessMonthBegin class, which determines the start date of a month adjusted for custom business days.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BusinessMonthEnd.normalize": {
    "new_func": "standardize_final_workday_month",
    "description": "Adjusts the final business day of the month to midnight. This method ensures that the time component of the offset is set to the standard starting point of a day.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CBMonthEnd": {
    "new_func": "customized_workday_month_closure",
    "description": "Serves as an alternate reference to the CustomBusinessMonthEnd class, which calculates the closing date of a month that conforms to custom business days.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BusinessMonthEnd.nanos": {
    "new_func": "nano_interval_month_closure",
    "description": "Retrieves the nanosecond duration for this particular frequency representing the closure of a business month.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BusinessMonthEnd.rule_code": {
    "new_func": "convention_identifier",
    "description": "Provides a unique identifier for the frequency convention, which is useful in temporal arithmetic.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CDay": {
    "new_func": "weekday_span",
    "description": "Represents a span of business days with custom weekmask and holidays. It's an alternative to the CustomBusinessDay frequency.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CustomBusinessDay.calendar": {
    "new_func": "schedule_planner",
    "description": "Accesses the calendar system associated with the custom frequency for defining working days.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CustomBusinessDay.copy": {
    "new_func": "duplicate_frequency",
    "description": "Creates an exact replica of the specified custom business day frequency object.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CustomBusinessDay.is_quarter_end": {
    "new_func": "special_workday_quarter_termination",
    "description": "Determines if a given timestamp coincides with the final day of a financial quarter within the context of specialized working days. Parameters: ts (Timestamp) - The point in time to evaluate. Returns: bool - True if the timestamp aligns with a quarter's closing day, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CustomBusinessDay.kwds": {
    "new_func": "offset_attributes",
    "description": "Retrieves a dictionary encompassing additional parameters relevant to the specialized business day time shift. Returns: dict - A mapping of extra argument names to their corresponding values.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CustomBusinessDay.nanos": {
    "new_func": "nanosecond_units",
    "description": "Yields the count of nanoseconds that constitute the single specialized business day period. Returns: int - The nanosecond count.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CustomBusinessHour.calendar": {
    "new_func": "specializedTradeHourPlanner",
    "description": "Retrieves the schedule that defines the dates and times considered as business hours for the specialized custom trade hour object. It details the operational periods for business-related activities within the specified custom timeframe.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CustomBusinessDay.normalize": {
    "new_func": "standardizeTradeIntervalStart",
    "description": "Adjusts the starting point of a tailored trade interval to the midnight time, effectively setting the timestamp to the beginning of the day. This provides a uniform commencement time for all intervals.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CustomBusinessDay.rule_code": {
    "new_func": "tradeIntervalDesignation",
    "description": "Yields an abbreviation that signifies the type of tailored trade interval being used. This code serves as a shorthand reference to the specific business day convention applied.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CustomBusinessDay.weekmask": {
    "new_func": "weeklyTradeCycleFilter",
    "description": "Provides a binary mask that illustrates the days of the week designated as active trading periods within a custom trade cycle. This mask allows for the customization of which days are considered valid for business.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CustomBusinessHour.copy": {
    "new_func": "duplicateTradeHourFrequency",
    "description": "Creates an exact replica of the current object that defines the frequency of trade hours. This duplication allows for safe modifications without altering the original configuration.",
    "return": "CustomBusinessHour - A new instance that is identical to the original.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CustomBusinessHour.is_year_end": {
    "new_func": "business_hours_on_final_day",
    "description": "Determines if a given timestamp coincides with the final day of the calendar year within business hours. Parameters: ts (Timestamp) - The timestamp to evaluate. Returns: bool - True if the timestamp is during business hours on the last day of the year, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CustomBusinessHour.kwds": {
    "new_func": "extra_offset_params",
    "description": "Retrieves additional arguments used for defining a specialized business hour offset. Returns: dict - A dictionary containing extra parameters for the offset configuration.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CustomBusinessHour.is_year_start": {
    "new_func": "business_hours_at_annual_commencement",
    "description": "Checks if a specific timestamp aligns with the commencement of the year during business operations. Parameters: ts (Timestamp) - The timestamp to test. Returns: bool - True if the timestamp falls within business hours on the first day of the year, else False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CustomBusinessHour.name": {
    "new_func": "base_frequency_label",
    "description": "Yields the label that symbolizes the fundamental frequency for the offset. Returns: str - A string that identifies the basic frequency of the offset.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CustomBusinessHour.nanos": {
    "new_func": "CustomBusinessHour_nano_intervals",
    "description": "Retrieves the nanosecond duration of a bespoke trading hour increment.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CustomBusinessHour.start": {
    "new_func": "initiation_time",
    "description": "Obtains the starting moment of a specified trade hour range.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CustomBusinessHour.normalize": {
    "new_func": "standardize_beginning",
    "description": "Adjusts the onset of a business interval to the start of the day.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CustomBusinessHour.weekmask": {
    "new_func": "weekly_schedule",
    "description": "Specifies the days considered valid for business operations within a week.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CustomBusinessMonthBegin": {
    "new_func": "bespoke_monthly_commencement",
    "description": "A class that advances through dates at the commencement of each custom work month, considering specified weekdays and holidays for business operations. Inputs include the number of months to increase, an option to standardize initial dates, a string representing valid business days, a list of dates to exclude as holidays, and an optional time offset.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CustomBusinessHour.rule_code": {
    "new_func": "business_hour_encoding",
    "description": "This attribute provides the encoded value representing the specific offset state for a specialized business hour. It serves to identify the type of business hour offset to external systems.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CustomBusinessMonthBegin.freqstr": {
    "new_func": "monthly_commencement_frequency_signature",
    "description": "This attribute returns an encoded string that signifies the starting frequency of a specialized business month. It helps in interpreting the temporal interval at which the month begins according to business days.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CustomBusinessMonthBegin.copy": {
    "new_func": "duplicate_monthly_onset",
    "description": "This method generates an exact replica of the current object that defines the inception of a business-focused month. It is useful when an immutable copy of the object is needed for independent manipulation or storage.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CustomBusinessMonthBegin.calendar": {
    "new_func": "business_month_inception_schedule",
    "description": "This attribute holds the schedule or system used to determine the business days that mark the commencement of the business month. It defines which days are considered working days for the purpose of calculating the start of the month.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CustomBusinessMonthBegin.is_month_end": {
    "new_func": "verifies_closure_of_month",
    "description": "This method evaluates a given timestamp to determine if it coincides with the final business day of the month. It outputs a boolean value, indicating whether the specified time falls on the concluding day according to the recognized business calendar.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CustomBusinessMonthBegin.holidays": {
    "new_func": "initialBusinessMonthNonWorkingDays",
    "description": "Retrieves a list of non-working days applied to the beginning of a custom business month calculation.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CustomBusinessMonthBegin.is_anchored": {
    "new_func": "unitFrequencyCheck",
    "description": "Determines if the offset represents a singular unit frequency (where n equals one). Note: This method is obsolete and will be removed in future releases. A direct comparison of the 'n' attribute to 1 should be used instead.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CustomBusinessMonthBegin.is_month_start": {
    "new_func": "commencementOfCycle",
    "description": "Evaluates whether a given timestamp coincides with the start of the month. Input: ts (datetime) - The timestamp to assess. Returns: boolean - True if the timestamp is at the start of the month, False otherwise.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CustomBusinessMonthBegin.is_on_offset": {
    "new_func": "alignsWithFrequency",
    "description": "Checks if a particular datetime aligns with the established frequency. Parameters: dt (datetime) - The datetime value to check against the frequency. Returns: boolean - True if dt aligns with the frequency, False otherwise.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CustomBusinessMonthBegin.is_quarter_end": {
    "new_func": "terminalQuarterPeriod",
    "description": "Assesses if a specific timestamp matches the end of a quarter period. Parameters: ts (datetime) - Timestamp to verify. Returns: boolean - True if timestamp is at the end of a quarter, False otherwise.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CustomBusinessMonthBegin.is_quarter_start": {
    "new_func": "initial_trimester_check",
    "description": "Assesses if a given timestamp corresponds to the commencement of a fiscal quarter. Parameters: ts (Timestamp) - The point in time to evaluate. Returns: bool - True if the timestamp marks the beginning of a quarter, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CustomBusinessMonthBegin.is_year_start": {
    "new_func": "commencement_annual_check",
    "description": "Evaluates if a specific timestamp aligns with the initial day of a calendar year. Parameters: ts (Timestamp) - The moment in time to assess. Returns: bool - True if the given timestamp is the first day of the year, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CustomBusinessMonthBegin.is_year_end": {
    "new_func": "closure_annual_check",
    "description": "Determines if a particular timestamp coincides with the final day of the calendar year. Parameters: ts (Timestamp) - The instant in time to verify. Returns: bool - True if the timestamp signifies the year's last day, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CustomBusinessMonthBegin.m_offset": {
    "new_func": "month_commence_displacement",
    "description": "Provides the offset value for the start of a custom business month. Returns: DateOffset - The offset used for aligning dates to the beginning of a business month.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CustomBusinessMonthBegin.kwds": {
    "new_func": "additional_offset_parameters",
    "description": "Retrieves a dictionary containing supplementary arguments pertinent to the offset calculation. Returns: dict - A collection of additional keyword arguments.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CustomBusinessMonthBegin.n": {
    "new_func": "BusinessMonthStartInteger",
    "description": "Retrieves the integer offset for the beginning of a custom business month.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CustomBusinessMonthBegin.nanos": {
    "new_func": "BusinessMonthInceptionNanoseconds",
    "description": "Obtains the nanosecond duration of the starting point for a specified business month.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CustomBusinessMonthBegin.name": {
    "new_func": "BusinessMonthCommencementLabel",
    "description": "Yields a textual representation that denotes the underlying frequency of the bespoke business month start.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CustomBusinessMonthBegin.rule_code": {
    "new_func": "BusinessMonthOriginCode",
    "description": "Returns the code that governs the rules for the initiation of the tailored business month period.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CustomBusinessMonthBegin.weekmask": {
    "new_func": "BusinessWeekPattern",
    "description": "Provides the weekly schedule that defines which days are considered business days for the purpose of determining the start of the custom business month.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CustomBusinessMonthEnd.freqstr": {
    "new_func": "tailored_trade_period_signature",
    "description": "Delivers a textual representation of the interval's cadence.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CustomBusinessMonthEnd.is_quarter_end": {
    "new_func": "terminal_trimester_check",
    "description": "Assesses if a specific point in time coincides with the culmination of a fiscal quarter. It yields a truth value reflecting this condition. Input: ts (datetime-like) \u2013 The point in time to evaluate. Output: boolean \u2013 True if the input corresponds with the final day of a quarter, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CustomBusinessMonthEnd.is_anchored": {
    "new_func": "singular_frequency_verifier",
    "description": "Evaluates if the frequency interval is singular (i.e., n=1). As of version 2.2.0, it is recommended to use the expression 'obj.n == 1' as this method is obsolete and will be removed in forthcoming releases.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CustomBusinessMonthEnd.is_on_offset": {
    "new_func": "precise_temporal_alignment",
    "description": "Determines if a given temporal point intersects with the specified interval. Input: dt (datetime-like) \u2013 The temporal point for intersection verification. Output: boolean \u2013 True if there is an intersection, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CustomBusinessMonthEnd.is_month_end": {
    "new_func": "final_day_fiscal_month_check",
    "description": "Ascertain if a temporal mark coincides with the terminal day of a business month, producing a binary outcome. Input: ts (datetime-like) \u2013 The temporal mark to assess. Output: boolean \u2013 Indicator of whether the given mark aligns with the last business day of the month.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CustomBusinessMonthEnd.is_month_start": {
    "new_func": "initial_trading_day_check",
    "description": "Determines if the provided timestamp coincides with the initial day of a month, taking into account custom business days. Parameters: ts (Timestamp) - The timestamp to check. Returns: bool - True if it's the initial business day of the month, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CustomBusinessMonthEnd.is_year_end": {
    "new_func": "final_trading_cycle_termination",
    "description": "Evaluates if the given timestamp falls on the last business day of the annual cycle. Parameters: ts (Timestamp) - The timestamp to verify. Returns: bool - True if it's the concluding business day of the year, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CustomBusinessMonthEnd.is_quarter_start": {
    "new_func": "inaugural_period_outset_verification",
    "description": "Checks if the specified timestamp corresponds with the outset of a business quarter. Parameters: ts (Timestamp) - The timestamp to analyze. Returns: bool - True if it matches the outset of a quarter based on business days, else False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CustomBusinessMonthEnd.m_offset": {
    "new_func": "month_shift_value",
    "description": "Retrieves the offset value associated with the ending day of the business month.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CustomBusinessMonthEnd.is_year_start": {
    "new_func": "commencement_trading_cycle_check",
    "description": "Ascertain whether a timestamp aligns with the commencement day of the annual business cycle. Parameters: ts (Timestamp) - The timestamp to appraise. Returns: bool - True if the timestamp is the first business day of the year, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CustomBusinessMonthEnd.kwds": {
    "new_func": "tailored_work_month_closure_parameters",
    "description": "Retrieves a dictionary of additional arguments for the time period adjustment. These arguments are used to fine-tune the behavior of the month-end calculation for business days.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CustomBusinessMonthEnd.n": {
    "new_func": "business_month_termination_multiplier",
    "description": "Provides an integer value that denotes the number of business month end periods to apply when calculating offsets.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CustomBusinessMonthEnd.name": {
    "new_func": "work_month_closure_frequency_label",
    "description": "Yields a textual representation of the primary interval used to demarcate the end of the business month.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CustomBusinessMonthEnd.nanos": {
    "new_func": "nano_interval_business_month_finish",
    "description": "Returns the nanosecond count corresponding to the business month end interval.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CustomBusinessMonthEnd.normalize": {
    "new_func": "standardize_business_month_completion",
    "description": "Adjusts the time to midnight in order to regularize the ending point of the business month.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CustomBusinessMonthEnd.rule_code": {
    "new_func": "tailored_trade_period_identifier",
    "description": "Retrieves the identifier for the specific rule that defines the end-of-month working period model. This identifier helps in recognizing the type of business month closure rule being applied.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.DateOffset.copy": {
    "new_func": "duplicate_frequency_instance",
    "description": "Produces a replica of the frequency instance, ensuring that the original object's state is not altered when making modifications to the copy.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CustomBusinessMonthEnd.weekmask": {
    "new_func": "weekday_filter_pattern",
    "description": "Obtains the binary string that illustrates the days of the week considered as valid business days within the month's closing period. This pattern is used to determine which days are included in the custom business schedule.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.DateOffset.freqstr": {
    "new_func": "rhythm_signature",
    "description": "Yields a textual representation of the frequency, encapsulating the temporal pattern in a concise string format.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.DateOffset": {
    "new_func": "TemporalIncrementer",
    "description": "Defines a structure for incrementing dates by a specified span of time, following a particular set of rules akin to those in 'relativedelta' but only through keyword arguments. This structure excludes positional argument usage and discourages the singular 'n' keyword. To check if a specific date aligns with this structure's rules, 'is_on_offset' method is utilized. The 'rollback' and 'rollforward' methods adjust the date to the closest valid one prior to or following the given date. Addition of this object to a date moves it by the defined number of valid periods, adhering to the roll-forward rule for zero periods. Parameters for initialization allow specifying the number of time units, rounding down to midnight, selecting a day of the week, or using additional temporal patterns to augment or override the initial time span. This object supports a multitude of temporal parameters, from years down to nanoseconds, or allows setting specific components of a timestamp.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.DateOffset.is_anchored": {
    "new_func": "unit_frequency_checker",
    "description": "Determines if the frequency represents a singular unit interval. It checks whether the frequency interval value equals one. This method is outdated and should be replaced with a direct comparison of the interval value to one.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.DateOffset.is_month_end": {
    "new_func": "final_day_checker",
    "description": "Assesses if a given timestamp falls on the concluding day of a month. Inputs: ts (Timestamp) - The point in time to evaluate. Outputs: boolean - True if the timestamp corresponds with the last calendar day of the month, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.DateOffset.is_month_start": {
    "new_func": "initial_day_checker",
    "description": "Evaluates whether a specific timestamp coincides with the initial day of a month. Inputs: ts (Timestamp) - The point in time to evaluate. Outputs: boolean - True if the timestamp aligns with the first calendar day of the month, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.DateOffset.is_quarter_end": {
    "new_func": "quarterly_terminus_checker",
    "description": "Determines if a given timestamp corresponds with the termination of a quarter. Inputs: ts (Timestamp) - The point in time to assess. Outputs: boolean - True if the timestamp matches the final day of a fiscal quarter, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.DateOffset.is_on_offset": {
    "new_func": "frequency_intersection_detector",
    "description": "Checks if a timestamp intersects with the specified frequency. Parameters: dt (datetime.datetime) - The point in time to check for intersections. Returns: boolean - True if there is an intersection, False otherwise.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.DateOffset.kwds": {
    "new_func": "offset_additional_parameters",
    "description": "Retrieves a dictionary containing supplementary arguments for the temporal adjustment.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.DateOffset.is_year_end": {
    "new_func": "timestamp_at_annual_closure",
    "description": "Evaluates if a given moment in time coincides with the final day of the calendar year. Parameters: ts (timestamp) - The moment to assess. Returns: bool - True if the moment is the last day of the year, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.DateOffset.is_year_start": {
    "new_func": "timestamp_at_annual_inception",
    "description": "Determines if a specific moment falls on the initial day of the calendar year. Parameters: ts (timestamp) - The moment to verify. Returns: bool - True if the moment is the first day of the year, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.DateOffset.is_quarter_start": {
    "new_func": "timestamp_at_quarter_commencement",
    "description": "Checks whether a particular moment corresponds with the beginning of a financial quarter. Parameters: ts (timestamp) - The time point to check. Returns: bool - True if the moment marks the start of a quarter, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.DateOffset.name": {
    "new_func": "frequency_identifier",
    "description": "Obtains the string that signifies the foundational frequency for the offset.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.DateOffset.nanos": {
    "new_func": "DateOffset_nano_intervals",
    "description": "Provides the nanosecond count for the offset.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.DateOffset.normalize": {
    "new_func": "standardize_time",
    "description": "Adjusts the offset to a standardized midnight timestamp.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Day": {
    "new_func": "daily_advancement",
    "description": "Advances a date by a specified number of days. Input: n (int, default is 1) - The quantity of days to advance. Output: An offset object representing the daily shift.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Day.n": {
    "new_func": "offset_increment",
    "description": "Retrieves the magnitude of the temporal offset. Returns: int - The number representing the offset's magnitude.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Day.kwds": {
    "new_func": "additional_offset_params",
    "description": "Obtains supplementary keyword arguments applicable to the temporal offset. Returns: dict - A dictionary containing the additional keyword arguments.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Day.name": {
    "new_func": "frequency_designator",
    "description": "Yields the designation for the primary interval used by the offset. Returns: str - A string that denotes the fundamental interval.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Easter.freqstr": {
    "new_func": "periodicity_representation",
    "description": "Produces a textual expression that symbolizes the recurrence rate of an event.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Easter.is_month_start": {
    "new_func": "commencement_of_month_check",
    "description": "Evaluates if a specific point in time corresponds with the initial day of a month. It takes a timestamp as an input and yields a truth value indicating the alignment with the first day of the month. Parameters: ts (datetime) - The point in time to assess. Returns: bool - True if the timestamp coincides with the month's commencement, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Easter.is_month_end": {
    "new_func": "termination_of_month_check",
    "description": "Determines if a given moment in time matches with the concluding day of a month. It accepts a timestamp and provides a boolean indicating whether the timestamp aligns with the month's final day. Parameters: ts (datetime) - The moment in time to evaluate. Returns: bool - True if the timestamp aligns with the month's termination, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Easter.is_on_offset": {
    "new_func": "alignment_with_frequency_check",
    "description": "Assesses whether a particular instant in time intersects with a pre-defined recurrence interval. Parameters: dt (datetime) - The instant in time to verify the intersection. Returns: bool - True if the datetime intersects with the specified frequency, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Easter.is_quarter_end": {
    "new_func": "culmination_of_quarter_check",
    "description": "Verifies if a temporal data point falls on the last day of a financial quarter. Parameters: ts (datetime) - The temporal data point to inspect. Returns: bool - True if the timestamp coincides with the quarter's culmination, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.FY5253.copy": {
    "new_func": "duplicate_interval",
    "description": "Generates an identical clone of the current interval object.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.FY5253.get_rule_code_suffix": {
    "new_func": "retrieve_code_terminator",
    "description": "Fetches the suffix of the rule code for the given interval.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.FY5253.get_year_end": {
    "new_func": "compute_fiscal_year_closure",
    "description": "Calculates the terminal date of the fiscal year for a specified date.",
    "parameters": {
      "dt": "datetime-like - The date for which to calculate the fiscal year end."
    },
    "returns": "datetime - The closing date of the fiscal year for the provided date.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.FY5253.is_anchored": {
    "new_func": "unit_frequency_check",
    "description": "Evaluates whether the interval has a single-period frequency.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.FY5253.is_quarter_end": {
    "new_func": "terminates_on_quarter_closure",
    "description": "Determines if a given timestamp coincides with the closure of a fiscal quarter. Parameters: ts (timestamp) - The moment in time to check. Returns: bool - True if the timestamp aligns with the final day of a fiscal quarter, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.FY5253.is_year_start": {
    "new_func": "commences_on_annual_inception",
    "description": "Assesses if a specific timestamp corresponds with the commencement of a fiscal year. Parameters: ts (timestamp) - The point in time to evaluate. Returns: bool - True if the timestamp falls on the initial day of a fiscal year, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.FY5253.is_quarter_start": {
    "new_func": "initiates_on_quarter_inauguration",
    "description": "Checks if a particular timestamp coincides with the inauguration of a fiscal quarter. Parameters: ts (timestamp) - The instant to verify. Returns: bool - True if the timestamp marks the beginning of a fiscal quarter, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.FY5253.rule_code": {
    "new_func": "frequency_standard_code",
    "description": "Acquires the code that specifies the frequency standard. Returns: str - The code delineating the frequency rule.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.FY5253.kwds": {
    "new_func": "fiscal_year_params",
    "description": "Retrieves a dictionary containing additional parameters relevant to the fiscal year offset calculation.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.FY5253.normalize": {
    "new_func": "standardize_fiscal_timestamp",
    "description": "Adjusts the fiscal year offset to the standard midnight time.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.FY5253.nanos": {
    "new_func": "fiscal_nano_count",
    "description": "Provides the number of nanoseconds that represent the fiscal year offset.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.FY5253.startingMonth": {
    "new_func": "fiscal_inception_month",
    "description": "Identifies the month designated as the commencement of the fiscal period.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.FY5253.variation": {
    "new_func": "fiscal_year_pattern",
    "description": "Specifies the type of fiscal year pattern being used, such as whether it follows a last weekday rule or a nearest weekday rule.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.FY5253.weekday": {
    "new_func": "fiscal_quintet_reference_day",
    "description": "Retrieves the specific day of the week designated for the ending of a 52-53 week fiscal period. This day serves as a consistent marker for the conclusion of the fiscal interval. Parameters: None. Returns: int - An integer representing the day of the week, where 0 is Monday and 6 is Sunday.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.FY5253Quarter.copy": {
    "new_func": "duplicate_fiscal_quarter_offset",
    "description": "Produces a replica of the current business quarter offset object, ensuring that modifications to the new instance don't affect the original. Parameters: None. Returns: A new instance of the business quarter offset object.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.FY5253Quarter": {
    "new_func": "fiscal_trimester_incrementor",
    "description": "Defines an object that represents the progression between business trimester dates in a specialized annual schedule which may consist of either 52 or 53 weeks. This schedule is particularly useful for industries that require their accounting period to conclude on a consistent weekly marker. Parameters: n (int) - The count of business trimesters to represent. normalize (bool, default False) - Whether to set start/end dates to midnight before generating a date range. reference_day (int, default 0) - An integer for the designated day of the week. final_month (int, default 1) - The month at year's end. special_trimester (int, default 1) - The trimester number that may include an additional or 14th week. adjustment_style (str, default 'nearest') - The method of applying the specialized annual schedule, with options 'nearest' or 'last'. Returns: An object that indicates the particular progression of business trimesters.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.FY5253Quarter.is_anchored": {
    "new_func": "unitary_fiscal_quarter_check",
    "description": "Checks if the frequency object represents a single unit frequency (n=1) for fiscal quarter offsets. Note: This method is deprecated as of version 2.2.0 and will be removed in future releases. Use the condition 'obj.n == 1' instead to achieve the same result. Parameters: None. Returns: bool - True if it's a unit frequency, False otherwise.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.FY5253Quarter.freqstr": {
    "new_func": "fiscal_quarter_ticker",
    "description": "Provides a textual representation of the business quarter frequency. Parameters: None. Returns: str - A string describing the frequency.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.FY5253Quarter.get_rule_code_suffix": {
    "new_func": "quarterly_code_postfix",
    "description": "Retrieves the identifying postfix for a financial quarter rule based on the specified frequency convention. No parameters are required for this method. The method returns a string representing the postfix.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.FY5253Quarter.get_weeks": {
    "new_func": "fetch_quarter_weeks",
    "description": "This method calculates the number of weeks in the financial quarter of a specific date. Parameters: dt (datetime-like) - The date for which the number of weeks is to be found. Returns: integer - The count of weeks.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.FY5253Quarter.is_month_start": {
    "new_func": "init_month_check",
    "description": "Evaluates if a given timestamp coincides with the commencement of a month. Parameters: ts (timestamp) - The timestamp to be assessed. Returns: boolean - True if the timestamp is at the beginning of a month, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.FY5253Quarter.is_month_end": {
    "new_func": "termination_month_check",
    "description": "Assesses if a specific timestamp corresponds with the conclusion of a month. Parameters: ts (timestamp) - The timestamp to evaluate. Returns: boolean - True if it is the final day of a month, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.FY5253Quarter.is_on_offset": {
    "new_func": "frequency_intersection_check",
    "description": "Determines if a particular timestamp intersects with the frequency defined by the financial quarter. Parameters: dt (datetime.datetime) - The timestamp to verify against the frequency. Returns: boolean - True if there is an intersection, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.FY5253Quarter.name": {
    "new_func": "fiscal_quarter_identifier",
    "description": "Provides an identifier for the base frequency of a 52-53 week fiscal quarter.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.FY5253Quarter.nanos": {
    "new_func": "fiscal_quarter_nanoseconds",
    "description": "Gives the nanosecond duration of the fiscal quarter offset.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.FY5253Quarter.n": {
    "new_func": "fiscal_quarter_multiplier",
    "description": "Retrieves the multiplier for the fiscal quarter offset object.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.FY5253Quarter.qtr_with_extra_week": {
    "new_func": "additional_week_indicator",
    "description": "Indicates whether the fiscal quarter contains an extra week.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.FY5253Quarter.normalize": {
    "new_func": "align_to_midnight",
    "description": "Adjusts the fiscal quarter offset to align with the start of the day (midnight).",
    "class": "tseries"
  },
  "pandas.tseries.offsets.FY5253Quarter.rule_code": {
    "new_func": "quarterly_pattern_identifier",
    "description": "Accessor for the identifier code of the fiscal quarter pattern, conforming to a 52-53 week year.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Hour.freqstr": {
    "new_func": "hourly_interval_notation",
    "description": "Provides a textual representation of the hourly interval frequency.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.FY5253Quarter.variation": {
    "new_func": "quarterly_shift_type",
    "description": "Accessor for the type of shift applied to the fiscal quarter, indicating whether it is a 'nearest' or 'last' variation.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Hour.copy": {
    "new_func": "duplicate_hourly_offset",
    "description": "Creates an exact replica of the hourly offset object.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Hour.is_month_end": {
    "new_func": "terminal_day_check",
    "description": "Evaluates if a given timestamp falls on the final day of a month. Input: ts (timestamp) - The timestamp to check. Returns: bool - True if timestamp is at the end of the month, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Hour.is_year_end": {
    "new_func": "final_moment_check",
    "description": "Determines if a given timestamp occurs on the last day of the calendar year. Input: ts (Timestamp) - the timestamp to check. Returns: bool - True if the timestamp is on the final day of the year, false otherwise.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Hour.kwds": {
    "new_func": "additional_args_dict",
    "description": "Retrieves a dictionary containing extra parameters relevant to the temporal offset. Returns: dict - A dictionary of additional keyword arguments.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Hour.name": {
    "new_func": "basic_frequency_label",
    "description": "Yields a text representation of the fundamental frequency interval. Returns: str - A string denoting the primary frequency.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Hour.nanos": {
    "new_func": "nanosecond_total",
    "description": "Provides the aggregate count of nanoseconds for the hourly offset. It may raise an exception if the frequency is irregular. Returns: int - The sum of nanoseconds.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Hour.n": {
    "new_func": "frequency_multiplier",
    "description": "Acquires the multiplier used for the hourly offset. Returns: int - The multiplier value.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.LastWeekOfMonth.is_anchored": {
    "new_func": "fixed_single_unit_check",
    "description": "Determines if the frequency interval is singular. This method is set to be retired in subsequent updates and can be replaced by directly checking if the interval value equals one. Parameters: None. Returns: bool - True if the interval is singular, False otherwise.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.LastWeekOfMonth.is_month_end": {
    "new_func": "final_day_occurrence",
    "description": "Checks if a given timestamp corresponds to the final day of a month. Parameters: ts (Timestamp) - The moment in time to be checked. Returns: bool - True if it coincides with the last day of a month, False otherwise.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.LastWeekOfMonth.freqstr": {
    "new_func": "interval_representation",
    "description": "Provides a textual representation of the interval frequency. Parameters: None. Returns: str - A string describing the frequency.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.LastWeekOfMonth.is_month_start": {
    "new_func": "initial_day_evidence",
    "description": "Assesses whether a provided timestamp aligns with the initial day of the month. Parameters: ts (Timestamp) - The date and time to assess. Returns: bool - True if it matches the first day of a month, False otherwise.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.LastWeekOfMonth.n": {
    "new_func": "final_week_monthly_position",
    "description": "Retrieves the integer indicating the week position within the final week of the month for a given frequency offset instance.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.LastWeekOfMonth.normalize": {
    "new_func": "standardize_final_week",
    "description": "Adjusts the time component of the DateOffset to midnight. This process sets the hour, minute, second, and microsecond attributes to zero, effectively normalizing the time to the start of the day.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.LastWeekOfMonth.name": {
    "new_func": "identifier_of_frequency",
    "description": "Obtains the textual identifier that represents the base periodicity of the offset. Outputs the designation as a string.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.LastWeekOfMonth.rule_code": {
    "new_func": "periodicity_abbreviation",
    "description": "Fetches the abbreviated identification code that relates to the offset's rule.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.LastWeekOfMonth.nanos": {
    "new_func": "nanosecond_interval",
    "description": "Provides the number of nanoseconds that make up the DateOffset.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Micro.kwds": {
    "new_func": "microscopic_parameters",
    "description": "Retrieves a dictionary containing supplementary configuration details for the time increment.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Micro.n": {
    "new_func": "microscopic_count",
    "description": "Gets the attribute representing the number of microsecond increments.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Micro.rule_code": {
    "new_func": "microscopic_identifier",
    "description": "Obtains the short string that signifies the base frequency of the time span.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Micro.normalize": {
    "new_func": "standardize_microscopic",
    "description": "Adjusts the microsecond offset to the midnight of the same day.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Micro.name": {
    "new_func": "designation_microscopic",
    "description": "Fetches the textual label denoting the primary periodicity.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Milli.is_month_end": {
    "new_func": "millisecond_terminal_day_check",
    "description": "Determines if a given millisecond timestamp falls on the final day of a month. Input: ts (Timestamp) - The timestamp to evaluate. Returns: bool - True if the timestamp coincides with the last day, False otherwise.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Milli.is_month_start": {
    "new_func": "millisecond_initial_day_check",
    "description": "Assesses if a particular millisecond timestamp aligns with the first day of a month. Input: ts (Timestamp) - The timestamp to assess. Returns: bool - True if it aligns with the commencement of the month, False otherwise.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Milli.is_quarter_end": {
    "new_func": "millisecond_quarter_closure",
    "description": "Evaluates if a specific millisecond timestamp corresponds with the termination point of a calendar quarter. Input: ts (Timestamp) - The timestamp under scrutiny. Returns: bool - Indicator of whether the timestamp marks the quarter's end.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Milli.is_anchored": {
    "new_func": "millisecond_fixed_point_status",
    "description": "Previously denoted whether a millisecond frequency was considered fixed. Deprecated: This method is obsolete and will be omitted in forthcoming releases. Always returns the boolean value False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Milli.is_quarter_start": {
    "new_func": "millisecond_quarter_inception",
    "description": "Verifies whether a millisecond timestamp denotes the initiation of a quarter period. Input: ts (Timestamp) - The timestamp in question. Returns: bool - True if the timestamp signals the start of a quarter, False otherwise.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Milli.is_year_end": {
    "new_func": "millisecond_closes_annum",
    "description": "Determines if a given timestamp coincides with the final moment of the calendar year. Parameters: ts (Timestamp) - The point in time to evaluate. Returns: bool - True if the timestamp aligns with the conclusion of the year, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Milli.is_year_start": {
    "new_func": "millisecond_commences_annum",
    "description": "Assesses if a particular timestamp matches the initial instant of the year. Parameters: ts (Timestamp) - The moment in time to check. Returns: bool - True if the timestamp coincides with the outset of the year, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Milli.name": {
    "new_func": "millisecond_frequency_alias",
    "description": "Retrieves the textual representation of the foundational rhythm. Returns: str - The designation of the base cadence.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Milli.kwds": {
    "new_func": "millisecond_additional_params",
    "description": "Procures a compilation of supplementary arguments for the temporal adjustment. Returns: dict - A mapping of extra parameters.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Milli.n": {
    "new_func": "millisecond_offset_multiplier",
    "description": "Obtains the scalar factor that modifies the millisecond increment. Returns: int - The multiplier for the millisecond increment.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Milli.rule_code": {
    "new_func": "millisecond_standard_identifier",
    "description": "Retrieves the standard abbreviation for millisecond-based time offsets. It is a concise code representing the frequency of the offset.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Milli.normalize": {
    "new_func": "millisecond_time_uniformity",
    "description": "Adjusts the millisecond timestamp to midnight. This method sets the time component of a timestamp to 00:00:00, effectively normalizing any intra-day time to the start of the day.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Milli.nanos": {
    "new_func": "millisecond_nano_count",
    "description": "Calculates the total count of nanoseconds encapsulated by a single millisecond increment. It returns an integer denoting this quantity. An error is raised if the frequency is not consistent.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Minute": {
    "new_func": "time_quantum_minute",
    "description": "Represents a specific span measured in minutes. It allows for specifying the quantity of minutes to offset a time stamp. Input: n (integer, default 1) - The count of minutes to use in the time increment.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Minute.is_month_end": {
    "new_func": "final_minute_check",
    "description": "Evaluates if a given timestamp falls on the final minute of a calendar month. It returns a Boolean value indicating the result of this assessment.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Minute.delta": {
    "new_func": "time_unit_interval",
    "description": "Retrieves the duration between two consecutive time units in the form of a timedelta object.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Minute.freqstr": {
    "new_func": "time_unit_designation",
    "description": "Produces a textual representation of the temporal frequency associated with the time unit.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Minute.is_on_offset": {
    "new_func": "timestamp_alignment_check",
    "description": "Evaluates whether a given point in time aligns with the specified temporal frequency. Parameters: ts (datetime.datetime) - The point in time to assess. Returns: bool - Indicates if there is an alignment with the frequency.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Minute.copy": {
    "new_func": "temporal_unit_replication",
    "description": "Generates an exact duplicate of the current temporal frequency instance.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.MonthBegin.copy": {
    "new_func": "initial_month_duplicate",
    "description": "Produces a replica of the current frequency instance.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Minute.rule_code": {
    "new_func": "sixty_second_identifier",
    "description": "Retrieves the identifier corresponding to the one-minute interval frequency.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.MonthBegin.is_month_end": {
    "new_func": "start_month_finish_check",
    "description": "Determines if a given timestamp coincides with the final day of a month. Parameters: ts (Timestamp) - The timestamp to evaluate. Returns: bool - True if the timestamp is the last day of the month, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.MonthBegin.freqstr": {
    "new_func": "commencement_month_sequence_representation",
    "description": "Yields a textual representation of the interval frequency.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.MonthBegin": {
    "new_func": "inaugural_monthly_offset",
    "description": "Represents a date shift to the nearest date marking the commencement of a month. It moves forward to the subsequent date that is the initial day of a month. Parameters: n (int, default 1) - The count of months to shift. normalize (bool, default False) - Whether to set the start and end dates to midnight prior to generating a date range.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.MonthBegin.is_quarter_end": {
    "new_func": "terminal_of_quarter_check",
    "description": "Evaluates if a specific timestamp aligns with the terminal day of a quarter. Input: ts (timestamp) - The timestamp to be evaluated. Returns: bool - True if the timestamp falls on the last day of a quarter, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.MonthBegin.kwds": {
    "new_func": "additional_params_retriever",
    "description": "Retrieves a dictionary containing supplementary parameters associated with the time offset. Returns: dict - A dictionary of extra keyword arguments.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.MonthBegin.is_anchored": {
    "new_func": "unit_frequency_validator",
    "description": "Determines if the frequency represents a solitary unit (n=1). Note: This function is deprecated and will be eliminated in a future version. It is recommended to use 'obj.n == 1' instead. Returns: bool - True if the frequency is a single unit frequency, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.MonthBegin.is_year_end": {
    "new_func": "culmination_of_year_check",
    "description": "Verifies if a given timestamp corresponds with the last day of the year. Input: ts (timestamp) - The timestamp to be verified. Returns: bool - True if the timestamp is on the final day of a year, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.MonthBegin.nanos": {
    "new_func": "init_month_nanoseconds",
    "description": "Provides the nanosecond count at the commencement of a monthly period.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.MonthBegin.rule_code": {
    "new_func": "initial_month_identifier",
    "description": "Generates a concise alphanumeric identifier for the beginning of a monthly period.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.MonthEnd.freqstr": {
    "new_func": "termination_month_frequency",
    "description": "Yields a textual representation that specifies the interval pattern of the concluding monthly date.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.MonthEnd": {
    "new_func": "conclude_month_offset",
    "description": "Creates an object that represents a shift to the subsequent date marking the cessation of a month. The shift magnitude is specified by an integer count, where the default value is one. Additionally, there is an option to adjust the start and termination dates to the zero hour for date range generation.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.MonthBegin.normalize": {
    "new_func": "commence_month_standardize",
    "description": "Adjusts the starting point of a monthly period to the initial moment of the day.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.MonthEnd.is_anchored": {
    "new_func": "fixed_monthly_frequency_check",
    "description": "Determines if the interval for month's end is set to a single period. Note that this method is deprecated and may be removed in upcoming versions. It is recommended to compare the frequency parameter to 1 as an alternative.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.MonthEnd.is_quarter_start": {
    "new_func": "commencement_of_quarter_check",
    "description": "Evaluates if a given datetime instance coincides with the commencement of a financial quarter. Input arguments: ts (Timestamp) - The datetime instance to check. Returns: bool - True if the timestamp aligns with the start of a quarter, False otherwise.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.MonthEnd.is_year_end": {
    "new_func": "closure_of_annum_check",
    "description": "Assesses if a specific datetime instance corresponds to the final day of the calendar year. Input arguments: ts (Timestamp) - The datetime instance to evaluate. Returns: bool - True if the timestamp marks the end of a year, False otherwise.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.MonthEnd.n": {
    "new_func": "monthly_interval_count",
    "description": "Retrieves the number of month-end intervals.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.MonthEnd.is_year_start": {
    "new_func": "MonthEnd_commences_annual_cycle",
    "description": "Determines if a given timestamp coincides with the commencement of the annual cycle. Parameters: ts (Timestamp) - The timestamp to evaluate. Returns: bool - True if the timestamp is at the start of the year, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.MonthEnd.nanos": {
    "new_func": "MonthEnd_nano_intervals",
    "description": "Retrieves the nanosecond duration for the specified month-end frequency. Returns: int - The number of nanoseconds.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.MonthEnd.name": {
    "new_func": "base_interval_label",
    "description": "Acquires the textual representation of the fundamental interval. Returns: str - The name denoting the base frequency.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.MonthEnd.rule_code": {
    "new_func": "interval_code",
    "description": "Obtains the code that symbolizes the interval's rule. Returns: str - The code representing the rule of the frequency interval.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.MonthEnd.normalize": {
    "new_func": "standardize_timestamp",
    "description": "Adjusts the given timestamp to the start of the day as per the standard time (00:00:00). Returns: Timestamp - The normalized timestamp.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Nano.copy": {
    "new_func": "duplicate_time_unit",
    "description": "Creates a duplicate of the current frequency instance.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Nano.delta": {
    "new_func": "time_span_difference",
    "description": "Retrieves the time span difference represented by the frequency instance.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Nano": {
    "new_func": "time_increment_quantum",
    "description": "Represents a specific quantum of time incrementation at the nanosecond level. Parameter: n (integer, default 1) - The quantity of nanosecond increments to represent.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Nano.freqstr": {
    "new_func": "temporal_frequency_notation",
    "description": "Generates a textual representation of the temporal frequency.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Nano.is_anchored": {
    "new_func": "fixed_position_check",
    "description": "Checks if the frequency is fixed in position. Always returns False. Note: This attribute is deprecated and will be removed in future releases. Directly use False in its place.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Nano.is_quarter_end": {
    "new_func": "nano_period_closure",
    "description": "Determines if a specified timestamp signifies the cessation of a fiscal quarter. Parameters: ts (Timestamp) - The moment in time to evaluate. Returns: bool - True if the provided timestamp marks the end of a quarter, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Nano.n": {
    "new_func": "nano_coefficient",
    "description": "Accesses the scalar integer multiplier affiliated with the nanosecond offset. Returns: int - The multiplier value.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Nano.is_year_start": {
    "new_func": "initial_annual_moment",
    "description": "Checks if a given timestamp coincides with the commencement of a calendar year. Parameters: ts (Timestamp) - The point in time to inspect. Returns: bool - True if the timestamp aligns with the start of the year, False otherwise.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Nano.normalize": {
    "new_func": "standardize_nano_timestamps",
    "description": "Standardizes the timestamp to the beginning of the day (midnight). This operation is beneficial when dealing with time series data that requires consistent start times for comparison or arithmetic operations.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Nano.nanos": {
    "new_func": "total_nanoseconds_count",
    "description": "Calculates the total count of nanoseconds represented by the frequency instance. If the frequency is irregular, a ValueError will be raised.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.QuarterBegin": {
    "new_func": "fiscal_period_start_incrementer",
    "description": "Advances dates to the beginning of the next fiscal quarter. The increment can be adjusted to target specific months as the start of the fiscal quarter. Parameters include the number of periods to shift, whether to set the time to midnight, and which month marks the beginning of the quarter. Returns a date offset for the specified fiscal quarter start.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.QuarterBegin.freqstr": {
    "new_func": "periodicity_descriptor",
    "description": "Retrieves a textual representation of the interval's periodicity used in time series analysis.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.QuarterBegin.copy": {
    "new_func": "duplicate_quarter_commencement",
    "description": "Produces a duplicate of the current quarterly initiation point. This method is useful when an immutable replication is required for further operations without altering the original instance.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.QuarterBegin.is_month_end": {
    "new_func": "terminates_monthly_cycle",
    "description": "Assesses whether a given temporal point coincides with the final day of a month. It accepts a timestamp and returns a truth value indicating the alignment with the monthly cycle's conclusion.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.QuarterBegin.is_on_offset": {
    "new_func": "aligns_with_interval",
    "description": "Evaluates the coincidence of a specific datetime instance with the established periodicity. The function accepts a datetime object and returns a boolean indicating whether it intersects with the defined frequency interval.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.QuarterBegin.is_quarter_end": {
    "new_func": "culminates_quarterly_period",
    "description": "Determines if a temporal marker corresponds with the cessation of a financial quarter. This function checks a timestamp against the quarterly calendar and returns a boolean indicating the occurrence at the quarter's end.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.QuarterBegin.is_quarter_start": {
    "new_func": "commences_quarterly_period",
    "description": "Verifies whether a specific time point signifies the onset of a quarter. The function receives a timestamp and returns a boolean signifying whether the time point matches the start of a quarterly cycle.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.QuarterBegin.is_anchored": {
    "new_func": "fixed_interval_check",
    "description": "Determines if the frequency is set to a single unit interval. This method is obsolete and may be removed in later updates. Instead, verify if 'obj.n' equals 1.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.QuarterBegin.is_year_start": {
    "new_func": "commencement_of_year",
    "description": "Checks if a given datetime instance falls on the initial day of a year. Parameters: ts (datetime) - The datetime to check. Returns: bool - True if the datetime is the first day of a year, False otherwise.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.QuarterBegin.kwds": {
    "new_func": "additional_parameters",
    "description": "Retrieves a dictionary containing supplementary arguments for the time offset. Returns: dict - A dictionary of additional arguments.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.QuarterBegin.normalize": {
    "new_func": "standardize_quarter_start",
    "description": "Adjusts the initial moment of a period to the beginning of the day. This is useful for normalizing date-time values to a consistent reference point, typically midnight. Parameters: None. Returns: The adjusted QuarterBegin object with the time standardized.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.QuarterBegin.is_year_end": {
    "new_func": "terminus_annum_check",
    "description": "Evaluates whether a given timestamp coincides with the final day of the calendar year. Parameters: ts (Timestamp) - The date-time value to assess. Returns: bool - True if the timestamp corresponds with the last day of the year, False otherwise.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.QuarterBegin.n": {
    "new_func": "incremental_period_count",
    "description": "Represents the quantity of quarter start periods to apply. It is an integral value that indicates the number of periods to be added or subtracted. Parameters: None. Returns: int - The number of periods.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.QuarterBegin.nanos": {
    "new_func": "nano_interval_value",
    "description": "Provides the nanosecond duration for the quarter commencement offset. This figure represents the smallest time unit for the offset. Parameters: None. Returns: int - The nanosecond count.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.QuarterBegin.rule_code": {
    "new_func": "commencement_identifier",
    "description": "Yields an abbreviation that signifies the rule for the quarter's starting offset. This code is a shorthand representation used in time series frequency specification. Parameters: None. Returns: str - The abbreviated rule code.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.QuarterEnd.startingMonth": {
    "new_func": "initial_month_quarterly_termination",
    "description": "Retrieves the month when each quarter period commences. This attribute assists in determining the alignment of the quarterly period relative to the calendar months.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.QuarterEnd.nanos": {
    "new_func": "nanosecond_duration_quarter_closure",
    "description": "Accords the nanosecond duration of the quarter's conclusion. It is the representation of the offset's nanoseconds portion.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.QuarterEnd.rule_code": {
    "new_func": "code_of_terminus_criterion",
    "description": "Yields the conventional code that symbolizes the specific rule for the quarter's end. This code is typically used in frequency strings.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Second": {
    "new_func": "time_shift_seconds",
    "description": "Represents a time displacement over a specified number of seconds. The shift magnitude is adjustable and defaults to a single second increment.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.QuarterEnd.normalize": {
    "new_func": "standardize_quarter_expiry",
    "description": "Adjusts the quarter conclusion to a standardized time, typically the stroke of midnight. This process ensures that the end time is regular irrespective of the specific time when the adjustment is applied.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Second.delta": {
    "new_func": "timeframe_span",
    "description": "Accesses the time duration that the object represents, expressed in the standard time unit for the object's granularity.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Second.is_month_start": {
    "new_func": "inaugural_of_month",
    "description": "Evaluates a given timestamp to ascertain if it coincides with the initial day of a month, returning a boolean indicative of this condition. Parameters: ts (Timestamp) - The point in time to analyze. Returns: bool - True if the timestamp is the first day of the month, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.SemiMonthBegin.freqstr": {
    "new_func": "biweekly_start_frequency_representation",
    "description": "provides a textual representation of the biweekly start frequency. It encapsulates the period into a string format.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.SemiMonthBegin.is_anchored": {
    "new_func": "unit_interval_check",
    "description": "evaluates whether the offset frequency corresponds to a single period interval. It returns a boolean indicating this state. Note: This method is deprecated and should be replaced with a check of whether the offset number is equal to one.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.SemiMonthBegin.is_on_offset": {
    "new_func": "intersects_with_biweekly_start",
    "description": "assesses if a particular datetime aligns with the defined biweekly start period. It takes a datetime object as input and returns a boolean indicating the alignment.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.SemiMonthBegin.is_month_end": {
    "new_func": "coincides_with_month_closure",
    "description": "determines if a given datetime falls on the last day of a month. It accepts a datetime object and yields a boolean result.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.SemiMonthBegin.is_quarter_end": {
    "new_func": "aligns_with_quarter_termination",
    "description": "ascertains whether a specified datetime occurs at the end of a financial quarter. The function takes a datetime object as an argument and returns a boolean indicating the occurrence.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.SemiMonthBegin.n": {
    "new_func": "mid_month_start_multiplier",
    "description": "Retrieves the number that represents the ordinal position of a semi-monthly period's commencement.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.SemiMonthBegin.name": {
    "new_func": "bi_monthly_onset_label",
    "description": "Provides a textual label that characterizes the base rate of recurrence for events that occur twice a month at the beginning.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.SemiMonthBegin.normalize": {
    "new_func": "standardize_mid_month_onset",
    "description": "Adjusts the starting point of a semi-monthly period to the midnight timestamp, ensuring a consistent time of day across all instances.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.SemiMonthBegin.nanos": {
    "new_func": "bi_monthly_onset_nanos",
    "description": "Returns the quantity of nanoseconds that encapsulate the duration of the period initiating at the semi-month start.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.SemiMonthBegin.rule_code": {
    "new_func": "mid_month_initialization_code",
    "description": "Outputs a short alphabetic code that uniquely identifies the semi-monthly starting period within a time series.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.SemiMonthEnd.is_anchored": {
    "new_func": "bi_monthly_boundary_fixed",
    "description": "Determines if the bi-monthly period aligns with a singular increment. Note that this method is obsolete and will be eliminated in subsequent releases. It is suggested to directly check if the period's increment equals one.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.SemiMonthEnd.is_quarter_end": {
    "new_func": "terminal_tri_monthly_phase",
    "description": "Assesses if a given time instant marks the termination of a three-month phase. Input: ts (timestamp) - The time instant to be evaluated. Returns: boolean - True if the time instant falls at the end of a quarterly cycle.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.SemiMonthEnd.is_on_offset": {
    "new_func": "coincides_with_frequency",
    "description": "Determines if a specific time instant intersects with the current bi-monthly interval. Input: dt (datetime) - The time instant to check for intersection with the interval. Returns: boolean - True if there is an intersection with the interval.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.SemiMonthEnd.is_quarter_start": {
    "new_func": "initiation_of_tri_monthly_period",
    "description": "Verifies if a particular time instant signifies the initiation of a quarterly segment. Input: ts (timestamp) - The time instant to be scrutinized. Returns: boolean - True if the time instant corresponds with the start of a quarterly segment.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.SemiMonthEnd.kwds": {
    "new_func": "bi_monthly_terminal_parameters",
    "description": "Retrieves a dictionary of supplementary arguments for the bi-monthly period's conclusion computation.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.SemiMonthEnd.is_year_end": {
    "new_func": "terminus_annual_check",
    "description": "Evaluates if a given timestamp coincides with the final day of the annum. Parameters: ts (Timestamp) - The point in time to assess. Returns: bool - True if the timestamp coincides with the annum's conclusion, False otherwise.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.SemiMonthEnd.n": {
    "new_func": "bi_monthly_increment",
    "description": "Accesses the integer multiplier associated with the bi-monthly period's end offset.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.SemiMonthEnd.name": {
    "new_func": "bi_monthly_designation",
    "description": "Provides a textual denomination for the principal frequency associated with the bi-monthly period's closure.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.SemiMonthEnd.rule_code": {
    "new_func": "fortnightly_terminus_identifier",
    "description": "Retrieves the identifier for the rule that defines the bi-monthly period's final day.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.SemiMonthEnd.normalize": {
    "new_func": "standardize_fortnight_termination",
    "description": "Modifies the bi-monthly offset to align with midnight.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Tick.freqstr": {
    "new_func": "interval_label",
    "description": "Outputs a textual representation of the interval frequency.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.SemiMonthEnd.nanos": {
    "new_func": "bi_monthly_closure_nanoseconds",
    "description": "Yields the nanosecond count for the bi-monthly period's closure.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Tick.is_quarter_end": {
    "new_func": "final_third_period_check",
    "description": "Determines if a given moment coincides with the final day of a financial quarter. Parameters: ts (Timestamp) - The moment in time to evaluate. Returns: bool - True if the given moment is the last day of a quarter, False otherwise.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Tick.is_month_start": {
    "new_func": "initial_monthly_moment",
    "description": "Evaluates if a specific instant corresponds to the commencement of a calendar month. Parameters: ts (Timestamp) - The point in time to assess. Returns: bool - True if the specified instant is the initial day of a month, False otherwise.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Tick.is_quarter_start": {
    "new_func": "commence_trimester_evaluation",
    "description": "Checks if a particular timestamp matches the beginning of a fiscal trimester. Parameters: ts (Timestamp) - The time point for assessment. Returns: bool - True if the timestamp matches the inception of a quarter, False if not.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Tick.is_year_start": {
    "new_func": "inaugural_annual_instant",
    "description": "Determines whether a timestamp falls on the initial day of the calendar year. Parameters: ts (Timestamp) - The temporal value to check. Returns: bool - Indicates if the timestamp is the first day of the year.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Tick.kwds": {
    "new_func": "additional_offset_attributes",
    "description": "Retrieves a dictionary containing supplementary parameters relevant to the temporal offset. Returns: dict - A mapping of additional offset configuration options.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Tick.n": {
    "new_func": "time_increment_value",
    "description": "Retrieves the magnitude of the time increment.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Tick.nanos": {
    "new_func": "nano_count",
    "description": "Calculates the aggregate count of nanoseconds associated with the time increment. It may raise a ValueError if the time increment is of an irregular frequency.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Tick.rule_code": {
    "new_func": "recurrence_identifier",
    "description": "Provides the symbolic representation associated with the time increment's regulatory principle.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.WeekOfMonth.is_quarter_end": {
    "new_func": "terminus_trimestrial",
    "description": "Determines if a given timestamp coincides with the final day of a fiscal quarter. Parameters: ts (datetime-like) - The point in time to evaluate. Returns: bool - True if the provided timestamp aligns with the close of a quarter.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.WeekOfMonth.is_on_offset": {
    "new_func": "aligns_with_temporal_interval",
    "description": "Assesses whether a given datetime instance coincides with the specified frequency interval. Parameters: dt (datetime.datetime) - The datetime instance to be evaluated. Returns: bool - True if the datetime aligns with the frequency interval.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.WeekOfMonth.is_year_start": {
    "new_func": "commencement_annual",
    "description": "Checks if a specified timestamp matches the initial day of a calendar year. Parameters: ts (datetime-like) - The moment to be checked. Returns: bool - True if the timestamp represents the start of a year.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.WeekOfMonth.is_quarter_start": {
    "new_func": "initium_trimestrial",
    "description": "Verifies if a specific timestamp falls on the inaugural day of a fiscal quarter. Parameters: ts (datetime-like) - The timestamp to verify. Returns: bool - True if the timestamp signifies the onset of a quarter.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.WeekOfMonth.is_year_end": {
    "new_func": "culmination_annual",
    "description": "Determines if a timestamp corresponds to the final day of the calendar year. Parameters: ts (datetime-like) - The point in time for assessment. Returns: bool - True if the timestamp occurs at the year's closing.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.WeekOfMonth.n": {
    "new_func": "shift_multiplier",
    "description": "Accesses the multiplier value used for the temporal adjustment.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.WeekOfMonth.nanos": {
    "new_func": "subsecond_offset",
    "description": "Provides the nanosecond duration component of the time increment.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.WeekOfMonth.normalize": {
    "new_func": "standardize_moment",
    "description": "Adjusts the timestamp to the start of the day at midnight.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.WeekOfMonth.rule_code": {
    "new_func": "monthly_week_identifier",
    "description": "Provides a unique identifier for the specified occurrence of a weekly period within a month. This identifier is primarily used in temporal calculations where specific week instances are considered.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.WeekOfMonth.week": {
    "new_func": "ordinal_week_extractor",
    "description": "Retrieves the ordinal number of the week within the month for a given date offset object. This number indicates the position of the week within its respective month.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.WeekOfMonth.weekday": {
    "new_func": "day_of_week_extractor",
    "description": "Acquires the integer representation of a day within the week for a temporal offset object. This integer corresponds to a particular day, ranging from Monday (0) to Sunday (6).",
    "class": "tseries"
  },
  "pandas.tseries.offsets.YearBegin": {
    "new_func": "start_of_annum_incrementer",
    "description": "Shifts dates to the initial day of the designated year, potentially iterating over multiple years depending on the specified frequency. It can also adjust the time component of the dates to a standardized point (e.g., midnight) when required. Input Parameters: count (integer, default 1) - The total number of annual cycles to be included. standardize (boolean, default False) - Determines if the date and time should be set to a uniform value before range creation. yearly_month (integer, default 1) - Specifies the particular month of the year to consider.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.YearBegin.freqstr": {
    "new_func": "annual_frequency_representation",
    "description": "Yields a textual representation of the periodicity for the commencement of the year. This string can be utilized to comprehend the frequency at which the year's initial day is recognized.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.YearBegin.is_anchored": {
    "new_func": "yearly_frequency_singular",
    "description": "Determines if the frequency object represents a singular yearly increment, specifically when the increment value is one. This function is deprecated and will be removed in subsequent versions, therefore it is recommended to directly check if the increment value equals one.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.YearBegin.copy": {
    "new_func": "clone_yearly_interval",
    "description": "Produces a duplicate of the given yearly frequency object, ensuring an independent instance that can be modified without affecting the original.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.YearBegin.is_month_start": {
    "new_func": "commence_month_check",
    "description": "Evaluates if a given timestamp coincides with the commencement of a month. The function expects a single argument: ts (timestamp) - The point in time to assess. It returns a boolean indicating the result of the assessment.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.YearBegin.is_month_end": {
    "new_func": "conclude_month_check",
    "description": "Assesses if a particular timestamp aligns with the final day of a month. Accepts the following parameter: ts (timestamp) - The moment in time to analyze. The return value is a boolean indicating the outcome of the evaluation.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.YearBegin.nanos": {
    "new_func": "initial_nano_duration",
    "description": "Returns the nanosecond duration for the initial time offset.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.YearEnd": {
    "new_func": "annual_terminus_increment",
    "description": "Advances dates to the subsequent point marking the completion of the calendar year. This class adjusts dates by a specified number of years, optionally normalizing to midnight and can be set to target a specific month's end.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.YearBegin.rule_code": {
    "new_func": "initial_annual_identifier",
    "description": "Retrieves the code that represents the starting point of a calendar year for the given date offset object.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.YearBegin.normalize": {
    "new_func": "commence_annual_standardization",
    "description": "Adjusts the date offset object such that the time component is set to midnight, effectively standardizing it to the start of the day.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.YearEnd.freqstr": {
    "new_func": "terminal_annual_frequency_string",
    "description": "Provides a textual representation of the interval at which the year-end occurs within the given date offset object.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.YearEnd.is_anchored": {
    "new_func": "fixed_yearly_interval_check",
    "description": "Determines if the date offset object represents a fixed interval that occurs exactly once per year.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.YearEnd.copy": {
    "new_func": "duplicate_yearly_terminus",
    "description": "Generates an identical replica of the date offset object that marks the end of the calendar year.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.YearEnd.is_quarter_end": {
    "new_func": "terminates_quarter",
    "description": "Determines if a specified timestamp coincides with the end of a fiscal quarter. Parameters: ts (Timestamp) - The moment in time to evaluate. Returns: bool - True if the timestamp matches the last day of a quarter; otherwise, False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.YearEnd.kwds": {
    "new_func": "additional_params",
    "description": "Retrieves a dictionary encapsulating supplementary arguments for the temporal offset. Returns: dict - A collection of keyword arguments.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.YearEnd.is_year_start": {
    "new_func": "commences_annum",
    "description": "Assesses whether a given timestamp corresponds with the commencement of a calendar year. Parameters: ts (Timestamp) - The point in time to assess. Returns: bool - True if the timestamp marks the first day of a year; otherwise, False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.YearEnd.month": {
    "new_func": "terminal_month",
    "description": "Acquires the month index at which the temporal offset concludes the year. Returns: int - The month number indicating the year's end.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.YearEnd.nanos": {
    "new_func": "nano_duration_year_completion",
    "description": "Retrieves the nanosecond duration for the completion of the calendar year in time-series offset objects.",
    "class": "tseries"
  },
  "pandas.unique": {
    "new_func": "distinct_element_finder",
    "description": "Retrieves an array of unique elements from the provided collection, preserving the order of their first occurrence. It is optimized for performance on long collections and includes any null entries. Input arguments: collection (1d array-like) - A series of elements to process. Return value: array (numpy.array or ExtensionArray) - An array of unique elements which may be of types Index, Categorical, or array depending on the input.",
    "class": "main"
  },
  "pandas.util.hash_array": {
    "new_func": "array_value_encoder",
    "description": "Transforms a one-dimensional series of elements into an array of deterministic integers using a hashing mechanism. Input arguments: elements (array or ExtensionArray) - The array of elements to hash. charset (string, default 'utf8') - The character encoding for strings. key (string, default '0123456789123456') - The hash key used for encoding strings. group_duplicates (bool, default True) - Indicates whether to group identical values before hashing for efficiency. Return value: array (array[np.uint64, ndim=1]) - An array of hashed integers with the same length as the input array.",
    "class": "util"
  },
  "pandas.tseries.offsets.YearEnd.normalize": {
    "new_func": "annual_finish_standardizer",
    "description": "Standardizes the time to midnight for the year-ending time series offset, ensuring a consistent point in time.",
    "class": "tseries"
  },
  "pandas.CategoricalIndex": {
    "new_func": "FactorizedQualitativeIndex",
    "description": "Constructs an index from categorical data, potentially with an order, but not supporting numerical operations. It represents an array of unique values drawn from a finite set of distinct options, known as categories. Each value is assigned to a category and can be sorted if ordered is specified. This type of index does not allow for arithmetic operations.\nParameters:\n- data (array-like, 1-dimensional): The values of the categorical data. If categories are provided, any values not included will be replaced with null.\n- categories (index-like, optional): The distinct categories for the data. These should be unique.\n- ordered (bool, optional): Indicates if the categories have an inherent order.\n- dtype (CategoricalDtype or 'category', optional): The specific dtype for categorization. Cannot be used with categories or ordered arguments.\n- copy (bool, default False): Whether to copy the input array.\n- name (object, optional): The name for the index.\nRaises:\n- ValueError: If the categories are not valid.\n- TypeError: If ordered is set to True without specified categories, and the values are not sortable.",
    "class": "CategoricalIndex"
  },
  "pandas.Categorical.codes": {
    "new_func": "CategoryIndices",
    "description": "Retrieves the integer codes that represent the position of each value within the category array of the categorical data. These codes effectively encode the categorical values as integers for efficient manipulation and retrieval.\nReturns:\n- array[int]: An immutable array of integer codes corresponding to the categories of the data.",
    "class": "Categorical"
  },
  "pandas.CategoricalDtype": {
    "new_func": "QualitativeTypeDescriptor",
    "description": "Defines a data type for categorical data specifying the possible distinct options and whether there is an inherent order to these options. It is used to typecast data into categorical type with or without a specified order.\nParameters:\n- categories (sequence, optional): A unique set of items that cannot contain nulls, forming the categorical options.\n- ordered (bool or None, default False): Specifies if the categorical data should be considered with order or not. None preserves the order status of existing data during operations that combine categorical data.",
    "class": "CategoricalDtype"
  },
  "pandas.Categorical.categories": {
    "new_func": "CategoryLabels",
    "description": "Accesses or assigns a new set of labels to the categories of the categorical data. When assigning, the new labels must be a list-like object with unique items, and the count must match the original number of categories.\nRaises:\n- ValueError: If the new labels are not valid as categories or if their count does not match the original number.",
    "class": "Categorical"
  },
  "pandas.CategoricalDtype.ordered": {
    "new_func": "IsSequenceRanked",
    "description": "Indicates if the categorical data type has an ordering among its values, reflecting whether there is a ranking or hierarchy in the categories.",
    "class": "CategoricalDtype"
  },
  "pandas.CategoricalIndex.as_unordered": {
    "new_func": "category_rank_unfixed",
    "description": "Transforms a categorical index to have its ranking without any inherent order. The result is a categorical collection without a sorted sequence.\nReturns: A categorical collection with order not considered.",
    "class": "CategoricalIndex"
  },
  "pandas.CategoricalIndex.equals": {
    "new_func": "categorical_match",
    "description": "Checks if two categorical indices comprise identical elements.\nReturns: A boolean value indicating whether the elements are equivalent (True) or not (False).",
    "class": "CategoricalIndex"
  },
  "pandas.CategoricalIndex.categories": {
    "new_func": "classifications_accessor",
    "description": "Accesses or assigns new labels to the classifications within a categorical index. The reassignment requires a collection of unique labels with a count equal to the existing number of classifications. An error is raised if the conditions for the new labels are not met.\nThis property acts as a getter and a setter for the classifications.\nRaises: A ValueError if the new labels do not meet required conditions.",
    "class": "CategoricalIndex"
  },
  "pandas.CategoricalIndex.remove_unused_categories": {
    "new_func": "prune_idle_classifications",
    "description": "Eliminates any classifications that are not referenced by the data.\nReturns: A modified categorical object with the extraneous classifications excised.",
    "class": "CategoricalIndex"
  },
  "pandas.CategoricalIndex.codes": {
    "new_func": "index_encodings",
    "description": "Provides the integral identifiers corresponding to the positions of values within the categorical's classifications. The array of these identifiers is immutable.\nReturns: An array-like structure containing integers that map to the categorical's values.",
    "class": "CategoricalIndex"
  },
  "pandas.CategoricalIndex.set_categories": {
    "new_func": "redefine_classifications",
    "description": "Alters the existing classifications to a new set, allowing for addition, removal, or reshuffling of classes. This operation can simultaneously add unused classes or exclude current ones, which may result in undefined values. The method can also be employed to simply alter the names of the classes. Simultaneous operations are more efficient than individual modifications through other specialized procedures. However, it does not perform certain verifications, which could lead to unexpected modifications.\nParameters:\n- new_classes (Index-like): The classifications in a new sequence.\n- is_ordered (bool, optional): Specifies if the classification is to be considered ordered (default is False).\n- is_rename (bool, optional): Determines if the operation is a renaming of classes rather than reordering (default is False).\nReturns:\n- A modified classification with the new specified classes.\nRaises:\n- ValueError: If the new classes do not qualify as valid categories.",
    "class": "CategoricalIndex"
  },
  "pandas.CategoricalIndex.remove_categories": {
    "new_func": "discard_classifications",
    "description": "Excludes specified classes from the classification. The classes to be excluded must be part of the existing classes. Values belonging to the excluded classes will be rendered undefined.\nParameters:\n- exclusions (category or list of categories): The classes to be eliminated.\nReturns:\n- A modified classification excluding the specified classes.\nRaises:\n- ValueError: If the classes to be removed are not part of the existing classification.",
    "class": "CategoricalIndex"
  },
  "pandas.DataFrame.T": {
    "new_func": "matrix_transpose",
    "description": "Generates the transposition of a two-dimensional data structure, reversing the axes.\nReturns:\n- A new data structure with flipped dimensions.",
    "class": "DataFrame"
  },
  "pandas.CategoricalIndex.rename_categories": {
    "new_func": "relabel_classifications",
    "description": "Substitutes the existing classes with new identifiers. The replacement can be a direct one-to-one substitution, a dictionary defining a mapping, or a function that applies the transformation.\nParameters:\n- new_classes (list-like, dict-like, or callable): The new identifiers to replace the old classes. The input structure dictates the replacement logic.\nReturns:\n- A modified classification with updated class labels.\nRaises:\n- ValueError: If the new identifiers do not match the quantity of existing classes or do not constitute valid classes.",
    "class": "CategoricalIndex"
  },
  "pandas.CategoricalIndex.map": {
    "new_func": "transform_classifications",
    "description": "Applies a transformation to the category labels based on a provided mapping or function. The transformation maintains the order property if it is a one-to-one mapping; otherwise, a generic index is returned. Undefined categories result in undefined values.\nParameters:\n- transformer (function, dict, or Series): The rule for transforming the category labels.\nReturns:\n- A transformed index which may be a category index or a generic index, depending on the mapping.",
    "class": "CategoricalIndex"
  },
  "pandas.CategoricalIndex.ordered": {
    "new_func": "sequential_relationship_check",
    "description": "Indicates if the categorical index implies a sequence where the elements have a specific order.",
    "class": "CategoricalIndex"
  },
  "pandas.CategoricalIndex.reorder_categories": {
    "new_func": "recategorize_sequence",
    "description": "Modifies the sequence of categories to a new specified arrangement. All existing categories must be included, and no additional categories can be introduced. The method allows for maintaining or altering the hierarchy of the categories.\\nParameters:\\n- new_sequence (Index-like) - The desired arrangement of categories.\\n- is_sequential (bool, optional) - Specifies if the recategorized sequence should maintain an ordered relationship. Defaults to current state if unspecified.\\nReturns:\\n- Recategorized sequence - A categorical sequence with the new specified order.\\nRaises:\\n- ValueError - If the new sequence does not include all existing categories or introduces new ones.",
    "class": "CategoricalIndex"
  },
  "pandas.DataFrame.__dataframe__": {
    "new_func": "exchange_protocol_object",
    "description": "Generates an object that adheres to the dataframe interchange protocol, which can be utilized by consumers to import the data structure efficiently.\\nParameters:\\n- allow_memory_copy (bool, default True) - Authorizes memory duplication during the export process. If set to False, any operation requiring memory copying will be unsuccessful.\\nReturns:\\n- Interchange protocol object - An object which can be used by the consuming library to import the data structure.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.__add__": {
    "new_func": "accumulate_columnwise",
    "description": "Calculates the column-wise summation of the data structure with another specified object.\\nParameters:\\n- addend (scalar, sequence, Series, dictionary or data structure) - The object to be combined with the data structure.\\nReturns:\\n- Summed data structure - The outcome of the combination operation.",
    "class": "DataFrame"
  },
  "pandas.DataFrame": {
    "new_func": "TwoDimensionalLabeledArray",
    "description": "A mutable, 2D data structure with potentially diverse data types, featuring labeled axes for both dimensions. Functionally comparable to a dictionary of Series, this primary data container is designed for arithmetic operations that align with labels on both axes.\\nParameters:\\n- input_data (array, iterable, dictionary, or data container) - The data source for the structure. Can consist of Series, arrays, or other recognized types. Ordering follows insertion sequence for dictionaries.\\n- row_labels (Index or array-like) - Labels for the rows, defaults to a numerical index if none provided.\\n- column_labels (Index or array-like) - Labels for the columns, defaults to a numerical index if none provided, or selects from the data if present.\\n- enforced_dtype (dtype, optional) - Enforces a single data type, with inference if unspecified.\\n- should_copy (bool or None, optional) - Determines if the data should be duplicated from the input, with default behavior varying based on input type.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.all": {
    "new_func": "entirely_truthful",
    "description": "Determines if every element across a specified dimension holds a truthy value. It returns a boolean indicator for each series or axis, indicating whether all non-NA/null elements meet a truth condition. Empty or entirely null series or axes will also evaluate to true.\nParameters:\n- dimension {0 or 'rows', 1 or 'columns', None}, default 0: The dimension to evaluate.\n- only_boolean bool, default False: Consider only binary columns if set to true.\n- exclude_na bool, default True: Ignore missing values during evaluation.\n- **kwargs: Extra arguments are accepted for compatibility but have no impact on the outcome.\nReturns:\n- Series or DataFrame: A single value, Series, or DataFrame indicating the truth evaluation for each axis or the entire data structure, depending on the dimension specified.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.add_prefix": {
    "new_func": "prepend_labels",
    "description": "Attaches a designated string at the start of each label within the data structure. For one-dimensional structures, this affects row labels, whereas for two-dimensional structures, column labels are modified.\nParameters:\n- affix str: The string to attach at the beginning of each label.\n- dimension {0 or 'rows', 1 or 'columns', None}, default None: The dimension along which to prepend the affix.\nReturns:\n- Series or DataFrame: The modified structure with updated labels.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.asfreq": {
    "new_func": "reindex_frequency",
    "description": "Alters the temporal resolution of a dataset to conform to a new index with a defined regularity. Missing timestamps in the new index compared to the original one will result in missing values unless a filling method is specified.\nParameters:\n- periodicity DateOffset or str: The target interval regularity.\n- filler_method {\u2018backfill\u2019/\u2019bfill\u2019, \u2018pad\u2019/\u2019ffill\u2019}, default None: The technique for populating missing timestamps.\n- anchor_point {\u2018start\u2019, \u2018end\u2019}, default 'end': Applicable for period-indexed data to determine the new index.\n- midnight_reset bool, default False: If true, shifts the new index to start at midnight.\n- fill_value scalar, optional: A value to use when upsampling data to fill new timestamps not present in the original index.\nReturns:\n- Series/DataFrame: The structure with its data conformed to the new index at the specified regularity.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.applymap": {
    "new_func": "elementwise_transform",
    "description": "Executes a specified function element-by-element throughout a two-dimensional structure. This method is deprecated and is recommended to be replaced by element-specific mapping techniques.\nParameters:\n- scalar_func callable: A function that takes and returns a single value.\n- na_strategy {None, \u2018ignore\u2019}, default None: If set to \u2018ignore\u2019, NaN values are not processed by the function.\n- **kwargs: Additional arguments to pass to the function.\nReturns:\n- DataFrame: A two-dimensional structure with each element transformed by the specified function.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.agg": {
    "new_func": "synthesize",
    "description": "Performs one or multiple operations across a chosen axis, summarizing the data with various measures.\nParameters:\n- operation function, str, list, or dict: The aggregation instructions, which could be a function, a string name of a function, a list of functions, or a dictionary mapping axis labels to functions or lists of functions.\n- dimension {0 or 'rows', 1 or 'columns'}, default 0: The axis along which to apply the operation(s).\n- *args: Positional arguments passed to the function.\n- **kwargs: Key-value pairs passed to the function.\nReturns:\n- scalar, Series, or DataFrame: The result can vary from a single value to a Series or DataFrame depending on the input operation(s) and data structure.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.astype": {
    "new_func": "alter_element_format",
    "description": "Converts the elements of the data structure to a different type. This operation can be applied to the entire structure or specified columns. A new copy can be returned if specified. Invalid data type conversions can be handled according to the chosen error handling strategy.\nParameters: dtype - The target type for the conversion, either a singular type for the whole structure or a dictionary specifying conversions per column.\ncopy - A boolean flag indicating whether to return a new copy with the modifications.\nerrors - An option to control the behavior when an invalid conversion occurs, either raising an exception or ignoring the error.\nReturns: A new instance of the same structure type with elements converted to the specified data types.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.attrs": {
    "new_func": "properties_bag",
    "description": "Retrieves a dictionary holding arbitrary metadata attributes of the data container. This feature is in a trial phase and the behavior or existence of this property might be modified in future updates.\nReturns: A dictionary containing the metadata attributes.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.at": {
    "new_func": "scalar_locator",
    "description": "Provides access to an individual element based on its row and column labels, ideal for quick access to a specific cell. This method is optimized for retrieval and modification of a single element in contrast to methods aimed at accessing multiple elements simultaneously.\nRaises: KeyError if the specified labels do not exist, ValueError if the provided labels are not appropriate for a scalar lookup.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.axes": {
    "new_func": "structure_axes_labels",
    "description": "Generates a list containing the labels for the axis dimensions of the data container, with the first entry corresponding to row labels and the second to column labels.\nReturns: A list of index objects representing the axis labels.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.at_time": {
    "new_func": "filter_by_clock",
    "description": "Isolates entries based on a specific clock time, allowing for selection of records occurring at that particular moment within the day.\nParameters: time - The clock time for filtering entries.\naxis - The axis along which to filter, with a default of 0.\nReturns: A subset of the original data structure containing only the rows or columns (depending on the axis) that match the specified time.\nRaises: TypeError if the data structure's index is not date-time based.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.bfill": {
    "new_func": "backward_fill_gaps",
    "description": "Substitutes missing entries by propagating subsequent non-null entries backward across the specified axis. The procedure will replace a set number of missing values as defined by the 'limit' parameter, and can be restricted to a certain area with 'limit_area'. Modifies the object directly if 'inplace' is true; otherwise, returns a modified copy.\nParameters: axis (int or str) - Determines the axis along which to apply the operation.\ninplace (bool) - Whether to alter the original data structure.\nlimit (int) - The maximum count of consecutive missing entries to substitute.\nlimit_area (str or None) - Defines the area within which to apply the limit.\ndowncast (dict or str) - Mapping of items to data types for downcasting, or 'infer' to attempt automatic downcasting.\nReturns: The data structure with missing entries backward filled or None if 'inplace' is true.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.combine": {
    "new_func": "merge_columns_custom",
    "description": "Merges the structure with another using a custom function for element-wise columnar operation. The indices of the resultant structure are the combined set from both structures.\nParameters: other (structure) - The structure to merge with.\nfunc (callable) - The function to apply to pairs of series.\nfill_value (scalar) - The value to use for replacing missing values before applying the function.\noverwrite (bool) - Whether to overwrite columns with missing values in the absence of corresponding columns in the other structure.\nReturns: A new structure with merged columns.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.combine_first": {
    "new_func": "update_nulls_from_another",
    "description": "Integrates two data structures, prioritizing non-null values from the current one and supplementing with values from the other where nulls are present. The index of the resulting structure comprises the combined indices of both.\nParameters: other (structure) - The structure providing replacement values.\nReturns: A new data structure with null values updated from the other.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.compare": {
    "new_func": "contrast_with_other",
    "description": "Generates a comparison against another data structure, highlighting discrepancies. The differences can be displayed along either the rows or columns, and the comparison can be configured to preserve original dimensions or to include only differing or equal values.\nParameters: other (structure) - The data structure to contrast against.\nalign_axis (int or str) - The axis along which to align the comparison.\nkeep_shape (bool) - Whether to maintain the original dimensions or not.\nkeep_equal (bool) - Whether to retain identical values in the comparison output.\nresult_names (tuple) - Names to assign to the data structures in the comparison.\nReturns: A new data structure displaying the differences side by side, with a potentially multi-level index.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.cumprod": {
    "new_func": "sequential_product_accumulation",
    "description": "Computes the progressive multiplication of elements along a specified axis, omitting null values. It outputs an object of identical shape with the accumulated product of each point.\nParameters: \n- axis (int or str): The axis along which to compute the accumulation.\n- skipna (bool): Whether to exclude NA/null values. If a whole row/column is NA, the output will be NA as well.\n- *args, **kwargs: Additional arguments are accepted for compatibility but have no impact on the operation.\nReturns: \n- An object of the same type with the cumulative product computed.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.cumsum": {
    "new_func": "sequential_addition_accumulation",
    "description": "Calculates the progressive addition of elements along a given axis, while ignoring null values. It produces an object with the same dimensions containing the accumulated sum at each position.\nParameters: \n- axis (int or str): The axis along which to perform the summation.\n- skipna (bool): Whether to ignore NA/null values. If the entire row/column is NA, the result will be NA.\n- *args, **kwargs: Extra arguments are permitted for compatibility purposes though they have no effect.\nReturns: \n- An object mirroring the caller's type with the accumulated sum.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.div": {
    "new_func": "elemental_fraction",
    "description": "Performs element-wise division between the object and another specified element, allowing an optional fill value for missing data. This method supports flexible operations equivalent to true division.\nParameters: \n- other (scalar, sequence, Series, dict or another similar object): The dividend in the operation.\n- axis (int or str): Specifies whether to align and compare by the index (0) or columns (1).\n- level (int or label): Matches Index values on the specified MultiIndex level for broadcasting.\n- fill_value (float): Optional value to use for filling missing data before computation.\nReturns: \n- A new object resulting from division operation.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.copy": {
    "new_func": "duplicate_structure",
    "description": "Creates a replica of the object's data and indices. A deep replication implies creating a new object with its own data and indices, while a shallow replication involves only references to the original data and index.\nParameters: \n- deep (bool): Indicates whether to perform a deep copy, including the data and indices. Otherwise, it defaults to a shallow copy.\nReturns: \n- A new object that is either a deep or shallow copy of the original.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.diff": {
    "new_func": "calculate_discrete_deltas",
    "description": "Determines the discrete variation between elements within the object, typically against a prior element in a row-wise or column-wise fashion.\nParameters: \n- periods (int): The offset for the difference calculation, which can be negative.\n- axis (int or str): Specifies the axis along which to calculate the difference, whether across rows (0) or columns (1).\nReturns: \n- An object of the same type presenting the calculated differences.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.drop_duplicates": {
    "new_func": "eliminate_repetitions",
    "description": "Creates a new data structure by removing redundant entries. The user may specify a subset of columns to consider for assessing redundancy. The method also allows one to retain either the first or last occurrence of the redundant items, or remove all instances. An option is available to directly alter the original data structure or to reset the index numbering after the operation.\\nParameters:\\n- subset: column label or sequence of labels, optional (default is to use all columns)\\n- keep: Determines which duplicates to retain, options are 'first', 'last', or False\\n- inplace: boolean, optional (default is False)\\n- ignore_index: boolean, optional (default is False)\\nReturns:\\n- A new data structure with reduced entries or None if alteration is applied in place.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.dropna": {
    "new_func": "purge_nulls",
    "description": "Removes data entries that contain absent data points. Configurable to operate across different dimensions and based on the quantity of missing entries. Also allows for selection of specific columns for consideration. Can modify the data structure in place and has an option to reset index labels after purging.\\nParameters:\\n- axis: specify operation along rows or columns\\n- how: criteria for removal, 'any' for at least one missing value, 'all' for only completely missing entries\\n- thresh: integer, minimum count of non-missing values required to keep an entry\\n- subset: columns to include, optional\\n- inplace: boolean, modifies the original data structure if True\\n- ignore_index: boolean, relabels index if True\\nReturns:\\n- The data structure with missing entries dropped or None if done in place.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.dtypes": {
    "new_func": "column_data_types",
    "description": "Retrieves the data types for each attribute in the data structure as a series, with column names as index. For columns with multiple types, the type is denoted as 'object'.\\nReturns:\\n- Series with index as column names and corresponding data types as values.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.duplicated": {
    "new_func": "flag_redundancies",
    "description": "Generates a boolean series indicating whether each row is a repeat of an earlier row. Offers the ability to focus on specific columns and to choose which occurrences to identify as redundant.\\nParameters:\\n- subset: column label or sequence of labels, optional (default is to consider all columns)\\n- keep: indicates which duplicates to mark, with options 'first', 'last', or False\\nReturns:\\n- Series with boolean values corresponding to each row's redundancy status.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.empty": {
    "new_func": "is_void",
    "description": "Checks if the data structure has no elements across all dimensions and returns a boolean value.\\nReturns:\\n- True if the data structure has no elements, otherwise False.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.equals": {
    "new_func": "identical_structure_content",
    "description": "Determines conformity in structure and data between two tabular data structures. It checks if both have identical dimensions and matching values, considering null values at corresponding locations to be equivalent. The comparison does not require identical index types, only the values need to match. Resulting output is a boolean indicating perfect match or difference.\nParameters:\nother: Another tabular data structure to compare.\nReturns:\nbool: A boolean value indicating whether both structures have the same content and form.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.eq": {
    "new_func": "elementwise_equality_test",
    "description": "Compares the caller with another array-like object or a scalar value for equality on an element-by-element basis. It supports selecting an axis for comparison and choosing a specific level in a MultiIndex to align the comparison. The result is a data structure of booleans reflecting the equality of each element.\nParameters:\nother: A scalar, sequence, or another tabular data structure for comparison.\naxis: The axis to perform the comparison on, either 'index' (0) or 'columns' (1).\nlevel: The level in case of a MultiIndex to align the comparison.\nReturns:\nA boolean data structure indicating the result of elementwise comparison.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.eval": {
    "new_func": "compute_expression",
    "description": "Interprets and calculates the result of an expression involving one or more columns. It evaluates a string that expresses operations between columns. The function can modify the caller if specified, or return a new object with the calculated results. While powerful, care must be taken to avoid code injection risks when user input is involved.\nParameters:\nexpr: A string containing the expression to evaluate.\ninplace: A boolean indicating whether to perform the operation on the existing object or to return a new one.\n**kwargs: Additional arguments for advanced usage.\nReturns:\nDepending on the expression, the result could be an array, scalar, or a new data structure. If 'inplace' is set to True, it may return None after modifying the caller.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.ewm": {
    "new_func": "exponential_weight_momentum",
    "description": "Applies exponentially weighted functions to the data, which emphasize recent data points more strongly in a time series. Various decay definitions can be specified to control the weighting. The function supports ignoring null values and adjusting starting weights to account for initial periods.\nParameters:\ncom: Decay parameter for center of mass.\nspan: Decay parameter defined by the span.\nhalflife: Decay parameter defined by the half-life.\nalpha: The smoothing factor directly specified.\nmin_periods: The minimum number of observations required to have a value.\nadjust: Whether to correct the weights at the beginning.\nignore_na: Whether to ignore null values when calculating weights.\naxis: The axis to calculate over, either rows (0) or columns (1).\ntimes: Times for the observations, affecting the weighting calculations.\nmethod: The method of execution for rolling operations.\nReturns:\nAn object that encapsulates the exponentially weighted calculations.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.explode": {
    "new_func": "expand_list_elements",
    "description": "Converts each entry in a list-like column into its own row, duplicating the index values for each of the new rows. This transformation is useful for normalizing data structures with embedded lists into a flat format.\nParameters:\ncolumn: The label of the column or a list of labels specifying which columns to transform.\nignore_index: A boolean that determines whether to relabel the resulting index sequentially.\nReturns:\nA new data structure with list-like entries converted to rows, potentially with a new sequential index.\nRaises:\nValueError: If the transformation cannot be performed due to non-unique columns or mismatched list lengths in the specified columns.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.from_records": {
    "new_func": "tabularize_structured_data",
    "description": "Transforms a structured array, a collection of tuples or dictionaries, or a similar data structure into a tabular data object. The transformation process interprets the structured input to create an organized, two-dimensional array of data. The method allows specifying which fields should be used as index, which to exclude, and the naming or ordering of columns. Additionally, it can attempt to convert non-numeric types to a floating point if required. An option to limit the number of processed rows is also available if the input is an iterator.\nParameters: data - Structured input data. index - Field to set as index or specific labels to use. exclude - Fields to ignore. columns - Names or order of columns. coerce_float - Flag to convert non-numeric types to float. nrows - Limit on rows to process if data is iterable.\nReturns: Two-dimensional array representation of the input data.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.get": {
    "new_func": "retrieve_column_value",
    "description": "Accesses an item using a specified key, such as a column label. If the specified key is not present within the object, a default value is returned instead.\nParameters: key - The label of the item to access. default - The value to return if the key is not found.\nReturns: Item of the same type contained within the object.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.hist": {
    "new_func": "column_value_distribution_plot",
    "description": "Generates visual distributions for the dataset's attributes using bar representations. Each attribute is depicted separately, showing the frequency of data points that fall within certain value ranges. The visuals are customizable, with options for grid visibility, axis label sizes and rotation, figure size, layout, and bin sizes. Additional backend customization and other visual adjustments can be specified through extra keyword arguments.\nParameters: data - The data object. column - Subset of data attributes. by - Grouping for separate distributions. grid - Grid line visibility. xlabelsize - X-axis label size. ylabelsize - Y-axis label size. xrot - X-axis label rotation. yrot - Y-axis label rotation. ax - Plotting axes. sharex - X-axis sharing. sharey - Y-axis sharing. figsize - Figure dimensions. layout - Histogram layout. bins - Bin count or sequence. backend - Plotting backend. legend - Legend display. kwargs - Additional plotting arguments.\nReturns: Plotting object or array of plotting objects.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.head": {
    "new_func": "initial_rows_extract",
    "description": "Retrieves a specified number of initial rows from the data structure based on their position. It is particularly useful for validating the data integrity by providing a quick glimpse of the dataset. In the case of a negative number, the method excludes the last few rows from the end.\nParameters: n - Number of initial rows to retrieve.\nReturns: Data structure containing the specified number of initial rows.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.gt": {
    "new_func": "element_wise_superiority_check",
    "description": "Performs an element-by-element comparison to determine whether elements in the data structure are greater than corresponding elements in another object. This method supports flexible comparison across either dimension or a specific level in a multi-index.\nParameters: other - The object to compare against. axis - The axis along which to perform the comparison. level - The index level to broadcast the comparison over.\nReturns: A data structure containing boolean values indicating the outcome of the comparison.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.iat": {
    "new_func": "cell_at_integer_position",
    "description": "Retrieves or assigns a value at a specific row-column location identified by integer coordinates within a data structure. It is intended for quick access to a scalar value. Attempting to access a location outside the valid bounds will result in an IndexError.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.idxmax": {
    "new_func": "index_of_peak",
    "description": "Identifies the label of the first occurrence of the highest value along a specified dimension, excluding any missing or NA values. This method allows control over whether to consider non-numeric data types. Parameters: dimension (0 for row-wise, 1 for column-wise), exclude_nulls (bool), only_numerics (bool). Returns: The label of the element with the maximum value along the given axis.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.groupby": {
    "new_func": "cluster_by_key",
    "description": "Organizes a data structure into groups based on a specified key or keys and enables combined computation on these clusters. It can split data based on different criteria and apply a function to each subset, then recombine the results. Parameters: key (function, label, list, or dict), dimension (0 for rows, 1 for columns), hierarchy_level (int or name), indexed (bool), ordered (bool), include_group_keys (bool), categorical_observed (bool), exclude_na (bool). Returns: An object representing the grouped structure, facilitating further analysis.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.idxmin": {
    "new_func": "index_of_nadir",
    "description": "Finds the label of the first instance of the lowest value along a specified axis, ignoring any missing or NA values. This function allows the user to specify whether to include non-numeric data types. Parameters: axis (0 for rows, 1 for columns), skip_na (bool), numeric_types (bool). Returns: The label of the element with the minimum value along the chosen axis.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.index": {
    "new_func": "row_identifiers",
    "description": "Returns the identifying labels for each row in a data structure. These labels are used for accessing and aligning data by row and can be a mix of integers, strings, or any hashable objects. Returns: A collection of labels corresponding to the rows of the data structure.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.last": {
    "new_func": "terminal_interval_slice",
    "description": "Extracts the concluding segments of a time-indexed dataset based on a specified temporal range. Targets the tail-end records that fall within the given period length from the end of the dataset. It operates on data with an ordered date-time index.\nParameters: offset (string, DateOffset, or dateutil.relativedelta) - The temporal duration to define the data to extract.\nReturns: A subset of the original dataset containing the elements from the end within the given temporal range.\nRaises: TypeError - In case the dataset index is not date-time based.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.last_valid_index": {
    "new_func": "final_nonnull_locator",
    "description": "Identifies the position of the last value in the dataset that is not null. If all values are null, the result will be None.\nReturns: The index type corresponding to the position of the last non-null value.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.lt": {
    "new_func": "elementwise_comparison_minor",
    "description": "Performs an element-by-element comparison of the dataset with another object, determining whether each element is less than the corresponding element in the other.\nParameters: other (scalar, sequence, Series, or DataFrame) - The object to compare against.\naxis ({0 or 'index', 1 or 'columns'}) - The axis along which to perform the comparison.\nlevel (int or label) - The index level to match for comparison in case of a MultiIndex.\nReturns: A dataset of Boolean values indicating the result of the comparison.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.map": {
    "new_func": "scalar_transform",
    "description": "Executes a specified function element-by-element throughout the dataset. The function should accept a single value and return a single value.\nParameters: func (callable) - A function that takes and returns a single value.\nna_action ({None, 'ignore'}) - If 'ignore', NaN values are not passed to the function.\n**kwargs - Any additional arguments to pass to the function.\nReturns: A transformed dataset with the function applied to each element.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.le": {
    "new_func": "elementwise_comparison_minor_equal",
    "description": "Conducts an element-by-element comparison of the dataset with another object, determining whether each element is less than or equal to the corresponding element in the other.\nParameters: other (scalar, sequence, Series, or DataFrame) - The object to compare against.\naxis ({0 or 'index', 1 or 'columns'}) - The axis along which to perform the comparison.\nlevel (int or label) - The index level to match for comparison in case of a MultiIndex.\nReturns: A dataset of Boolean values representing the outcome of the comparison.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.max": {
    "new_func": "peak_value",
    "description": "This method retrieves the highest value across the specified axis, disregarding any null entries unless otherwise specified. This operation can be performed across different data types, limited to numeric data if required.\nParameters: axis (int, default 0) - The axis to perform the operation on. skipna (bool, default True) - Option to exclude null values. numeric_only (bool, default False) - Restrict to numeric data types. **kwargs - Additional arguments.\nReturns: The highest value as a scalar or Series.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.mask": {
    "new_func": "substitute_conditionally",
    "description": "This method replaces values in a DataFrame where a specified condition is met with another set of values. The condition can be defined by a callable, and the substitution can be performed in place if desired.\nParameters: cond (bool Series/DataFrame or callable) - Condition for replacement. other (scalar, Series/DataFrame, or callable) - Values to replace with. inplace (bool, default False) - Modify the DataFrame in place. axis (int, default None) - Axis for alignment. level (int, default None) - Level for alignment.\nReturns: Modified DataFrame or None if done in place.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.median": {
    "new_func": "center_value",
    "description": "This method calculates the middle value of the data across the chosen axis, considering non-null entries. It can be constrained to only numeric data types if specified. Additional parameters can be passed via kwargs.\nParameters: axis (int, default 0) - Axis to compute the median. skipna (bool, default True) - Ignore null values. numeric_only (bool, default False) - Limit to numeric data. **kwargs - Additional arguments.\nReturns: The median value as a scalar or Series.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.melt": {
    "new_func": "reshape_longer",
    "description": "This method transforms the DataFrame from a wide format to a long format, turning columns into rows. It allows for the specification of identifier variables and measured variables, resulting in a DataFrame with two non-identifier columns.\nParameters: id_vars (optional) - Identifier variables. value_vars (optional) - Columns to transform. var_name (default None) - Name for the variable column. value_name (default 'value') - Name for the value column. col_level (optional) - Level to melt if MultiIndex columns. ignore_index (bool, default True) - Whether to reset the index.\nReturns: A DataFrame in long format.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.loc": {
    "new_func": "retrieve_by_labels",
    "description": "This property provides access to specific rows and columns based on their labels or a boolean condition. It supports various input types such as single labels, lists of labels, slice objects, boolean arrays, alignable Series, Indices, or callables.\nInputs: Labels, lists, slices, boolean arrays, alignable Series/Index, or callables.\nRaises: KeyError when labels are not found, IndexingError for unalignable keys.\nReturns: The selected subset of the DataFrame.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.mode": {
    "new_func": "frequent_elements",
    "description": "Calculates the most recurrent values along a specified axis of a data structure. These values are the ones that appear with the highest frequency and there can be more than one per axis.\nParameters:\naxis (int or str, default 0) - Dimension to perform the operation on where 0 denotes column-wise and 1 denotes row-wise.\nnumeric_only (bool, default False) - Limits the calculation to data of numerical type if set to True.\ndropna (bool, default True) - Excludes null values from the frequency count if set to True.\nReturns:\nA data structure containing the most frequently occurring values for each row or column.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.ndim": {
    "new_func": "array_dimensions",
    "description": "Yields an integer indicating the count of dimensions or axes in the data structure. For a one-dimensional structure, it returns 1, while for a two-dimensional structure, it returns 2.\nReturns:\nint - The number of dimensions in the data structure.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.ne": {
    "new_func": "elementwise_inequality",
    "description": "Compares the calling data structure with another, element by element, to determine inequality. The comparison yields a boolean structure of the same size indicating True for elements that differ and False for those that are equal.\nParameters:\nother (scalar, sequence, Series, or data structure) - The object to compare against.\naxis (int or str, default 'columns') - The axis for comparison; 'columns' or 0 for index-wise, 'rows' or 1 for column-wise comparison.\nlevel (int or label, optional) - If the data structure has a multi-level index, this parameter specifies which level to align with.\nReturns:\nA boolean data structure indicating the result of the inequality comparison.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.notna": {
    "new_func": "existent_values_detector",
    "description": "Identifies all non-null entries in the data structure, returning a boolean matrix of the same dimensions where True indicates the presence of a valid data point, and False signifies a null entry.\nReturns:\nA boolean data structure where each element signifies whether the corresponding entry in the original data structure is non-null.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.plot": {
    "new_func": "visualize_data",
    "description": "Renders a visual representation of a data series or a structured data set using various chart types. The visual output can be customized with multiple parameters to display line charts, bar charts, histograms, box plots, kernel density estimates, area charts, pie charts, scatter plots, and hexagonal binning plots. Options for defining axes, choosing subplots, setting figure size, and many other plot customizations are available.\nParameters: data (Series or structured data set) - The data to be visualized.\nReturns: An object representing the plot, which varies based on the selected backend.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.plot.barh": {
    "new_func": "horizontal_category_comparator",
    "description": "Crafts a horizontal bar chart to showcase a comparative view of quantitative data across various discrete categories, with bar lengths reflecting associated values. It allows for customization of colors and additional styling through keyword arguments.\nParameters: labels for categories and values (optional) - Specifies the data points to be compared.\nReturns: An object or an array of objects depicting the horizontal bars, with each representing a distinct category.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.plot.bar": {
    "new_func": "vertical_category_comparator",
    "description": "Produces a vertical bar chart to display a comparison of categorical data, with bars' heights proportional to the represented values. The function allows specifying colors and additional properties to tailor the visual presentation.\nParameters: labels for categories and values (optional) - Defines the categories and their corresponding values to be plotted.\nReturns: An object or an array of objects that represent the vertical bars for each category.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.plot.hexbin": {
    "new_func": "hexagonal_cluster_chart",
    "description": "Creates a hexagonal binning diagram, plotting data points on a two-dimensional plane, where the frequency of occurrence or a specified aggregate metric is represented within each hexagon. It offers customization options including grid size and reduction function for values within bins.\nParameters: x and y coordinates (labels or positions), value metric (optional), reduction function (optional), grid dimensions (optional) - Parameters determining the data points to plot, the metric to aggregate, and the hexagonal grid's layout.\nReturns: An Axes object on which the hexagonal binning is rendered.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.replace": {
    "new_func": "substitute_values",
    "description": "Modifies a tabular dataset by exchanging specified elements with alternative ones. This function supports dynamic alteration of data without the need for explicit position indexing. It accepts single or multiple replacements, which can be defined through various data structures and can also interpret patterns for substitution. The operation can be conducted in place or return a modified copy.\nParameters:\n- to_replace (various types) - The criteria used to determine which elements to alter.\n- value (various types) - The new elements that will be substituted into the dataset.\n- inplace (bool) - If set to true, changes the original dataset and returns None.\n- limit (int) - Deprecated. Maximum number of subsequent elements to forward/backward fill.\n- regex (bool or various types) - Indicates whether to_replace and value should be treated as regular expressions.\n- method (string) - Deprecated. The technique used for replacement when certain conditions are met.\nReturns:\n- A modified copy of the original dataset with specified elements replaced.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.rfloordiv": {
    "new_func": "reverse_integer_divide",
    "description": "Performs element-wise integer division of a provided value by the dataset's elements, with an option to fill missing data. This method is essentially the inverse of the standard floor division operation, allowing for a substitute value in place of missing or misaligned data.\nParameters:\n- other (various types) - The value to be divided by the dataset's elements.\n- axis (int or string) - Defines whether the operation is applied across rows or columns.\n- level (int or string) - For hierarchical indices, the level on which the operation is performed.\n- fill_value (float) - A value to use in place of missing data during the operation.\nReturns:\n- A dataset resulting from the integer division.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.reorder_levels": {
    "new_func": "reshuffle_indices",
    "description": "Changes the order of hierarchical index levels of the dataset based on the provided sequence. The function ensures that all levels are retained and no duplicates are created during the process.\nParameters:\n- order (list of integers or strings) - The new sequence specifying the desired order of index levels.\n- axis (int or string) - Determines if the index levels to be reordered are from rows or columns.\nReturns:\n- A dataset with its index levels rearranged.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.rmul": {
    "new_func": "reverse_product",
    "description": "Calculates the element-wise product of the dataset with another value, allowing for a fill value to replace any missing data. This version reverses the operands, multiplying the provided value by the dataset's elements. It also supports alignment of inputs with different sizes or indices.\nParameters:\n- other (various types) - The multiplier used in the operation.\n- axis (int or string) - Specifies if the operation should align with the dataset's rows or columns.\n- level (int or string) - Identifies the hierarchical index level applicable for the operation, if any.\n- fill_value (float) - A value used to replace missing data before the operation.\nReturns:\n- A dataset containing the results of the multiplication.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.rmod": {
    "new_func": "reverse_remainder",
    "description": "Determines the element-wise remainder when another value is divided by the elements of the dataset. Similar to the modulo operation but with the operands in reverse order. Missing data can be substituted with a specified value before performing the calculation.\nParameters:\n- other (various types) - The dividend in the modulo operation.\n- axis (int or string) - Indicates whether the operation should be performed along rows or columns.\n- level (int or string) - In case of a hierarchical index, the level at which the operation should take place.\n- fill_value (float) - A value to fill in for missing data prior to computation.\nReturns:\n- A dataset that reflects the remainder of the division operation.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.sparse.to_coo": {
    "new_func": "dataframe_to_sparse_matrix",
    "description": "Converts the data structure into a COO (Coordinate) format sparse matrix, which is suitable for certain types of mathematical operations that benefit from sparse data representations.\nReturns: \n- A sparse matrix object, specifically a scipy.sparse.spmatrix. If the data includes booleans or objects, the dtype of the matrix will be object.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.sparse": {
    "new_func": "sparse_data_accessor",
    "description": "Provides access to specialized methods and properties for handling data with many missing or zero entries efficiently.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.sort_values": {
    "new_func": "order_by_columns",
    "description": "Organizes the dataset based on the values in specified columns, either in an ascending or descending order. This can be applied across different axes and allows for sorting to be done either in-place or to return a new instance.\nParameters:\n- by: Name or list of names indicating which columns to sort by.\n- axis: The axis to sort along, either 0 for index or 1 for columns.\n- ascending: Determines the sort order, where True is ascending and False is descending.\n- inplace: If set to True, the sort will alter the original data structure.\n- kind: The algorithm used for sorting, with options including 'quicksort', 'mergesort', 'heapsort', and 'stable'.\n- na_position: Position of NA values, either 'first' or 'last'.\n- ignore_index: If True, the original index is ignored and a new index is created.\n- key: Optional function that gets applied to the values before sorting.\nReturns:\n- A sorted data structure, which could be a new instance or the original modified if inplace is True.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.sparse.from_spmatrix": {
    "new_func": "construct_from_sparse_matrix",
    "description": "Builds a new data structure using a sparse matrix as the source. This conversion ensures that the sparse data format is maintained.\nParameters:\n- data: A scipy.sparse.spmatrix that can be converted to csc format.\n- index: Optional row labels for the resulting data structure. Defaults to a RangeIndex if not provided.\n- columns: Optional column labels for the resulting data structure.\nReturns:\n- A data structure where each column is a SparseArray.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.std": {
    "new_func": "deviation_measure",
    "description": "Calculates the dispersion metric of dataset entries across a specified axis, considering N-1 as the normalization factor by default. This factor can be altered via the 'ddof' parameter. Excludes any null entries, unless the entire segment being considered is null, resulting in a null outcome. The operation can be performed across rows or columns of the dataset, with the ability to include only numerical data if specified.\nParameters: \n- axis (0 for rows, 1 for columns): The axis along which to compute the metric.\n- skipna (bool): Option to exclude null values in calculations.\n- ddof (int): Modifier for the normalization factor in the calculation.\n- numeric_only (bool): Restrict calculations to numerical data only.\nReturns: \n- A series or a dataset with the computed dispersion metric, depending on the context.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.sub": {
    "new_func": "elementwise_difference",
    "description": "Performs element-by-element subtraction between the dataset and another specified data structure, with the ability to fill in missing data before the calculation. The operation is equivalent to a direct subtraction, but with enhanced handling for null values. It also supports the reverse operation. This function works in conjunction with a set of flexible arithmetic operations.\nParameters:\n- other (scalar, sequence, series, dictionary, or dataset): The data to subtract from the dataset.\n- axis (0 for 'index', 1 for 'columns'): The axis to align the input data structure on.\n- level (int or label): The index level to broadcast across if the dataset has a multi-level index.\n- fill_value (float or None): A value to use for filling missing data before performing the operation.\nReturns: \n- A dataset containing the results of the subtraction.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.style": {
    "new_func": "dataframe_aesthetics",
    "description": "Provides access to a decorator object that enables the creation of an aesthetically enhanced HTML representation for the dataset, facilitating customization and styling options for presentation.\nReturns: \n- A decorator object that can be used to style the dataset's HTML representation.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.swaplevel": {
    "new_func": "index_level_interchange",
    "description": "Alters the dataset by interchanging two specified levels in its multi-level index, which can be identified by either their integer position or name. By default, the two innermost levels are interchanged. The operation can be performed row-wise or column-wise.\nParameters:\n- i, j (int or str): The index levels to be interchanged.\n- axis (0 for 'index', 1 for 'columns'): The axis along which the levels should be swapped.\nReturns:\n- A dataset with the specified index levels interchanged.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.swapaxes": {
    "new_func": "axes_interchanger",
    "description": "Alters the dataset by exchanging two specified axes, effectively transposing the corresponding values. Note that this method is marked for deprecation and will be removed in future releases. A different method is recommended for similar functionality.\nReturns: \n- A dataset with the specified axes exchanged, identical in structure to the input.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.to_csv": {
    "new_func": "export_delimited_text",
    "description": "Outputs the data structure to a delimited text file format, such as one used by spreadsheet programs. It allows a variety of options to customize the output including delimiters, representation of missing values, file modes, and handling of special characters. Parameters: - destination (str, path object, file-like object, or None) - Target file path or object. If None, returns the content as a string. - delimiter (str) - Character to separate fields within each record. - missing_value_representation (str) - Placeholder for absent data entries. - numeral_format (str or Callable) - Template or function to format floating point numbers. - selected_columns (sequence) - Subset of columns to be included in the output. - include_headers (bool or list of str) - Whether to prepend column names to the output. Can provide aliases for column names. - include_index (bool) - Whether to include the index as a column in the output. - index_labeling (str or sequence, or False) - Label for the index column(s) if included. - file_mode ({'w', 'x', 'a'}) - Mode for opening the file. - file_encoding (str) - Character encoding for the output file. - on_the_fly_compression (str or dict) - Compression format or configuration for the output. - field_quoting (optional constant from csv module) - Policy for enclosing fields with special characters. - field_quote_character (str) - Character to enclose fields when quoting is needed. - record_terminator (str, optional) - Character or sequence to separate records. - batch_size (int or None) - Number of rows per written batch. - datetime_format (str) - Template for datetime objects. - allow_double_quoting (bool) - Whether to permit quoting of the quote character within fields. - escape_character (str) - Character to precede delimiters or quote characters within fields. - decimal_separator (str) - Symbol to recognize as the decimal point. - encoding_errors_handling (str) - Strategy for handling encoding and decoding errors. - additional_storage_options (dict, optional) - Additional parameters for storage connections. Returns: - None or str - If destination is None, the content as a string; otherwise, None after writing to file.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.tail": {
    "new_func": "fetch_final_records",
    "description": "Retrieves a specified number of concluding records from the data structure, which can be used for data inspection or verification. Parameters: - number_of_records (int) - Count of records to retrieve from the end. Returns: - data_structure - The subset of the data structure containing the last specified number of records.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.to_clipboard": {
    "new_func": "copy_to_clipboard",
    "description": "Transfers a textual representation of the data structure to the clipboard, allowing for easy pasting into external applications such as spreadsheet editors. Parameters: - as_spreadsheet_format (bool) - Whether to format the output for compatibility with spreadsheet software. - field_delimiter (str) - String to separate fields in the output. - additional_parameters - These parameters will be passed to the method responsible for converting the data structure to text. Returns: - None - The data is copied to the clipboard without returning any value.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.take": {
    "new_func": "retrieve_by_position",
    "description": "Obtains elements from specified positions within the data structure, based on their ordinal location rather than their index or label. Parameters: - position_indices (array-like) - Sequence of integer positions indicating the elements to retrieve. - axis_dimension ({0, 1}) - The dimension across which to take elements (0 for rows, 1 for columns). - additional_parameters - Placeholder for compatibility with similar methods; does not affect the outcome. Returns: - data_structure_subset - A subset of the original data structure containing the retrieved elements.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.sum": {
    "new_func": "aggregate_total",
    "description": "Calculates the aggregate sum across a given dimension, excluding any missing or null entries, and optionally limited to numeric data types. Parameters: - calculation_axis ({0, 1}) - The axis along which to calculate the sum (0 for index, 1 for columns). - omit_na (bool) - Whether to ignore missing values in the summation. - numerics_only (bool) - Whether to consider only numeric data types in the calculation. - valid_data_threshold (int) - Minimum number of valid values required to perform the operation without returning a missing value result. - additional_keyword_arguments - Further arguments for the summation function. Returns: - Series or scalar - The sum as a Series across the specified axis or a scalar if the axis is None.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.to_string": {
    "new_func": "frame_to_textual_display",
    "description": "Transforms a tabular data structure into a text-based table representation that is easy to read in a console or plain text environment. It allows customization of the output format, such as specifying which columns to include, customizing the representation of missing data, and controlling the display size of the table.\nParameters:\n- buf (str, Path or StringIO-like): The buffer to write to. If not provided, the result is returned as a string.\n- columns (array-like): Columns to include in the output. If not provided, all columns are included.\n- col_space (int, list of int, or dict of int): Minimum column width specifications.\n- header (bool or list of str): Whether to output the column names, or provide aliases for them.\n- index (bool): Whether to include row labels.\n- na_rep (str): String representation for missing data.\n- formatters (list, tuple, or dict): Functions for transforming the data by position or name.\n- float_format (one-parameter function): A formatting function for float values.\n- sparsify (bool): Controls sparsity of hierarchical indices.\n- index_names (bool): Whether to print index names.\n- justify (str): How to align the column labels.\n- max_rows (int): Maximum number of rows to display.\n- max_cols (int): Maximum number of columns to display.\n- show_dimensions (bool): Whether to show the dimensions of the data structure.\n- decimal (str): Character to recognize as the decimal separator.\n- line_width (int): The character width to wrap lines.\n- min_rows (int): Minimum number of rows to display in a truncated representation.\n- max_colwidth (int): Maximum column width for truncation.\n- encoding (str): The character encoding for the output.\nReturns:\n- (str or None): The formatted text representation or None if 'buf' is provided.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.to_stata": {
    "new_func": "frame_to_statistical_software_format",
    "description": "Exports the tabular data structure to a file in a format compatible with a popular statistical analysis software. It allows for custom date conversions, inclusion of index, and control over the file format version.\nParameters:\n- path (str, path object, or buffer): File path or object where the data will be written.\n- convert_dates (dict): Mapping from columns to stata date formats.\n- write_index (bool): Whether to include the index.\n- byteorder (str): Byte order indicator.\n- time_stamp (datetime): File creation date.\n- data_label (str): A label for the data set.\n- variable_labels (dict): Labels for the variables (columns).\n- version (int): Format version for the output file.\n- convert_strl (list): Columns to convert to StrL format.\n- compression (str or dict): Compression options for the output file.\n- storage_options (dict): Options for storage connectivity.\n- value_labels (dict of dicts): Mapping from columns to value labels.\nReturns:\n- None: The function writes the data to a file and does not return anything.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.to_xarray": {
    "new_func": "frame_to_multidim_array",
    "description": "Converts the structured data into a multi-dimensional array-like object suitable for advanced data analysis and modeling. The resulting structure will be a Dataset if the input is a two-dimensional structure, or a DataArray if the input is one-dimensional.\nReturns:\n- (xarray.DataArray or xarray.Dataset): The converted data in the form of an xarray object.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.to_timestamp": {
    "new_func": "frame_to_datetime_index",
    "description": "Converts the time-related index of the data structure to a more granular datetime index, placing the timestamps at either the start or the end of the specified frequency period.\nParameters:\n- freq (str): The frequency conversion string.\n- how (str): Whether to place timestamps at the start or end of the period.\n- axis (int or str): The axis along which to convert.\n- copy (bool): Whether to copy the underlying data.\nReturns:\n- (DataFrame): The modified data structure with a datetime index.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.transform": {
    "new_func": "frame_modify_via_function",
    "description": "Applies a given transformation to the data structure, potentially altering its contents while maintaining the original axis dimensions. The transformation can be specified as a single function, a list of functions, or a dictionary mapping columns to functions.\nParameters:\n- func (function, str, list-like, or dict-like): The transformation to apply.\n- axis (int or str): The axis along which to apply the function(s).\n- args (tuple): Additional positional arguments for the function(s).\n- kwargs (dict): Additional keyword arguments for the function(s).\nReturns:\n- (DataFrame): A new data structure of the same size as the original with the transformation applied.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.value_counts": {
    "new_func": "row_frequency_tally",
    "description": "Produces a one-dimensional array-like object containing counts of unique row occurrences within a two-dimensional data structure. It provides options to normalize the counts to proportions, sort the counts in either ascending or descending order, and to exclude rows with missing values from the count. Parameters: subset (label or list of labels, optional) - Specific columns to consider for unique combinations. normalize (bool, default False) - Whether to return the relative frequencies instead of absolute counts. sort (bool, default True) - Whether to order the results by frequency. ascending (bool, default False) - If sorting, specifies whether to sort in ascending order. dropna (bool, default True) - Whether to include rows with missing values in the count. Returns: A one-dimensional array-like object with indexed frequency counts.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.where": {
    "new_func": "conditional_replacer",
    "description": "Performs a replacement operation across a two-dimensional data structure based on a specified conditional logic. Where the condition is not met, the replacement is executed with an alternative value or callable result. This operation can be executed in place and supports alignment on a specified axis or level. Parameters: cond (boolean array-like or callable) - The condition upon which to base replacements. other (scalar, array-like, or callable, default NaN) - The replacement values for non-compliant elements. inplace (bool, default False) - Whether to apply changes directly to the original data. axis (int, default None) - Axis along which to align if necessary. level (int, default None) - The level for alignment in case of multi-level indexing. Returns: The same type as the original data structure with modifications applied, or None if 'inplace' is set to True.",
    "class": "DataFrame"
  },
  "pandas.DataFrame.xs": {
    "new_func": "selective_indexer",
    "description": "Extracts a specific section from a one-dimensional array-like object or a two-dimensional data structure based on a provided key. When dealing with multi-level indexing, this method allows for the selection of data at any given level, with an option to maintain or drop the level of indexing in the result. Parameters: key (label or tuple of label) - The index value(s) specifying the section to extract. axis (int, default 0) - The axis along which to extract the section, with 0 for index and 1 for columns. level (object, default None) - The index levels to consider when extracting the section, applicable for multi-level indexing. drop_level (bool, default True) - Whether to maintain the hierarchy of the index levels in the resulting object. Returns: A one-dimensional array-like object or a two-dimensional data structure representing the extracted section.",
    "class": "DataFrame"
  },
  "pandas.DatetimeIndex.as_unit": {
    "new_func": "resample_temporal_index",
    "description": "Adjusts the temporal resolution of a time-based index to the specified unit, such as seconds, milliseconds, microseconds, or nanoseconds. This transformation maintains the type of the index while altering the granularity of the timestamp representation. Parameters: unit (string) - The temporal resolution to which the index should be converted, options include 's' for seconds, 'ms' for milliseconds, 'us' for microseconds, and 'ns' for nanoseconds. Returns: An index object of the same type with updated temporal resolution.",
    "class": "DatetimeIndex"
  },
  "pandas.DatetimeIndex.snap": {
    "new_func": "align_frequency",
    "description": "Adjusts the timestamps to the nearest specified regular interval. The result is an array-like structure with the timestamps aligned to the closest matching frequency.\nParameters: freq (str) - The desired frequency to align the timestamps with.\nReturns: An array-like structure of timestamps aligned to the nearest desired frequency.",
    "class": "DatetimeIndex"
  },
  "pandas.DatetimeIndex.to_pydatetime": {
    "new_func": "datetime_objects_array",
    "description": "Produces an array of standard Python datetime.datetime objects from the given datetime-like structure.\nReturns: An array of datetime.datetime objects.",
    "class": "DatetimeIndex"
  },
  "pandas.DatetimeIndex.strftime": {
    "new_func": "format_to_index",
    "description": "Transforms a datetime-like structure into an array-like structure of strings formatted according to a specified pattern. It adheres to the string formatting conventions of the standard library.\nParameters: date_format (str) - The pattern used to format the datetime objects (e.g., '%Y-%m-%d').\nReturns: An array-like structure containing string representations formatted as per the given pattern.",
    "class": "DatetimeIndex"
  },
  "pandas.DatetimeIndex.to_period": {
    "new_func": "convert_to_period",
    "description": "Changes a datetime-like structure to a period-like structure with specified or inferred frequency.\nParameters: freq (str or Period, optional) - The target frequency or Period object for the conversion. If not provided, the frequency is inferred.\nReturns: A period-like structure corresponding to the input datetime-like structure.\nExceptions: Raises a ValueError if the conversion cannot infer a regular frequency from non-regular values.",
    "class": "DatetimeIndex"
  },
  "pandas.DatetimeIndex.to_series": {
    "new_func": "index_to_series",
    "description": "Generates a one-dimensional array-like object, with the index as both the positions and the values.\nParameters: index (Index, optional) - The index for the resulting array-like object. Defaults to the original index if not provided.\nname (str, optional) - The name for the resulting array-like object. Defaults to the name of the original index if not provided.\nReturns: A one-dimensional array-like object with the index values serving as both the positions and the values.",
    "class": "DatetimeIndex"
  },
  "pandas.HDFStore.info": {
    "new_func": "storage_details",
    "description": "Outputs comprehensive details about the data storage container. The method produces an informative string.\nReturns: A string containing the details.",
    "class": "HDFStore"
  },
  "pandas.HDFStore.get": {
    "new_func": "retrieve_data_item",
    "description": "Extracts a stored data entity using a specified identifier.\nParameters: key (string) - The unique identifier for the data entity.\nReturns: The retrieved data entity, maintaining the same type as when it was stored.",
    "class": "HDFStore"
  },
  "pandas.HDFStore.groups": {
    "new_func": "top_level_nodes",
    "description": "Produces a list of the highest hierarchy nodes within the data storage.\nReturns: A list containing objects representing the top-level nodes.",
    "class": "HDFStore"
  },
  "pandas.HDFStore.append": {
    "new_func": "extend_storage_table",
    "description": "Increases the size of an existing Table by adding new data to it.\nParameters: \n- key (string) - An identifier for the Table.\n- value (Series or DataFrame) - The data to add to the Table.\n- format (optional) - The format for storing the object; default is 'table'.\n- Additional parameters to specify the append behavior like 'axes', 'index', 'complib', 'complevel', 'columns', 'min_itemsize', 'nan_rep', 'chunksize', 'expectedrows', 'dropna', 'data_columns', 'encoding', 'errors' with various defaults and data types as detailed in the full documentation.\nReturns: None. Modifies the Table in the storage to include the new data.",
    "class": "HDFStore"
  },
  "pandas.HDFStore.put": {
    "new_func": "storage_write",
    "description": "Writes an object to a hierarchical data format storage under the specified key. This method supports various storage formats and compression levels, and it can append to existing data or create indexed columns for efficient queries. The method handles both series and dataframes as input values.\nParameters:\n- key (str): Identifier for the stored object.\n- value (Series, DataFrame): The data structure to store.\n- format (str, optional): The storage format ('fixed' or 'table').\n- index (bool, optional): Whether to write the dataframe index as a column.\n- append (bool, optional): If True, append data to an existing object within the store.\n- complib (str, optional): Compression library to use.\n- complevel (int, optional): Compression level from 0 to 9.\n- min_itemsize (dict or int, optional): Minimum string size for columns.\n- nan_rep (str, optional): Representation for missing values.\n- data_columns (list, optional): Columns to create as data columns for indexing.\n- encoding (str, optional): String encoding.\n- errors (str, optional): Protocol for handling encoding errors.\n- track_times (bool, optional): Whether to include time metadata.\n- dropna (bool, optional): Whether to exclude missing values.\nReturns: None.",
    "class": "HDFStore"
  },
  "pandas.Float64Dtype": {
    "new_func": "decimal_precision_type",
    "description": "Defines a data type for decimal numbers with double precision, utilizing a specific missing value indicator for absent data.\nInput arguments: None.\nReturns: The data type instance.",
    "class": "Float64Dtype"
  },
  "pandas.HDFStore.select": {
    "new_func": "storage_query",
    "description": "Retrieves a stored object from a hierarchical data format file, potentially filtered by specific criteria. The method can return a subset of rows and columns and can return results in chunks as an iterator.\nParameters:\n- key (str): The identifier of the object to retrieve.\n- where (list, optional): Conditions for filtering the results.\n- start (int, optional): The starting row number for the selection.\n- end (int, optional): The ending row number for the selection.\n- columns (list, optional): Specific columns to retrieve.\n- iterator (bool, optional): If True, returns an iterator.\n- chunksize (int, optional): The number of rows per chunk for the iterator.\n- auto_close (bool, optional): Whether to close the store automatically after the operation.\nReturns: The retrieved object (or an iterator over chunks of the object).",
    "class": "HDFStore"
  },
  "pandas.HDFStore.walk": {
    "new_func": "storage_hierarchy_explore",
    "description": "Iteratively explores the group hierarchy in a hierarchical data format file, providing paths and names of subgroups and objects. It excludes non-relevant items and lists the parent group before its children.\nParameters:\n- where (str, optional): The starting group path for the exploration.\nYields:\n- path (str): Complete path to the current group.\n- groups (list): Names of subgroups within the current group.\n- leaves (list): Names of objects within the current group.",
    "class": "HDFStore"
  },
  "pandas.Index": {
    "new_func": "axis_label_sequence",
    "description": "Creates an immutable sequence to serve as axis labels for data structures, suitable for indexing and alignment purposes. It can also infer an appropriate data type if none is provided and supports various configurations including the option to create a multi-level index.\nParameters:\n- data (array-like, optional): One-dimensional input data.\n- dtype (str or dtype, optional): Desired data type for the sequence.\n- copy (bool, optional): Whether to copy the input data.\n- name (object, optional): Designated name for the index.\n- tupleize_cols (bool, optional): Flag to create a MultiIndex if applicable.\nReturns: An instance representing the sequence of labels.",
    "class": "Index"
  },
  "pandas.Index.T": {
    "new_func": "self_transposition",
    "description": "Provides a self-referential transpose, effectively returning the object itself as transposing an index does not change it.",
    "class": "Index"
  },
  "pandas.Index.any": {
    "new_func": "any_truthful",
    "description": "Checks if at least one element in the index evaluates to a true value. Includes compatibility parameters for other libraries. Parameters: *args - Compatibility with other libraries. **kwargs - Compatibility with other libraries. Returns: A boolean indicating the presence of any true value, or an array-like object if an axis is specified. Single element array-likes can be cast to boolean.",
    "class": "Index"
  },
  "pandas.Index.argmax": {
    "new_func": "peak_position",
    "description": "Determines the positional index of the highest value, disregarding any null values if instructed. If the peak is reached multiple times, the index of the first occurrence is provided. Parameters: axis - Not used, present for compatibility. skipna - A boolean, when true, ignores any null values for determining the peak. *args, **kwargs - Additional arguments for compatibility with other numerical libraries. Returns: An integer indicating the position of the highest value.",
    "class": "Index"
  },
  "pandas.Index.append": {
    "new_func": "concatenate_indices",
    "description": "Combines the current index with another index or a collection of indices, forming a new concatenated index. Parameters: other - A single index or a list/tuple of indices to be concatenated. Returns: A new index consisting of the combined elements.",
    "class": "Index"
  },
  "pandas.Index.argmin": {
    "new_func": "smallest_value_position",
    "description": "Determines the index of the first occurrence of the least element in a given sequence, disregarding any null values if specified. This is used for identifying the initial location where the minimum value can be found. Parameters: axis (None) - Only for compatibility purposes as it's not utilized. skipna (bool, default True) - Whether to ignore NA/null values for the operation. *args, **kwargs - Further arguments for compatibility with underlying methods. Returns: int - Index of the first occurrence of the minimum value in the sequence.",
    "class": "Index"
  },
  "pandas.Index.argsort": {
    "new_func": "index_sorting_order",
    "description": "Provides the sequence of indices that would arrange the elements in a sorted order. This method helps in understanding the order in which elements are sorted without changing the original sequence. Parameters: *args - Passed directly to the underlying sorting method. **kwargs - Also passed directly to the underlying sorting method. Returns: array (of integer type) - The indices that would sort the sequence.",
    "class": "Index"
  },
  "pandas.Index.asof": {
    "new_func": "prior_or_exact_label",
    "description": "Retrieves the closest label up to a certain threshold from a sorted sequence. If the specified label exists, it is returned; otherwise, the label immediately preceding the specified one is returned. A not-a-number (NaN) is returned if there is no suitable label. Parameters: label (object) - The threshold label up to which the closest label is sought. Returns: object - The exact or preceding label in relation to the threshold, or NaN if neither is found.",
    "class": "Index"
  },
  "pandas.Index.astype": {
    "new_func": "recast_index_values",
    "description": "Transforms the values of the sequence into a different data type, potentially resulting in a different sequence type. The transformation might fail if the conversion isn't feasible, raising an error in such cases. Parameters: dtype - The desired data type for the conversion. copy (bool, default True) - Specifies whether to return a new instance or modify the existing one if possible. Returns: The sequence with its values cast to the specified data type.",
    "class": "Index"
  },
  "pandas.Index.delete": {
    "new_func": "excise_indices",
    "description": "Generates a new sequence by removing the element(s) at the specified location(s). Can be used to omit single or multiple elements based on their positions. Parameters: loc (int or list of int) - The position(s) of the element(s) to remove. Returns: A new sequence of the same type, excluding the positions defined by loc, except when the original sequence is a RangeIndex.",
    "class": "Index"
  },
  "pandas.Index.difference": {
    "new_func": "distinct_complement",
    "description": "Produces a new set-like object containing elements from the calling set-like object that are not present in the provided comparable object. It performs an asymmetrical relative complement operation between two set-like collections.\nParameters:\n- other (Comparable collection) - The collection to compare with.\n- sort (Boolean or None, optional) - Decides whether to sort the result. Default behavior attempts to sort, catching any errors due to non-comparable elements.\nReturns:\n- Set-like object - A new set-like collection containing the relative complement.",
    "class": "Index"
  },
  "pandas.Index.copy": {
    "new_func": "duplicate_with_label",
    "description": "Creates and returns a new set-like object that is a duplicate of the current object, with an optional label assigned to it.\nParameters:\n- name (Label, optional) - The label to assign to the new object.\n- deep (Boolean, default False) - Indicates whether to make a deep copy of the object.\nReturns:\n- Set-like object - A new set-like object that is a duplicate of the current one.",
    "class": "Index"
  },
  "pandas.Index.drop": {
    "new_func": "discard_elements",
    "description": "Constructs a new set-like object by removing specified elements from the current object.\nParameters:\n- labels (Array-like or scalar) - The elements to remove from the set-like object.\n- errors ({'ignore', 'raise'}, default 'raise') - Determines whether to ignore errors if some labels are not found, or to raise an exception.\nReturns:\n- Set-like object - A new set-like object with specified elements removed, unless errors occur and 'raise' is specified.",
    "class": "Index"
  },
  "pandas.Index.asof_locs": {
    "new_func": "nearest_indices",
    "description": "Retrieves an array of indices representing the positions of labels from the current set-like object that correspond to the non-later nearest labels from the provided 'where' array, considering the masking array to filter out 'NA' values.\nParameters:\n- where (Comparable collection) - A collection of labels to compare against the current set-like object.\n- mask (Boolean array) - An array flagging non-'NA' values in the original data.\nReturns:\n- Array of integers - An array indicating the positions in the current set-like object for each label in 'where'.",
    "class": "Index"
  },
  "pandas.Index.droplevel": {
    "new_func": "remove_hierarchy",
    "description": "Generates a new Index or MultiIndex by eliminating one or more levels from the original hierarchical index. The original index remains unaltered.\nParameters:\n- level (Integer, string, or list-like, default 0) - Specifies the level(s) to remove, which can be indicated by name or index.\nReturns:\n- Set-like object - A new Index or MultiIndex with the specified level(s) removed.",
    "class": "Index"
  },
  "pandas.Index.fillna": {
    "new_func": "replace_nulls",
    "description": "Substitutes missing values in the index with a specified scalar value. It also offers an option to downcast the datatype of the replaced elements to a more suitable type if possible.\\nParameters: value (scalar) - The non-list-like value to use for replacing missing data.\\ndowncast (dict or 'infer', optional) - A mapping of item to datatype for downcasting or the string 'infer' to automatically find the appropriate datatype. This argument is deprecated as of version 2.1.0.\\nReturns: Index - A new index with missing values replaced by the specified value.",
    "class": "Index"
  },
  "pandas.Index.equals": {
    "new_func": "compare_indices",
    "description": "Checks for equality of the current index with another index, considering both the content and the order of elements.\\nParameters: other (Any) - The index to compare with the current index.\\nReturns: bool - True if the provided index is equivalent in terms of both elements and their order, otherwise False.",
    "class": "Index"
  },
  "pandas.Index.factorize": {
    "new_func": "categorize_elements",
    "description": "Assigns a numeric code to the unique values in the index, effectively categorizing them for use in algorithms that require numerical input. It can sort the unique values and is capable of handling missing data. The user can choose to represent missing values with a sentinel code.\\nParameters: sort (bool, default False) - If True, the unique values are sorted.\\nuse_na_sentinel (bool, default True) - If True, missing values (-1) are used as sentinel; otherwise, they are encoded as non-negative integers.\\nReturns: (codes, uniques) - A tuple containing an array of integer codes and an array of unique values or categories.",
    "class": "Index"
  },
  "pandas.Index.get_indexer_for": {
    "new_func": "locate_indices",
    "description": "Ensures the retrieval of an array of index positions corresponding to the elements of a target sequence, even when the index contains duplicates.\\nReturns: array of integers - A list of index positions that correspond to the target's elements.",
    "class": "Index"
  },
  "pandas.Index.get_indexer": {
    "new_func": "index_aligner",
    "description": "Calculates an array of positions that align the current index with a new one. It supports various methods to handle different alignment scenarios, including exact matches and the nearest match within a specified tolerance.\\nParameters: target (Index) - The new index to align with.\\nmethod (string, optional) - The method to use for alignment, including 'pad', 'backfill', or 'nearest'.\\nlimit (int, optional) - The maximum number of consecutive labels to consider for inexact matches.\\ntolerance (optional) - The allowable difference between the original and new labels for inexact matches, can be a scalar or list-like for variable tolerance.\\nReturns: array of integers - Positions from 0 to n - 1 that indicate the correspondence of the index to the target; missing target values are marked by -1.",
    "class": "Index"
  },
  "pandas.Index.get_indexer_non_unique": {
    "new_func": "locate_non_singular_indices",
    "description": "Calculates the array indices alignment and the identification mask for elements that are not uniquely found in the current array as compared to a given target array. Results support the proper alignment of data to a different array. It marks the absence of elements in the target with a specific integer.\nParameters: target (Index) - The array to compare against and align to.\nReturns: (array of integers, array of integers) - The first array contains indices corresponding to the alignment of the current array with the target. The second array indicates the positions of elements in the target that are not found in the current array.",
    "class": "Index"
  },
  "pandas.Index.get_level_values": {
    "new_func": "extract_level_data",
    "description": "Retrieves a collection of elements corresponding to a specific hierarchy level in a multi-tiered index structure. This function is also applicable to a single-tier index for uniformity.\nParameters: level (integer or string) - The specific tier position or its name within the index hierarchy.\nReturns: Index - A collection of elements from the specified tier.",
    "class": "Index"
  },
  "pandas.Index.get_loc": {
    "new_func": "retrieve_position",
    "description": "Obtains the position or a collection of positions within the index structure that correspond to a specific label.\nParameters: key (value) - The label to locate within the index.\nReturns: integer, slice, or array - The position of the label if it is unique, a range if the index is ordered, or an array of positions if there are multiple matches.",
    "class": "Index"
  },
  "pandas.Index.get_slice_bound": {
    "new_func": "determine_slice_limit",
    "description": "Identifies the appropriate boundary index for slicing, based on a label and a specified side. This boundary index represents the outer limit of the label's position within the index.\nParameters: label (object) - The reference label to determine the slice boundary.\nside (string) - Specifies whether the 'left' or 'right' boundary is desired.\nReturns: integer - The calculated boundary index for the label.",
    "class": "Index"
  },
  "pandas.Index.hasnans": {
    "new_func": "contains_nulls",
    "description": "Assesses the presence of any missing or undefined data points within the index structure.\nReturns: boolean - Indicates the presence (True) or absence (False) of missing data points.",
    "class": "Index"
  },
  "pandas.Index.identical": {
    "new_func": "index_clone_check",
    "description": "Evaluates whether two Index objects are clones, considering both their elements and attributes. It returns a truth value indicating complete equivalence, including the type of objects. Parameters: other (Index) - The Index to compare with. Returns: boolean - True if both Index objects are clones, False otherwise.",
    "class": "Index"
  },
  "pandas.Index.inferred_type": {
    "new_func": "index_element_kind",
    "description": "Provides a string describing the kind of data the Index elements represent. Returns: string - A description of the Index data type.",
    "class": "Index"
  },
  "pandas.Index.has_duplicates": {
    "new_func": "index_redundancy_check",
    "description": "Determines if any elements in the Index are not unique. Returns: boolean - True if there are non-unique elements, False if all elements are unique.",
    "class": "Index"
  },
  "pandas.Index.intersection": {
    "new_func": "index_common_elements",
    "description": "Calculates the common elements between this Index and another sequence. Depending on the 'sort' parameter, the resulting Index may or may not be sorted. Parameters: other (Index or array-like) - The sequence to intersect with. sort (bool or None, default False) - Whether to sort the resulting Index. Returns: Index - An Index containing the shared elements.",
    "class": "Index"
  },
  "pandas.Index.is_": {
    "new_func": "index_data_equality",
    "description": "Performs a flexible and efficient comparison to determine if the underlying data of two Index objects are identical. Parameters: other (object) - The object to compare against. Returns: boolean - True if the underlying data is the same for both objects, False otherwise.",
    "class": "Index"
  },
  "pandas.Index.is_boolean": {
    "new_func": "index_truth_check",
    "description": "Determines if an Index structure exclusively contains true or false values. This function is obsolete and has been replaced in recent updates. The output is a boolean indicating the composition of the Index data structure in terms of logical values. \nReturns: bool - True if exclusively true or false values, False otherwise.",
    "class": "Index"
  },
  "pandas.Index.is_categorical": {
    "new_func": "index_type_verifier",
    "description": "Assesses whether an Index structure is composed of categorically defined data. This function is outdated and a different approach is recommended for such checks in the current version. The result is a boolean value.\nReturns: bool - Indicates the categorical nature of the Index.",
    "class": "Index"
  },
  "pandas.Index.is_integer": {
    "new_func": "index_whole_number_status",
    "description": "Evaluates if an Index structure exclusively comprises whole numbers. This function has been deprecated as of a specific version in favor of a more updated method. It returns a boolean indicating whether the Index is entirely made up of integer values.\nReturns: bool - True if the Index consists only of integers, False otherwise.",
    "class": "Index"
  },
  "pandas.Index.is_floating": {
    "new_func": "index_decimal_presence",
    "description": "Inspects whether an Index structure is of a decimal type, which includes floats, missing values (NA), or a combination thereof, along with integers. This function is deprecated and superseded by a newer alternative method. It provides a boolean result regarding the Index's data type composition.\nReturns: bool - True if the Index contains floats, NA values, or a mixture including integers, False otherwise.",
    "class": "Index"
  },
  "pandas.Index.insert": {
    "new_func": "index_element_inclusion",
    "description": "Creates a new Index structure by adding a specified element at a given location. The operation adheres to the conventional semantics of numpy's insertion function for handling negative indices.\nParameters: loc (int) - The index at which to insert the new element, item (object) - The element to insert.\nReturns: Index - A new Index with the element included at the specified position.",
    "class": "Index"
  },
  "pandas.Index.is_monotonic_decreasing": {
    "new_func": "sequence_nonincreasing_check",
    "description": "Evaluates if the elements of a sequence are non-increasing, meaning each element is less than or equal to its predecessor. This assessment returns a true or false value.\\nReturns: boolean - True if the sequence is non-increasing, otherwise False.",
    "class": "Index"
  },
  "pandas.Index.is_monotonic_increasing": {
    "new_func": "sequence_nondecreasing_check",
    "description": "Determines whether the elements of a sequence are non-decreasing, indicating that each element is greater than or equal to the one before it. The output is a true or false value.\\nReturns: boolean - True if the sequence is non-decreasing, otherwise False.",
    "class": "Index"
  },
  "pandas.Index.is_interval": {
    "new_func": "range_element_verification",
    "description": "Asserts whether the elements within the collection are of a range-based type. This function is now outdated and a different approach is recommended for such verification.\\nReturns: boolean - True if the elements are range-based, otherwise False.",
    "class": "Index"
  },
  "pandas.Index.is_numeric": {
    "new_func": "digit_data_confirmation",
    "description": "Validates that every element in the collection constitutes numerical data. This function is deprecated, and alternative methods are suggested for numerical type verification.\\nReturns: boolean - True if all elements are numerical, otherwise False.",
    "class": "Index"
  },
  "pandas.Index.is_object": {
    "new_func": "generic_type_assessment",
    "description": "Inspects if the collection is composed of elements with a generic data type. This function is no longer recommended, with other options available for checking generic data types.\\nReturns: boolean - True if the collection has a generic data type, otherwise False.",
    "class": "Index"
  },
  "pandas.Index.is_unique": {
    "new_func": "distinctiveness_check",
    "description": "Evaluates whether all entries in the index are distinct from each other. It returns a truth value indicating the absence of duplicates.\nParameters: None.\nReturns: bool - True if all entries are distinct, False otherwise.",
    "class": "Index"
  },
  "pandas.Index.item": {
    "new_func": "singular_element_extract",
    "description": "Retrieves the sole element from the index as a standard Python scalar. This operation is valid only when the index consists of exactly one element.\nReturns: scalar - The single element of the index.\nRaises: ValueError - Raised when the index doesn't contain exactly one element.",
    "class": "Index"
  },
  "pandas.Index.isna": {
    "new_func": "nullity_identifier",
    "description": "Checks for the presence of missing or NA values in the index. Returns an array of boolean values of the same size, indicating the presence of missing data.\nReturns: array[bool] - An array where each boolean indicates whether an element is missing or not.",
    "class": "Index"
  },
  "pandas.Index.isin": {
    "new_func": "membership_validator",
    "description": "Generates a boolean array indicating if each element of the index appears in a provided collection. The resulting array's length corresponds to that of the index.\nParameters: \n- sought_elements (set or list-like) - Collection of elements to check against.\n- level (str or int, optional) - Specific level to use for a MultiIndex.\nReturns: array[bool] - An array of truth values showing membership of index elements in the provided collection.",
    "class": "Index"
  },
  "pandas.Index.map": {
    "new_func": "index_transformation_apply",
    "description": "Applies a specified function, mapping, or correspondence to the index, potentially transforming it. The return type can be a modified Index or MultiIndex depending on the function's output.\nParameters: \n- conversion_function (function, dict, or Series) - The rule for transforming the data.\n- na_behavior (optional) - If set to 'ignore', missing values are not passed through the transformation function.\nReturns: Index or MultiIndex - The transformed index after applying the given function or mapping.",
    "class": "Index"
  },
  "pandas.Index.join": {
    "new_func": "index_merge",
    "description": "Performs an alignment of two index objects, conforming them to a common structure based on the specified type of merge operation. This operation might be comparable to SQL table joins.\\nParameters:\\n- other (Index): The index to be merged with.\\n- how (str, optional): The type of merge to be performed; can be 'left', 'right', 'inner', or 'outer'.\\n- level (int or str, optional): Target level for the merge.\\n- return_indexers (bool, optional): If True, return the indexers of the labels in the merged index.\\n- sort (bool, optional): If True, sort the result index lexicographically. Otherwise, the order depends on the merge type.\\nReturns:\\n- A tuple consisting of the merged index and, optionally, the indexers indicating the positions of labels in the merged index.",
    "class": "Index"
  },
  "pandas.Index.memory_usage": {
    "new_func": "index_storage_footprint",
    "description": "Calculates the amount of memory occupied by the index values.\\nParameters:\\n- deep (bool, optional): If True, perform a deeper introspection of object data types to determine the memory usage.\\nReturns:\\n- An integer representing the number of bytes used by the index.",
    "class": "Index"
  },
  "pandas.Index.min": {
    "new_func": "index_floor_value",
    "description": "Retrieves the smallest element from the index, considering or disregarding NaN values based on a specified parameter.\\nParameters:\\n- axis (None): A dummy parameter included to maintain interface consistency.\\n- skipna (bool, optional): If True, ignore NaN values when determining the result; otherwise, include them.\\n- *args, **kwargs: Additional variable-length arguments and keyword arguments for compatibility.\\nReturns:\\n- A scalar value representing the minimum element within the index.",
    "class": "Index"
  },
  "pandas.Index.max": {
    "new_func": "index_ceiling_value",
    "description": "Obtains the largest element from the index, selectively excluding or including NaN values based on the given parameter.\\nParameters:\\n- axis (int, optional): Parameter for compatibility which accepts only 0 or None.\\n- skipna (bool, optional): If set to True, NaN values are not considered when computing the result.\\n- *args, **kwargs: Extra arguments and keyword arguments for compatibility purposes.\\nReturns:\\n- A scalar value that represents the maximum element in the index.",
    "class": "Index"
  },
  "pandas.Index.name": {
    "new_func": "index_label",
    "description": "Retrieves the designation or title associated with the index or multi-level index.\\nReturns:\\n- The name attribute of the index, which could be a string or an array of strings for a MultiIndex.",
    "class": "Index"
  },
  "pandas.Index.names": {
    "new_func": "identifier_labels",
    "description": "Accesses or sets the names for the index levels. These labels are typically utilized for identification purposes. The property can be assigned a list to redefine the labels.\nParameters: labels (list-like): A sequence of strings representing the new names for each level.\nReturns: Index or list - The current names of the index levels or assigns new names when a list is provided.",
    "class": "Index"
  },
  "pandas.Index.ndim": {
    "new_func": "axis_count",
    "description": "Retrieves the count of axes or dimensions for the index, which is always a fixed value of 1, indicating a single-dimensional structure.\nReturns: int - The count of dimensions, which is 1 for Index objects.",
    "class": "Index"
  },
  "pandas.Index.nbytes": {
    "new_func": "memory_footprint",
    "description": "Calculates the total memory consumption, in bytes, of the index data.\nReturns: int - The number of bytes occupied by the index.",
    "class": "Index"
  },
  "pandas.Index.notna": {
    "new_func": "existent_values",
    "description": "Evaluates which elements in the index are present and not considered missing. Produces an array of boolean values indicating the presence of data.\nReturns: array-like of bool - A collection of truth values where each is True if the corresponding element is present, otherwise False.",
    "class": "Index"
  },
  "pandas.Index.reindex": {
    "new_func": "index_align_indices",
    "description": "Aligns the current index to a given set of labels, possibly filling or interpolating values according to a specified method. It can be used to conform the index to a new set, filling in gaps and handling non-matching labels as specified.\nParameters:\n- targets (iterable): The collection of labels to align the current index to.\n- fill_method (str, optional): The technique to use for filling holes in reindexed index ('pad', 'backfill', 'nearest').\n- multiindex_level (int, optional): Specifies the level in case of a MultiIndex.\n- fill_limit (int, optional): The maximum number of consecutive labels to fill for inexact matches.\n- fill_tolerance (int or float, optional): The permissible distance between the index and new labels for inexact matches.\nReturns:\n- new_index (Index): The reindexed version of the index.\n- indexer (array-like of ints, optional): The indices in the original index corresponding to the labels in the new index.",
    "class": "Index"
  },
  "pandas.Index.shift": {
    "new_func": "advance_intervals",
    "description": "Moves the index by a specified quantity of time intervals. Ideal for datetime-like indices to increment or decrement dates and times by a specific frequency.\nParameters: periods - Integer, default 1 - The count of intervals to move, positive or negative.\nfreq - DateOffset, Timedelta, or string (optional) - The time interval to advance by. If omitted, the index's own frequency is used.\nReturns: The index adjusted by the specified time increments.",
    "class": "Index"
  },
  "pandas.Index.slice_indexer": {
    "new_func": "compute_segment_locator",
    "description": "Determines the segment of the ordered and unique index that corresponds to the specified start, end, and step values.\nParameters: start - Starting label, defaults to the first label if None.\nend - Ending label, defaults to the last label if None.\nstep - Integer, interval of the slice.\nReturns: A slice object representing the segment.\nRaises: KeyError - If the label does not exist, or if the label is not unique and the index is not ordered.",
    "class": "Index"
  },
  "pandas.Index.set_names": {
    "new_func": "assign_identifiers",
    "description": "Assigns new identifiers to the index or a level of a multi-layered index. Partial naming and specific level targeting are possible. Modifies the index directly if requested.\nParameters: identifiers (label or list of labels or dict-like for MultiIndex) - New identifier(s) to assign.\nlevel (int, label, or list of these, optional) - Specific level(s) to target in a MultiIndex.\ninplace (bool, default False) - Whether to modify the index in place or return a modified copy.\nReturns: The modified index if inplace is False, otherwise None.",
    "class": "Index"
  },
  "pandas.Index.sort_values": {
    "new_func": "order_indices",
    "description": "Generates an ordered version of the index, with the option to get the corresponding sorting indices. Supports sorting direction and handling of null values.\nParameters: return_indexer (bool, default False) - Flag to return the sorting indices.\nascending (bool, default True) - Determines the sort order.\nna_position ('first' or 'last', default 'last') - Placement of null values.\nkey (callable, optional) - Vectorized function to apply before sorting.\nReturns: ordered_index (Index) - The ordered version of the original index.\nsorter (array, optional) - The indices that sorted the original index, if return_indexer is True.",
    "class": "Index"
  },
  "pandas.Index.slice_locs": {
    "new_func": "compute_interval_positions",
    "description": "Determines the position indices for slicing the index based on provided start, end, and step labels.\nParameters: start (label, default None) - The starting label of the slice.\nend (label, default None) - The ending label of the slice.\nstep (int, default None) - The step interval for slicing.\nReturns: A tuple of integers (int, int) indicating the slice start and end positions.",
    "class": "Index"
  },
  "pandas.Index.take": {
    "new_func": "retrieve_indices",
    "description": "Creates a new instance composed of elements at specified positions. This function is compatible with internal array-like structures.\nParameters: indices (array-like) - Positions of elements to include.\naxis (int, optional) - Target axis for the operation.\nallow_fill (bool, default True) - Whether to allow filling for missing positions with a fill value.\nfill_value (scalar, default None) - Value to use for filling if allow_fill is true and indices contain -1.\nReturns: An instance of the same type containing elements at the given positions.",
    "class": "Index"
  },
  "pandas.Index.str": {
    "new_func": "textual_operations",
    "description": "Enables access to a suite of vectorized text processing methods, designed to operate on string elements. This gateway maintains null values unless the operation specifies otherwise, drawing from Python's string methods and R's approach to string handling.\nReturns: A specialized accessor for string methods.",
    "class": "Index"
  },
  "pandas.Index.union": {
    "new_func": "merge_indices",
    "description": "Combines two collections of labels into one, containing all unique elements from both. If there's a type mismatch, the collections are first converted to a common type before merging.\nParameters:\n- other (Index or array-like): The second collection to be merged.\n- sort (bool or None): Determines if the resulting collection should be sorted. The default behavior is to sort unless certain conditions are met.\nReturns:\n- A combined collection of unique labels.",
    "class": "Index"
  },
  "pandas.Index.symmetric_difference": {
    "new_func": "disjunctive_merge",
    "description": "Calculates the disjunctive union of two label collections, returning a new collection that consists of elements unique to each. The order of the resulting collection can optionally be sorted.\nParameters:\n- other (Index or array-like): The second collection for comparison.\n- result_name (str): The name for the resulting index.\n- sort (bool or None): Specifies if the result should be sorted, with a default behavior that attempts to sort but can handle TypeErrors.\nReturns:\n- A new collection containing the unique labels from both initial collections.",
    "class": "Index"
  },
  "pandas.Index.value_counts": {
    "new_func": "tally_labels",
    "description": "Produces a sequence that enumerates the frequency of distinct elements within the collection, typically sorted from most common to least common. This operation can also normalize the results, sort by occurrence, and control the inclusion of NA values.\nParameters:\n- normalize (bool): If True, the frequencies are returned as proportions.\n- sort (bool): Dictates whether the output is ordered by frequency.\n- ascending (bool): If True, the output is sorted in ascending order of frequency.\n- bins (int, optional): Groups the elements into bins; only applicable to numerical data.\n- dropna (bool): If True, NA elements are omitted from the count.\nReturns:\n- A sequence enumerating the frequency of each unique element.",
    "class": "Index"
  },
  "pandas.Index.view": {
    "new_func": "cast_index",
    "description": "Generates a new object that is a view of the input data structure. This means the new object looks at the same data as the original. Optionally, the view can be cast to a provided class.\nParameters: cls (class, optional) - The class to which to cast the view.\nReturns: An object of the same type as the original, or the specified class if provided, which is a view on the original data.",
    "class": "Index"
  },
  "pandas.Index.values": {
    "new_func": "index_array_elements",
    "description": "Acquires the data from the index as an array structure. It is advisable to utilize alternative methods if a reference to the underlying data or a compatible array is necessary.\nReturns: An array structure containing the data from the index.",
    "class": "Index"
  },
  "pandas.Index.to_list": {
    "new_func": "index_to_python_list",
    "description": "Converts the index's contents into a standard Python list, with each item preserving its native scalar type.\nReturns: A Python list containing the scalar values from the index.",
    "class": "Index"
  },
  "pandas.IntervalIndex": {
    "new_func": "RangePartition",
    "description": "Constructs an immutable index structure composed of non-overlapping ranges. Each range is either open or closed at its endpoints. The structure is unmodifiable and supports rapid membership checks for interval-based data.\\nParameters: data (array-like, 1-dimensional) - A sequence of interval objects.\\nclosed (string, optional) - Specifies whether the ranges are open or closed on each side, with options 'left', 'right', 'both', or 'neither'.\\ndtype (dtype or None, optional) - The desired data-type for the index. If omitted, it will be inferred.\\ncopy (boolean, default False) - Indicates whether to copy the input data.\\nname (object, optional) - A name identifier for the index.\\nverify_integrity (boolean, default True) - Ensures the validity of the index upon creation.\\nReturns: A new index object.",
    "class": "IntervalIndex"
  },
  "pandas.Interval.overlaps": {
    "new_func": "RangeIntersection",
    "description": "Determines if there is a shared segment between two range-like objects, including their endpoints. A common edge does not constitute an intersection if both edges are open.\\nParameters: other (Interval) - The range object to compare with.\\nReturns: boolean - Indicates whether a shared segment exists.",
    "class": "Interval"
  },
  "pandas.Interval.open_right": {
    "new_func": "IsRightOpen",
    "description": "Determines if the right boundary of a range-like object is not inclusive.\\nReturns: boolean - True if the right boundary is exclusive.",
    "class": "Interval"
  },
  "pandas.Interval.mid": {
    "new_func": "CentralPoint",
    "description": "Calculates the middle value of a range-like object.\\nReturns: The central value.",
    "class": "Interval"
  },
  "pandas.IntervalIndex.closed": {
    "new_func": "BoundaryType",
    "description": "Provides a textual representation indicating if the ranges within the index are inclusive at the start, end, both, or neither side.\\nReturns: A string denoting the inclusiveness of the index boundaries.",
    "class": "IntervalIndex"
  },
  "pandas.IntervalIndex.get_loc": {
    "new_func": "find_interval_position",
    "description": "Retrieves the position of a given interval as an integer, range or a mask. The method determines the location of a specified interval in the index.\nParameters: key (label) - The interval to find.\nReturns: integer if the index is unique, range if the index is sequentially ordered, or a boolean mask otherwise.",
    "class": "IntervalIndex"
  },
  "pandas.IntervalIndex.from_tuples": {
    "new_func": "construct_interval_basis",
    "description": "Creates an index based on intervals from a list of tuple pairs. This constructor accepts an array-like structure of tuple elements to form intervals.\nParameters: \n- data (array-like, 1-dimensional) - A list of tuple pairs.\n- closed (string, options: 'left', 'right', 'both', 'neither') - Indicates which side of the interval is closed.\n- name (string, optional) - Assigns a name to the resulting index.\n- copy (boolean, default False) - Determines whether to copy the input data, mostly for compatibility purposes and usually ignored.\n- dtype (data type or None, default None) - Data type of the index; if unspecified, the type is inferred.\nReturns: A new index structure based on the provided intervals.",
    "class": "IntervalIndex"
  },
  "pandas.IntervalIndex.is_non_overlapping_monotonic": {
    "new_func": "check_sequence_disjoint_sorted",
    "description": "Evaluates whether the collection of intervals is sorted in a single direction and none of them intersect with each other.\nReturns: A boolean value indicating the sorted and disjoint nature of the intervals.",
    "class": "IntervalIndex"
  },
  "pandas.IntervalIndex.is_overlapping": {
    "new_func": "verify_intervals_intersection",
    "description": "Assesses if any of the intervals within the index intersect with one another.\nReturns: A boolean indicating if there are any intersecting intervals within the index.",
    "class": "IntervalIndex"
  },
  "pandas.IntervalIndex.left": {
    "new_func": "extract_beginning_bounds",
    "description": "Accesses the starting boundary values of each interval present in the index.\nReturns: An array containing the left-side boundaries of the intervals.",
    "class": "IntervalIndex"
  },
  "pandas.IntervalIndex.overlaps": {
    "new_func": "interval_conjunction",
    "description": "Evaluates each interval in the collection for common points with another set of intervals. Parameters: other - An IntervalArray to compare against. Returns: array - An array of booleans indicating the presence of a conjunction at corresponding positions.",
    "class": "IntervalIndex"
  },
  "pandas.IntervalIndex.right": {
    "new_func": "boundary_terminus",
    "description": "Accesses the right-side endpoint for each interval within the collection. Returns: Index - The right-side endpoints.",
    "class": "IntervalIndex"
  },
  "pandas.IntervalIndex.set_closed": {
    "new_func": "define_termini",
    "description": "Produces a new IntervalArray with specified endpoint closure. Parameters: closed - A string indicating which sides ('left', 'right', 'both', 'neither') should be closed. Returns: IntervalArray - The modified IntervalArray with updated endpoint closures.",
    "class": "IntervalIndex"
  },
  "pandas.IntervalIndex.to_tuples": {
    "new_func": "convert_to_pairs",
    "description": "Transforms the collection into an array or Index of ordered pairs representing the interval endpoints. Parameters: na_tuple - A boolean flag indicating how to handle NA values, returning them as a tuple of NaNs if True. Returns: array or Index - An array or Index of tuples with the interval endpoints.",
    "class": "IntervalIndex"
  },
  "pandas.IntervalIndex.mid": {
    "new_func": "central_point",
    "description": "Retrieves the central value of each interval within an interval-based index structure. It provides a simple way to access the midpoint of ranges in a data structure designed for interval data. Parameters: None. Returns: array-like - The central values for all intervals.",
    "class": "IntervalIndex"
  },
  "pandas.MultiIndex": {
    "new_func": "hierarchical_keys",
    "description": "Creates an object representing a multi-layered key structure for data indexing purposes. It allows for the organization of data in a nested, tree-like format. Parameters: - levels (sequence of array-like): Distinct labels for each hierarchy level. - codes (sequence of array-like): Integer arrays for each level, which map labels to locations. - sortorder (optional int): The sort level. - names (optional sequence): Identifiers for each of the index levels. - dtype (data type, optional): The data type for the index. - copy (bool, default False): If true, copies the metadata before modification. - name (object, optional): A label for name compatibility. - verify_integrity (bool, default True): Ensures that the levels and codes form a valid structure. Returns: object - An instance representing hierarchical indices.",
    "class": "MultiIndex"
  },
  "pandas.IntervalIndex.values": {
    "new_func": "range_contents",
    "description": "Obtains an array-like structure encapsulating the data within an interval-indexed structure. It serves as an accessor for the data elements indexed by intervals. Warning: Prefer the use of dedicated array or to-array conversion methods for better control over the output format. Returns: - array-like: An array structure that could be a native array or an extension array.",
    "class": "IntervalIndex"
  },
  "pandas.MultiIndex.copy": {
    "new_func": "duplicate_hierarchy",
    "description": "Generates a duplicate of the current hierarchical index object, with the option to override specific attributes during duplication. Parameters: - names (optional sequence): Labels for the resulting index's levels. - deep (bool, default False): If true, copy the data deeply. - name (object, optional): Reserved for compatibility; avoid using for 1D indices. Returns: object - A new instance of a hierarchical index with identical or updated attributes.",
    "class": "MultiIndex"
  },
  "pandas.MultiIndex.droplevel": {
    "new_func": "discard_hierarchy_level",
    "description": "Creates a new index by eliminating specified levels from a hierarchical index. If the resulting structure has only a single tier, it converts into a simpler index structure. The modification does not alter the original hierarchical index.\nParameters: level (int, str, or list-like, default 0) - The index or name of the level(s) to remove.\nReturns: A simpler index if only one tier remains, otherwise a hierarchical index with the specified level(s) removed.",
    "class": "MultiIndex"
  },
  "pandas.MultiIndex.drop": {
    "new_func": "remove_tuples",
    "description": "Generates a new hierarchical index by eliminating the specified tuples. If a level is not specified, the tuples must be complete.\nParameters: codes (array-like) - List of tuples to remove. level (int or level name, default None) - Specific level from which to remove the tuples. errors (str, default 'raise') - If 'raise', an error will be raised if any code is not found.\nReturns: A new hierarchical index with the specified tuples removed.",
    "class": "MultiIndex"
  },
  "pandas.MultiIndex.from_frame": {
    "new_func": "hierarchy_from_dataframe",
    "description": "Constructs a hierarchical index from a tabular data structure.\nParameters: df (DataFrame) - The data structure to convert into a hierarchical index. sortorder (int, optional) - The level of sorting by lexicographical order. names (list-like, optional) - The names to assign to the levels of the index; defaults to the data structure's column names.\nReturns: A hierarchical index constructed from the provided data structure.",
    "class": "MultiIndex"
  },
  "pandas.MultiIndex.get_indexer": {
    "new_func": "aligner_indices",
    "description": "Calculates an array of integers that maps the entries of the current hierarchical index to the entries of a new index. This mapping array can be used to reorganize data to align with the new index.\nParameters: target (Index) - The new index to map against. method ({None, 'pad'/'ffill', 'backfill'/'bfill', 'nearest'}, optional) - The method to use when an exact match is not found. limit (int, optional) - The maximum number of consecutive labels to match for inexact alignments. tolerance (optional) - The maximum distance allowed between original and new labels for inexact alignments.\nReturns: An array of integers indicating the positions of the matching entries in the new index. Missing values in the target are indicated by -1.",
    "class": "MultiIndex"
  },
  "pandas.MultiIndex.reorder_levels": {
    "new_func": "reshuffle_hierarchy",
    "description": "Adjusts the sequence of the hierarchical index layers according to a specified order. This operation retains all index layers without introducing duplicates or omitting any. It alters the arrangement but maintains the overall structure.\nParameters: order (list of int or list of str) - The desired order of index layers, identified by their integer positions or string labels.\nReturns: A new hierarchical index with reordered levels.",
    "class": "MultiIndex"
  },
  "pandas.MultiIndex.get_level_values": {
    "new_func": "extract_layer_data",
    "description": "Produces a sequence of labels for a specified layer within a hierarchical index. The length of the output matches the hierarchy's total length.\nParameters: level (int or str) - The specific layer of interest, denoted by its position or name.\nReturns: An Index object containing the labels of the specified layer.",
    "class": "MultiIndex"
  },
  "pandas.MultiIndex.get_loc_level": {
    "new_func": "fetch_location_slice",
    "description": "Retrieves the position and corresponding subset of a hierarchical index for given label(s) at a specified layer. The output is a tuple where the first element is the location identifier and the second element is the sliced index.\nParameters: key (label or sequence of labels) - Targeted label(s) for retrieval.\nlevel (int, str, or list, optional) - Specific layer(s) to consider.\ndrop_level (bool, default True) - If False, retains the level in the resulting index.\nReturns: A tuple with two elements: (1) location specifier, (2) sliced hierarchical index or None if all layers are specified in the key.",
    "class": "MultiIndex"
  },
  "pandas.MultiIndex.remove_unused_levels": {
    "new_func": "prune_idle_layers",
    "description": "Generates a new hierarchical index by eliminating any layers that are not represented in the labels. The new index will appear identical in terms of values and order, and will be considered equal to the original.\nReturns: A hierarchical index with the unused layers removed.",
    "class": "MultiIndex"
  },
  "pandas.MultiIndex.set_codes": {
    "new_func": "assign_new_identifiers",
    "description": "Applies new identifiers to the specified layers of a hierarchical index, typically resulting in a new index instance.\nParameters: codes (sequence or list of sequences) - The new identifiers for the index layers.\nlevel (int, str, or sequence, optional) - The layer(s) to update, with None implying all layers.\nverify_integrity (bool, default True) - When True, ensures compatibility between levels and new codes.\nReturns: A new index of the same type unless the operation is performed in place.",
    "class": "MultiIndex"
  },
  "pandas.Period.now": {
    "new_func": "current_cycle_moment",
    "description": "Retrieves the current time cycle based on a specified frequency. It gives the time period associated with the current date. Parameters: freq (str or BaseOffset) - The timing frequency for the resulting time cycle. Returns: Period instance - Corresponds to the current time cycle.",
    "class": "Period"
  },
  "pandas.Period.strftime": {
    "new_func": "cycle_format",
    "description": "Provides a textual representation of the time cycle, formatted according to directives provided. If directives are unspecified, the output format is inferred from the time cycle's frequency. Compatible with standard time formatting directives, as well as a few specialized ones. Parameters: fmt (str, optional) - The formatting string with directives. Returns: str - The textual representation of the time cycle.",
    "class": "Period"
  },
  "pandas.Period.second": {
    "new_func": "cycle_second_component",
    "description": "Retrieves the seconds portion from the time cycle, ranging from 0 to 59. Returns: int - The seconds part of the time cycle.",
    "class": "Period"
  },
  "pandas.Period.week": {
    "new_func": "cycle_week_of_year",
    "description": "Obtains the week number within the year from a given time cycle. Returns: int - The week number within the year.",
    "class": "Period"
  },
  "pandas.Period.weekday": {
    "new_func": "cycle_week_day",
    "description": "Determines the day of the week for the time cycle, using a zero-based index with Monday as the start. Returns: int - The index of the day within the week.",
    "class": "Period"
  },
  "pandas.PeriodIndex.hour": {
    "new_func": "period_hour_component",
    "description": "Accesses the hour component of the temporal division within the day from the index. It extracts the hour part, indicating the time elapsed since midnight for the given period.\nReturns: Integer - The hour portion of the period.",
    "class": "PeriodIndex"
  },
  "pandas.PeriodIndex.minute": {
    "new_func": "period_minute_component",
    "description": "Obtains the minute component of the temporal division within the hour from the index. This attribute pinpoints the specific minute within the hour for the period in question.\nReturns: Integer - The minute slice of the period.",
    "class": "PeriodIndex"
  },
  "pandas.PeriodIndex.start_time": {
    "new_func": "initial_timestamp",
    "description": "Acquires the initial point in time for the specified period. This property provides a datetime object marking the commencement of the period.\nReturns: DateTime - The starting point in time for the period.",
    "class": "PeriodIndex"
  },
  "pandas.PeriodIndex.quarter": {
    "new_func": "trimester_section",
    "description": "Fetches the trimester segment of the year to which the indexed period belongs. It differentiates which part of the year, split into four equal parts, the period falls into.\nReturns: Integer - The three-month segment of the year.",
    "class": "PeriodIndex"
  },
  "pandas.PeriodIndex.to_timestamp": {
    "new_func": "period_sequence_to_datetime",
    "description": "Converts a time-span collection into a datetime array or index. This operation changes the type of the collection to allow date and time arithmetic. The target frequency and the specific moment of conversion within the interval can be specified.\nParameters: target_frequency (string or DateOffset, optional) - The desired frequency for the datetime representation. Defaults to 'D' for weekly intervals or longer, 's' for others.\nconversion_moment ({'s', 'e', 'start', 'end'}) - Specifies whether to align the conversion to the interval's commencement or conclusion.\nReturns: A datetime array/index reflecting the converted datetime values.",
    "class": "PeriodIndex"
  },
  "pandas.PeriodIndex.end_time": {
    "new_func": "finalize_interval_timestamp",
    "description": "Retrieves the final point in time for the specified interval. This would return the last instance that marks the completion of the defined time span.\nReturns: A Timestamp representing the final moment of the time interval.",
    "class": "PeriodIndex"
  },
  "pandas.PeriodIndex.freqstr": {
    "new_func": "interval_frequency_as_string",
    "description": "Provides the string representation of the interval's frequency, if it is defined. Otherwise, returns a null value.\nReturns: A string depicting the frequency of the interval, or None if not set.",
    "class": "PeriodIndex"
  },
  "pandas.PeriodIndex.freq": {
    "new_func": "interval_frequency",
    "description": "Accesses the frequency attribute of the interval collection. This property provides insight into the regularity with which the intervals occur.\nReturns: The frequency attribute of the interval collection.",
    "class": "PeriodIndex"
  },
  "pandas.PeriodIndex.weekday": {
    "new_func": "interval_weekday_indices",
    "description": "Determines the index of weekdays for the intervals, starting with Monday as 0 and ending with Sunday as 6.\nReturns: An array denoting the position of the weekday within the week, for each interval.",
    "class": "PeriodIndex"
  },
  "pandas.Series.abs": {
    "new_func": "magnitude_values",
    "description": "Computes and returns the non-negative value of each element in the series or data structure. This operation is only applicable to elements of a numeric type.\nParameters: None\nReturns: A similar series or data structure consisting of the non-negative values corresponding to each element.",
    "class": "Series"
  },
  "pandas.Series.agg": {
    "new_func": "compress_operations",
    "description": "Applies one or several functions to the series, potentially reducing its dimension. This method can accept a variety of function formats and combinations to perform its operation.\nParameters: \n- func (function, string, list, or dictionary): The function(s) to apply.\n- axis (int or string): Axis along which to apply the functions. Default is 0.\n- *args: Positional arguments for the function.\n- **kwargs: Keyword arguments for the function.\nReturns:\n- A scalar, series, or frame depending on the input function(s) provided.",
    "class": "Series"
  },
  "pandas.Series.add": {
    "new_func": "increment_by",
    "description": "Performs element-wise addition between the series and another series or a scalar value. This method supports filling in missing values with a specified number before calculation.\nParameters:\n- other (Series or scalar): The second operand in the addition.\n- level (int or string): Level on which to broadcast across a MultiIndex.\n- fill_value (numeric): Value to use for replacing missing entries before computation.\n- axis (int or string): Axis for the operation, default is 0.\nReturns:\n- A series with the resulting values post addition.",
    "class": "Series"
  },
  "pandas.Series.all": {
    "new_func": "universally_truthful",
    "description": "Checks if all elements in the series evaluate to True, excluding NA values by default. An element is considered True if it is non-zero or non-empty.\nParameters:\n- axis (int, string, or None): Axis to aggregate over. Default is 0.\n- bool_only (bool): If set to True, only boolean columns are considered.\n- skipna (bool): If set to True, ignores NA values during evaluation.\n- **kwargs: Additional arguments are accepted for compatibility.\nReturns:\n- A scalar or series indicating the Truth evaluation of the entire series or along the specified axis.",
    "class": "Series"
  },
  "pandas.Series.any": {
    "new_func": "existential_verity",
    "description": "Evaluates whether any element in the series is True, excluding NA values by default. An element is considered True if it is non-zero or non-empty.\nParameters:\n- axis (int, string, or None): Axis to aggregate over. Default is 0.\n- bool_only (bool): If set to True, only boolean columns are considered.\n- skipna (bool): If set to True, ignores NA values during evaluation.\n- **kwargs: Additional arguments are accepted for compatibility.\nReturns:\n- A scalar or series indicating if at least one element is True within the entire series or along a specified axis.",
    "class": "Series"
  },
  "pandas.Series.align": {
    "new_func": "synchronize_series",
    "description": "Synchronizes two data structures, ensuring they share a common set of index labels, according to a specified alignment strategy. The operation can harmonize the indices of both structures, either by including only the shared labels, all labels, or the labels from one or the other. The result is a pair of new structures with matching axes. Options exist to fill missing entries with a specified value or propagate existing values. Parameters: - other (DataFrame or Series): The data structure to align with. - join (str): The strategy for index alignment, with options 'outer', 'inner', 'left', or 'right'. - axis (int or None): The axis to align along, with 0 for index and 1 for columns, or None for both. - level (int or level name): The level in a MultiIndex to align to. - copy (bool): Determines whether to always return new objects or the original objects if no reindexing is needed. - fill_value (scalar): The value to use for filling missing data. - method (str): The method for forward or backward filling of missing values. - limit (int): The maximum number of consecutive missing values to fill. - fill_axis (int or str): The axis along which to fill missing values. - broadcast_axis (int or str): The axis along which to broadcast when aligning objects of different dimensions. Returns: - tuple: A pair of aligned objects (Series/DataFrame, same type as other).",
    "class": "Series"
  },
  "pandas.Series.argmin": {
    "new_func": "index_of_minimum",
    "description": "Determines the positional index where the smallest value is located within the data structure. When the smallest value occurs multiple times, the index of its first occurrence is returned. NA/null values can be excluded from consideration. Parameters: - axis (None): Unused, present for compatibility. - skipna (bool): Whether to exclude NA/null values from the search. - *args, **kwargs: Additional arguments for compatibility with other libraries. Returns: - int: Index of the first occurrence of the minimum value.",
    "class": "Series"
  },
  "pandas.Series.argmax": {
    "new_func": "index_of_maximum",
    "description": "Identifies the positional index where the largest value is found within the data structure. In cases where the maximum value appears more than once, the index of the first occurrence is provided. This function allows omitting NA/null values from the search process. Parameters: - axis (None): Unused and only included for compatibility. - skipna (bool): Option to exclude NA/null values when identifying the maximum value. - *args, **kwargs: Extra arguments for compatibility with external libraries. Returns: - int: Index of the first occurrence of the maximum value.",
    "class": "Series"
  },
  "pandas.Series.argsort": {
    "new_func": "indices_for_sorted_order",
    "description": "Calculates the indices that would arrange the data structure's values in ascending order. This method takes into account the presence of NA/null values, which are assigned the index -1 and thus placed at the end of the sorted array. Parameters: - axis (int or str): Unused, present for compatibility. - kind (str): The algorithm used for sorting, with options like 'mergesort', 'quicksort', 'heapsort', or 'stable'. - order (None): Unused parameter, included for compatibility. - stable (None): Unused parameter, included for compatibility. Returns: - Series of int: An array of indices indicating the sorted order of the original values.",
    "class": "Series"
  },
  "pandas.Series.apply": {
    "new_func": "invoke_custom_function",
    "description": "Executes a specified function on each element or the entire data structure, depending on the function's capabilities. This can be applied to single values or to the entire series if the function is capable of vectorized operations. Parameters: - func (function): The function to execute on the data structure's elements. - convert_dtype (bool): Whether to attempt to convert the result to a better data type, defaulting to True. Deprecated in version 2.1.0. - args (tuple): Positional arguments to pass to the function after the value from the data structure. - by_row (bool or str): Controls whether the function is applied element-wise ('compat') or to the entire series at once (False). New in version 2.1.0. - **kwargs: Additional keyword arguments to send to the function. Returns: - Series or DataFrame: The result of applying the function, which may be either of the same type or a different type depending on the function's return value.",
    "class": "Series"
  },
  "pandas.Series.cat.as_unordered": {
    "new_func": "categorize_without_order",
    "description": "This method marks a category-based attribute as having no inherent sequence. It modifies the attribute to indicate that its categories should not be considered in a specific order. The method returns a modified version of the attribute with the sequencing attribute removed.\nReturns: A modified categorical attribute with the sequencing property removed.",
    "class": "Series"
  },
  "pandas.Series.cat.reorder_categories": {
    "new_func": "reshuffle_category_sequence",
    "description": "Alters the sequence of existing categorical labels according to the array provided, ensuring that the supplied array includes all current labels without introducing new ones. The method also allows specifying whether the attribute should be treated as having an intrinsic order.\nParameters: new_sequence (array-like) - The desired arrangement of categorical labels; ordered (bool, optional) - Indicator of whether the category should be considered ordered.\nReturns: A categorical attribute with its labels rearranged as specified.\nRaises: ValueError if the provided sequence does not cover all existing labels or introduces new ones.",
    "class": "Series"
  },
  "pandas.Series.cat.remove_categories": {
    "new_func": "eliminate_specified_labels",
    "description": "Erases certain labels from a categorical attribute. The labels to be removed must already exist within the attribute. Entries associated with the erased labels will be assigned a null value.\nParameters: deletions (category or list of categories) - The labels to be expunged.\nReturns: A categorical attribute absent the specified labels.\nRaises: ValueError if any of the labels to be removed are not currently present in the attribute.",
    "class": "Series"
  },
  "pandas.Series.cat.rename_categories": {
    "new_func": "alter_category_labels",
    "description": "Substitutes existing categorical labels with new ones, which can be specified through a list, mapping, or a function that transforms the old labels to new ones. The transformation must ensure that the new labels are unique and that their count matches the count of existing labels.\nParameters: new_labels (list-like, dict-like, or callable) - Defines the new categorical labels.\nReturns: A categorical attribute with updated labels.\nRaises: ValueError if the new labels do not match in number with existing labels, are not unique, or do not conform to categorical constraints.",
    "class": "Series"
  },
  "pandas.Series.combine_first": {
    "new_func": "merge_with_fallback",
    "description": "Merges the object with another, using values from the latter to fill in null entries of the former. The merged object will have an index that is the combination of both objects' indices.\nParameters: fallback_source (Series) - The object used as a backup to fill in null entries.\nReturns: A new object with null values filled from the corresponding entries in the fallback source.",
    "class": "Series"
  },
  "pandas.Series.cummax": {
    "new_func": "sequential_peak",
    "description": "Calculates the progressive apex values across a dataset. It generates a sequence with each element representing the highest value up to that point. Exclusion of missing data is optional.\nParameters: \n- axis (int or str): The axis to apply the function on. Defaults to 0.\n- skipna (bool): Whether to ignore missing values. Defaults to True.\nReturns: \n- An object of similar dimensions with the accumulated maximum values.",
    "class": "Series"
  },
  "pandas.Series.describe": {
    "new_func": "dataset_summary",
    "description": "Provides a synopsis of statistical measures for a collection of data, including measures of central location, dispersion, and shape, but disregards missing values. It supports a variety of data types and can be tailored to include specific percentiles or data types.\nParameters:\n- percentiles (list-like): Percentiles to include in the synopsis.\n- include (list-like, 'all', or None): Data types to consider in the synopsis.\n- exclude (list-like or None): Data types to omit from the synopsis.\nReturns:\n- A summary object with statistical information about the data.",
    "class": "Series"
  },
  "pandas.Series.cumsum": {
    "new_func": "aggregate_escalation",
    "description": "Computes the aggregate ascent by adding values sequentially across a data structure. It yields a structure with each element being the sum total up to that index, optionally disregarding missing entries.\nParameters: \n- axis (int or str): The axis for the operation. Defaults to 0.\n- skipna (bool): Option to exclude missing values. Defaults to True.\nReturns: \n- An object reflecting the cumulative sum.",
    "class": "Series"
  },
  "pandas.Series.cummin": {
    "new_func": "sequential_nadir",
    "description": "Determines the progressive lowest values in a dataset, delivering a sequence where each element is the smallest value encountered up to that point, with the possibility to omit missing data.\nParameters: \n- axis (int or str): The axis for calculation. Defaults to 0.\n- skipna (bool): Whether to ignore missing values. Defaults to True.\nReturns: \n- An object mirroring the same shape with the accumulated minimum values.",
    "class": "Series"
  },
  "pandas.Series.cumprod": {
    "new_func": "accumulative_multiplication",
    "description": "Calculates the ongoing product by multiplying elements in sequence across a dataset. It provides a structure equivalent in size with each component representing the product up to that index, with an option to exclude missing values.\nParameters: \n- axis (int or str): Axis to perform the operation on. Defaults to 0.\n- skipna (bool): Whether to ignore missing entries. Defaults to True.\nReturns: \n- An object containing the cumulative product.",
    "class": "Series"
  },
  "pandas.Series.div": {
    "new_func": "fractional_elementwise_combine",
    "description": "Performs element-by-element true division of the invoking series by another series or a scalar, optionally replacing missing values with a specified number. Parameters: - other (Series or scalar): The divisor. - level (int or name, optional): The level in a MultiIndex to broadcast across. - fill_value (float, optional): The value to use to fill missing entries before computation. - axis (int or 'index', optional): Axis for the function to be applied on. Returns: - Series: The quotient of the division.",
    "class": "Series"
  },
  "pandas.Series.dot": {
    "new_func": "scalar_product_compute",
    "description": "Calculates the scalar product of the series with another series, a data structure or an array-like object. When working with a data structure, it performs the computation across the columns. Parameters: - other (Series, DataFrame, or array-like): The object to calculate the scalar product with. Returns: - scalar, Series or array: The result of the scalar product computation.",
    "class": "Series"
  },
  "pandas.Series.drop": {
    "new_func": "omit_indexed_elements",
    "description": "Excludes specified elements from the series based on their index labels. Supports removal of single or multiple labels and is compatible with hierarchical indices. Parameters: - labels (single label or list-like): Index labels to exclude. - level (int or level name, optional): The level to remove labels from in case of MultiIndex. - inplace (bool, default False): If set to True, performs operation in-place and returns None. - errors ('ignore' or 'raise', default 'raise'): Error handling strategy. Returns: - Series or None: The modified series without the specified labels, or None if operation was in-place.",
    "class": "Series"
  },
  "pandas.Series.diff": {
    "new_func": "sequential_difference",
    "description": "Computes the difference between consecutive elements in the series, offset by a specified number of periods. Useful for discrete differentiation. Parameters: - periods (int, default 1): The number of periods to offset for the difference computation. Negative values are accepted. Returns: - Series: The differences computed.",
    "class": "Series"
  },
  "pandas.Series.droplevel": {
    "new_func": "eliminate_index_levels",
    "description": "Removes specified levels from the index of the series. Can target a single level or multiple levels by name or index. Parameters: - level (int, str, or list-like): The level(s) to be removed. - axis ({0 or 'index', 1 or 'columns'}, default 0): The axis along which to drop the level(s). Note: For series, this is always 0 or 'index'. Returns: - Series: The series with the specified level(s) removed from its index.",
    "class": "Series"
  },
  "pandas.Series.dt.minute": {
    "new_func": "time_fraction_hour",
    "description": "Extracts the time component representing sixtieths of an hour from each timestamp in the series.\nParameters: None.\nReturns: A series or index with the specified time component ranging from 0 to 59.",
    "class": "Series"
  },
  "pandas.Series.dt.month_name": {
    "new_func": "verbal_month_identifier",
    "description": "Retrieves the denominations of the months corresponding to the timestamps in the series, optionally adapting the language to the specified locale.\nParameters: locale (str, optional) - The locale code to determine the language for the month names. Defaults to English ('en_US.utf8'). To find your system's locale language codes, use the terminal command 'locale -a' on Unix-based systems.\nReturns: A series or index with the translated month names.",
    "class": "Series"
  },
  "pandas.Series.dt.nanoseconds": {
    "new_func": "submicrosecond_units",
    "description": "Determines the count of the smallest time unit within the sub-microsecond range for each timestamp in the series. It returns the number of these time units (non-negative and less than one microsecond) for each element.\nParameters: None.\nReturns: A series or index indicating the quantity of these specific time units.",
    "class": "Series"
  },
  "pandas.Series.dt.nanosecond": {
    "new_func": "time_component_billionth_second",
    "description": "Gathers the time unit that represents a billionth of a second from the timestamps in the series.\nParameters: None.\nReturns: A series or index with the value of this minute time unit.",
    "class": "Series"
  },
  "pandas.Series.dt.start_time": {
    "new_func": "period_initiation_moment",
    "description": "Obtains the initial point in time for a given period represented within the data structure. The output reflects the earliest timestamp of the specified interval.\nParameters: None.\nReturns: Timestamp - The initial datetime instance for the period under consideration.",
    "class": "Series"
  },
  "pandas.Series.dt.total_seconds": {
    "new_func": "duration_in_seconds",
    "description": "Calculates the span of each element within a time delta collection, converting it to a quantity of seconds.\nParameters: *args (additional positional arguments), **kwargs (additional keyword arguments).\nReturns: A numerical array, index, or series - When invoked on a TimedeltaArray, it yields a numerical array. If on a TimedeltaIndex, it produces an index with float64 data type. For a series input, it results in a series of float64 type, maintaining the original indexing.",
    "class": "Series"
  },
  "pandas.Series.dt.to_pytimedelta": {
    "new_func": "convert_to_native_timedelta",
    "description": "Transforms a sequence of time duration objects into the native Python representation of 'datetime.timedelta'.\nParameters: None.\nReturns: Array - A one-dimensional array consisting of 'datetime.timedelta' objects, with a length identical to the original sequence.",
    "class": "Series"
  },
  "pandas.Series.dt.to_pydatetime": {
    "new_func": "export_to_native_datetime",
    "description": "Converts the data into an array of 'datetime.datetime' objects, adhering to the native Python format. While retaining timezone details if available, users should be aware of the potential truncation of values due to differences in temporal resolution.\nParameters: None.\nReturns: Array - A collection of 'datetime.datetime' instances with object data type.",
    "class": "Series"
  },
  "pandas.Series.dt.tz": {
    "new_func": "retrieve_timezone_info",
    "description": "Acquires the timezone information associated with the datetime data. If the data does not contain timezone details, the result will be 'None'.\nParameters: None.\nReturns: Timezone object or None - The timezone information as a 'datetime.tzinfo' object, or 'None' if the data is timezone-unaware.",
    "class": "Series"
  },
  "pandas.Series.expanding": {
    "new_func": "growing_window_calculator",
    "description": "Calculates a range of statistics over an expanding window of values, starting with a minimum number of entries and increasing until it encompasses the entire data set. This operation is similar to a rolling window, but the window size grows with each point instead of shifting.\\nParameters: min_periods (int) - The minimum number of entries required for the window to return a value; otherwise, the result is a NaN.\\nReturns: An object allowing for the computation of statistics over the expanding window.",
    "class": "Series"
  },
  "pandas.Series.equals": {
    "new_func": "data_matcher",
    "description": "Assesses whether two data containers of the same type have identical contents, considering the order and presence of elements, including null values at corresponding positions.\\nParameters: other (Same type as calling object) - The data container to compare with the caller.\\nReturns: A boolean value indicating whether the contents match exactly.",
    "class": "Series"
  },
  "pandas.Series.explode": {
    "new_func": "list_to_row_transformer",
    "description": "Converts each entry within a list-like structure into its own row, effectively expanding list entries into multiple rows.\\nParameters: ignore_index (bool) - If set to True, the resulting index will be a range from 0 to n-1, otherwise the original index is used with duplicate values for the expanded rows.\\nReturns: A data structure with the list entries transformed into rows.",
    "class": "Series"
  },
  "pandas.Series.factorize": {
    "new_func": "enumerated_encoder",
    "description": "Assigns a unique integer code to each distinct value in the data, which is often useful for converting categorical data into a numerical format suitable for algorithms that require numerical input.\\nParameters: sort (bool) - Dictates whether the unique values should be sorted before encoding.\\nuse_na_sentinel (bool) - Determines if NaN values should use a sentinel value or be encoded as non-negative integers.\\nReturns: A tuple containing an array of the integer codes and an array of the unique values or categories.",
    "class": "Series"
  },
  "pandas.Series.fillna": {
    "new_func": "null_value_replacer",
    "description": "Substitutes missing or null entries with a specified value or according to a specified method such as forward or backward filling.\\nParameters: value (scalar, dict, or same type as caller) - The replacement value for missing entries, or a collection providing replacement values for specific indices.\\nmethod (string) - Specifies the method for filling, such as 'forward' or 'backward'.\\naxis (int or string) - The axis over which to apply the fill method.\\ninplace (bool) - If set to True, the operation will modify the data in place.\\nlimit (int) - The maximum number of consecutive missing entries to fill when using a fill method.\\nReturns: The object with missing values replaced, or None if the operation is performed in place.",
    "class": "Series"
  },
  "pandas.Series.kurtosis": {
    "new_func": "excess_fisher_coefficient",
    "description": "Calculates the excess coefficient of peakedness for a dataset, utilizing the Fisher method where a perfect normal distribution has a value of 0.0. This computation is unbiased and normalized by the count minus one. The calculation can exclude null values and, if applicable, only consider numerical data. Parameters: axis (int, default 0) - The axis along which the calculation is performed. skipna (bool, default True) - Whether to exclude NA/null values. numeric_only (bool, default False) - When set to True, include only numerical data types for the computation. **kwargs - Additional arguments passed to the function. Returns: Scalar value representing the kurtosis.",
    "class": "Series"
  },
  "pandas.Series.item": {
    "new_func": "singular_element_extractor",
    "description": "Extracts the sole element from the data structure and returns it as a Python scalar. If the series contains more than one element, a ValueError is raised. Returns: Scalar value representing the single element in the series. Raises: ValueError - If the series does not contain exactly one element.",
    "class": "Series"
  },
  "pandas.Series.last_valid_index": {
    "new_func": "final_nonmissing_index_locator",
    "description": "Finds the position of the last non-missing entry in the data structure. If all entries are missing, the result is None. Returns: Index type representing the position of the last non-NA entry, or None if no such entry exists.",
    "class": "Series"
  },
  "pandas.Series.le": {
    "new_func": "element_comparator_inferior_or_equal",
    "description": "Performs element-wise comparison between the series and another series or scalar, determining whether each element in the former is less than or equal to the corresponding element in the latter. Allows for substituting a specific value for missing data before the comparison. Parameters: other (Series or scalar) - The value to compare against. level (int or name, optional) - If provided, comparison will be broadcast across the specified MultiIndex level. fill_value (float, optional) - Value to replace missing data before computation. axis (int, default 0) - Axis along which to perform the comparison; unused for Series as it is one-dimensional. Returns: Series with the results of the comparison.",
    "class": "Series"
  },
  "pandas.Series.list.__getitem__": {
    "new_func": "sequence_element_accessor",
    "description": "Accesses elements from lists within the series using an index or slice. Parameters: key (int or slice) - The index or slice indicating which element(s) to access from each list. Returns: Series containing the accessed list elements.",
    "class": "Series"
  },
  "pandas.Series.list.flatten": {
    "new_func": "series_element_unravel",
    "description": "Extracts elements from nested containers within a data structure, producing a data structure with a single tier of elements. The contents from all containers are extracted and concatenated sequentially.\nReturns: A data structure with a similar index as the original but with flattened contents.",
    "class": "Series"
  },
  "pandas.Series.list.len": {
    "new_func": "series_container_quantify",
    "description": "Calculates the quantity of elements within each container in a data structure.\nReturns: A new data structure containing the counts corresponding to each original container's size.",
    "class": "Series"
  },
  "pandas.Series.map": {
    "new_func": "series_element_transform",
    "description": "Applies a specified transformation to each element in a data structure, which can be dictated by a function, a mapping object, or another data structure containing the transformations.\nParameters: transform_rule (function, mapping object, or data structure) - The rule defining the transformation of elements. na_option (string, optional) - Determines how to handle null values; if set to 'ignore', the nulls are maintained without transformation.\nReturns: A new data structure with the same index as the original, containing transformed elements.",
    "class": "Series"
  },
  "pandas.Series.lt": {
    "new_func": "series_elementwise_minor",
    "description": "Compares elements from two data structures, determining if the elements in the first are less than those in the second on an element-by-element basis. It also provides the option to fill in missing data points for the comparison.\nParameters: comparator (Series or scalar) - The second set of elements to compare against. level_name_or_int (int or string, optional) - Level for index alignment if working with a multi-level index. placeholder_value (float, optional) - Value to substitute for any missing data points pre-computation.\nReturns: A new data structure indicating the results of the comparison with a boolean value for each element.",
    "class": "Series"
  },
  "pandas.Series.last": {
    "new_func": "series_terminal_slice",
    "description": "Extracts a segment from a time-indexed data structure that includes the periods at the end within a specified timeframe. This operation is applicable to data structures with time-based indices.\nParameters: timeframe_span (string or date offset object) - The time span which defines how far back from the latest index the selection should extend.\nReturns: A portion of the original data structure containing data from the specified final periods. Note: Utilization of this function is discouraged in favor of more explicit filtering techniques.",
    "class": "Series"
  },
  "pandas.Series.radd": {
    "new_func": "right_hand_summation",
    "description": "Performs element-wise summation between an array and another array or scalar value, with the ability to fill in missing data on either input with a specified value prior to the calculation. This method is commutative, meaning the array and the 'other' can be summed in either order, but it is expressed in a way that the 'other' is conceptually the left operand. Parameters: other (array or scalar) - The array or value to be added to the calling array. level (int or string, optional) - Targets a specific level in a MultiIndex to match Index values for broadcasting. fill_value (float, optional) - Specifies a value to replace any missing data before the operation. axis (int or string, optional) - Compatibility parameter with no effect in this context. Returns: array - The sum of the input array and the 'other' value.",
    "class": "Series"
  },
  "pandas.Series.quantile": {
    "new_func": "percentile_value",
    "description": "Computes the value(s) at the specified percentile(s) of the array. Different interpolation techniques can be applied if the desired percentile lies between two data points. Parameters: q (float or array-like, default 0.5) - The percentile(s) to compute, valid values are within the interval [0, 1]. interpolation (string, optional) - The interpolation method to determine the percentile value between data points. Returns: numeric or array - A single value if q is a float, or an array of values with indices corresponding to the percentiles if q is array-like.",
    "class": "Series"
  },
  "pandas.Series.plot.pie": {
    "new_func": "circular_chart",
    "description": "Creates a circular statistical graphic, which is divided into slices to illustrate numerical proportion. This method is a wrapper for a popular plotting library's pie chart function, and it can be used to create a pie chart for the data in a single column or for each numerical column separately. Parameters: y (int or string, optional) - The label or position of the column whose data will be represented in the chart. If not supplied, the 'subplots' argument must be set to True. **kwargs (optional) - Additional keyword arguments to customize the plot. Returns: plot object or array of plot objects - A plot object if a single pie chart is created, or an array of plot objects if multiple charts are created due to 'subplots' being True.",
    "class": "Series"
  },
  "pandas.Series.rank": {
    "new_func": "ordinal_position",
    "description": "Assigns ranks to the elements in the array, with several strategies available for handling equal values. Ranks can be assigned in ascending or descending order and can be expressed as percentile ranks if desired. Parameters: axis (int or string, default 0) - Axis along which to rank, primarily for compatibility with other objects. method (string, default 'average') - The approach to apply when assigning ranks to tied values. numeric_only (bool, default False) - Applicable to DataFrame objects, where only numeric columns are considered if set to True. na_option (string, default 'keep') - Determines how NaN values are treated in the ranking. ascending (bool, default True) - Determines if the ranking should be performed in ascending order. pct (bool, default False) - Indicates whether the ranks should be returned as percentile ranks. Returns: array - An array of the same type as the caller, containing ranks as values.",
    "class": "Series"
  },
  "pandas.Series.ravel": {
    "new_func": "flatten_series",
    "description": "Returns a 1D array containing the elements of the original array. This method is marked as deprecated and to_numpy() should be used instead for its redundancy as the array is already 1D. Returns: array - The 1D array containing all elements of the original array.",
    "class": "Series"
  },
  "pandas.Series.repeat": {
    "new_func": "element_amplify",
    "description": "Produces a new sequence where each element is duplicated a specified number of times. The order of the original data is preserved.\nParameters: amplification_factor (int or array of ints) - The number of times each element should be duplicated. Must be non-negative.\nReturns: amplified_sequence - A new sequence with elements duplicated.",
    "class": "Series"
  },
  "pandas.Series.reorder_levels": {
    "new_func": "index_shuffle",
    "description": "Creates a new object with the hierarchy of the index rearranged according to the provided sequence. Neither level removal nor duplication is allowed during this operation.\nParameters: new_order (list of int) - A list defining the desired arrangement of index levels.\nReturns: reordered_object - An object with a rearranged index structure.",
    "class": "Series"
  },
  "pandas.Series.reset_index": {
    "new_func": "index_reinitialize",
    "description": "Returns a new object or modifies the existing one by resetting its index. This process is helpful to convert the index into a column or to get rid of an uninformative index.\nParameters: remove_levels (int, str, tuple, or list, optional) - Specifies which levels of a MultiIndex to remove.\nomit_index (bool, default False) - If set to True, the index is discarded and not added as a column.\ncolumn_name (object, optional) - The label for the column created from the index. Defaults to the object's name.\nalter_in_place (bool, default False) - If True, this method does the operation in place and does not return anything.\npermit_duplicates (bool, default False) - If True, allows creating columns with the same labels.\nReturns: reset_object - A new object with the index reset, or None if altered in place.",
    "class": "Series"
  },
  "pandas.Series.rfloordiv": {
    "new_func": "reciprocal_floor_divide",
    "description": "Computes the floor division of an external value by each element of the sequence, supporting a value to fill in any missing elements.\nParameters: divisor (Series or scalar) - The value to be divided by the sequence elements.\nbroadcast_level (int or name, optional) - The level of a MultiIndex to align with.\nsubstitute_value (None or float, optional) - A value to replace missing elements before the calculation.\nReturns: floored_result - A sequence of the floor division results.",
    "class": "Series"
  },
  "pandas.Series.rmod": {
    "new_func": "reciprocal_modulo",
    "description": "Calculates the modulo, or remainder, of an external value divided by each element of the sequence, while allowing for a fill value for missing data points.\nParameters: modulus_divisor (Series or scalar) - The value to be divided by elements of the sequence to find the remainder.\nalign_level (int or name, optional) - The level in a MultiIndex to match for alignment.\nfill_substitute (None or float, optional) - A value to replace any missing data before the operation.\nReturns: remainder_sequence - A sequence of the modulo results.",
    "class": "Series"
  },
  "pandas.Series.sort_values": {
    "new_func": "order_elements",
    "description": "Arranges the elements in a one-dimensional array based on their values, either in ascending or descending direction. The method offers the flexibility of choosing the sorting algorithm and the position of null values in the sorted array. It can also modify the original data structure or return a new one.\nParameters:\naxis (int or str): Unused parameter for compatibility purposes.\nascending (bool or list of bool): Determines the direction of the sort. Default is True for ascending order.\ninplace (bool): If set to True, the sorting is done in place, modifying the original data structure. Default is False.\nkind (str): The choice of sorting algorithm. Options are 'quicksort', 'mergesort', 'heapsort', or 'stable'. Default is 'quicksort'.\nna_position (str): Position of null values in the sorted array. Options are 'first' or 'last'.\nignore_index (bool): If True, the original index is ignored and a new integer index is used.\nkey (callable): Optional key function to customize sort order.\nReturns: A sorted array, unless inplace is set to True, in which case the operation is performed in place and returns None.",
    "class": "Series"
  },
  "pandas.Series.sparse.fill_value": {
    "new_func": "sparse_default",
    "description": "Represents the most common element within a data structure that utilizes memory-efficient storage techniques for homogenous data. These elements are not explicitly stored, allowing for optimization of space.\nReturns: Scalar value - The common element that is implicitly represented within the sparse data structure.",
    "class": "Series"
  },
  "pandas.Series.sparse.from_coo": {
    "new_func": "construct_sparse_series",
    "description": "Generates a one-dimensional array with memory-efficient storage from a two-dimensional sparse matrix. The resulting array contains data points that are non-zero in the matrix and can be indexed either by the coordinates of these data points or by a complete index that includes zero-valued positions.\nParameters:\nA (scipy.sparse.coo_matrix): A sparse matrix in COOrdinate format.\ndense_index (bool): Determines whether to use a full index that includes zero-valued entries or a concise index of non-zero entries only. Default is False.\nReturns: A one-dimensional array with sparse storage representing non-zero entries of the input matrix.",
    "class": "Series"
  },
  "pandas.Series.squeeze": {
    "new_func": "contract_dimensionality",
    "description": "Transforms higher-dimensional structures with only one element along a certain axis into lower-dimensional representations. This method is particularly effective when the exact dimensionality of the object is unknown but it is certain that it contains only a single column of data. One-dimensional objects can be reduced to scalar values, and matrices can be reduced to one-dimensional arrays if they contain only a single row or column.\nParameters:\naxis (int, str, or None): Indicates a specific axis to target or None to squeeze all length-1 dimensions. Default is None.\nReturns: The lower-dimensional representation of the input object after reduction, which can be a matrix, a one-dimensional array, or a scalar.",
    "class": "Series"
  },
  "pandas.Series.sparse.npoints": {
    "new_func": "count_nondefault",
    "description": "Calculates the quantity of explicitly stored data points in a memory-efficient array, excluding the elements that are represented by a common default value to save space.\nReturns: Integer - The total number of stored elements that are different from the default value.",
    "class": "Series"
  },
  "pandas.Series.sparse.to_coo": {
    "new_func": "multiindex_sparse_matrix",
    "description": "Transforms a multi-level indexed data structure into a sparse matrix in coordinate format. Select specific levels for the matrix rows and columns using the provided parameters. The labels can be sorted if required for faster creation of the matrix. The sparse matrix is returned alongside the row and column labels.\nParameters:\n- row_levels (tuple/list): Identifiers for the index levels to use as rows.\n- column_levels (tuple/list): Identifiers for the index levels to use as columns.\n- sort_labels (bool, default False): Whether to sort the labels for quicker creation.\nReturns:\n- matrix (scipy.sparse.coo_matrix): The constructed sparse matrix.\n- rows (list): Row labels.\n- columns (list): Column labels.",
    "class": "Series"
  },
  "pandas.Series.std": {
    "new_func": "sample_variance_measure",
    "description": "Computes the dispersion measurement for numerical data within the series, based on a corrected sample. Adjust the degree of freedom difference to alter the divisor in the calculation.\nParameters:\n- axis (None): Intended for compatibility, has no effect.\n- skipna (bool, default True): Exclude missing values from the calculation.\n- ddof (int, default 1): The adjustment to the number of data points (N) in the divisor (N - ddof).\n- numeric_only (bool, default False): Applicable only for DataFrame, ignored for Series.\nReturns:\n- result (scalar or Series): The computed value.",
    "class": "Series"
  },
  "pandas.Series.str.casefold": {
    "new_func": "text_normalize_casefold",
    "description": "Applies a transformation on textual elements to achieve uniform casing, suitable for case-insensitive comparisons. This method is more aggressive than lowercasing and can be used to simplify string matching.\nReturns:\n- transformed (Series or Index): The series or index with transformed text.",
    "class": "Series"
  },
  "pandas.Series.str.capitalize": {
    "new_func": "text_initial_upper",
    "description": "Modifies textual elements to have their initial character in uppercase and the remaining characters in lowercase, typically used for formatting purposes.\nReturns:\n- transformed (Series or Index): The series or index with modified text.",
    "class": "Series"
  },
  "pandas.Series.str.endswith": {
    "new_func": "string_terminates_with_pattern",
    "description": "Determines if the tail segment of each textual element in a series coincides with a specified character sequence. It compares the terminal characters of each element to verify if they match a provided character sequence or any element within a tuple of character sequences. When an element is not textual, a predefined object is returned.\nParameters:\n- sequence (str or tuple of str): The character sequence or a tuple of character sequences for comparison.\n- null_obj (object, default NaN): The value returned when an element is not textual. The default is dependent on the data type of the series.\nReturns:\n- Series or Index of bool: A series or index with boolean values indicating the presence of the specified terminal character sequence in each element.",
    "class": "Series"
  },
  "pandas.Series.str.extract": {
    "new_func": "regex_group_capture",
    "description": "Retrieves subgroups from each element in a series that match a specified regular expression into a data structure. It extracts segments from each string based on the first occurrence that matches the expression.\nParameters:\n- expression (str): A regular expression with groups to capture.\n- mod_flags (int, default 0): Flags from the regular expression module to modify pattern matching.\n- separate_columns (bool, default True): Determines the format of the return; multiple columns for each capture group if True, or a single series/index if False with only one group.\nReturns:\n- DataFrame or Series or Index: A structure housing one row for each element and columns representing each regex capture group. Column names are derived from the capture group names within the expression, or numerically if unnamed. The data type for each column is always object, irrespective of match presence.",
    "class": "Series"
  },
  "pandas.Series.str.contains": {
    "new_func": "pattern_presence_check",
    "description": "Evaluates the presence of a specified sequence or regular expression within each textual element. A boolean series or index is returned denoting the existence of the pattern in each element.\nParameters:\n- sequence (str): The character sequence or regular expression to locate.\n- sensitive (bool, default True): If True, the search is case sensitive.\n- mod_flags (int, default 0): Regular expression module flags to modify the search.\n- null_value (scalar, optional): The fill value for missing values, which varies based on the data type of the series.\n- use_regex (bool, default True): Treats the sequence as a regular expression if True, or as a literal string if False.\nReturns:\n- Series or Index of boolean: A series or index with boolean values representing the existence of the specified pattern within each string element.",
    "class": "Series"
  },
  "pandas.Series.str.findall": {
    "new_func": "pattern_occurrences_discovery",
    "description": "Locates all non-overlapping instances of a specified pattern or regular expression within each textual element. It is analogous to applying the regular expression 'findall' method to all elements.\nParameters:\n- expression (str): The pattern or regular expression to search for.\n- mod_flags (int, default 0): Flags from the regular expression module that affect the pattern search.\nReturns:\n- Series/Index of lists of strings: A series or index where each element is a list of strings containing all found instances of the pattern.",
    "class": "Series"
  },
  "pandas.Series.str.extractall": {
    "new_func": "regex_group_capture_all_matches",
    "description": "Gathers all subgroup matches of a regular expression from each textual element into a data frame. Each match across the elements results in a separate entry, with columns corresponding to the capture groups.\nParameters:\n- expression (str): The regular expression with groups to be extracted.\n- mod_flags (int, default 0): Flags from the regular expression module that can alter pattern matching behavior.\nReturns:\n- DataFrame: A data frame with a multi-level index, where each row corresponds to a match and columns represent the capture groups. The outer levels of the index originate from the series, with an additional 'match' level indexing the matches per element. Column names are based on the capture group names or numbers from the expression.",
    "class": "Series"
  },
  "pandas.Series.str.cat": {
    "new_func": "string_series_element_join",
    "description": "Merges text elements in a sequence or between multiple sequences with an optional delimiter. For a single sequence, it combines elements into a single text. When multiple sequences are provided, it merges them element-wise. An optional string can replace null entries. The merge can be performed with different join styles based on the provided argument.\nParameters:\n- others (optional): A sequence, two-dimensional array-like, or similar iterable of text must have the same length as the primary sequence unless join is specified.\n- sep (optional, str): Delimiter to separate text elements. Defaults to an empty delimiter.\n- na_rep (optional, str or None): Placeholder for null entries. Behavior varies based on the presence and type of 'others'.\n- join (optional, str): Specifies the join style between the primary sequence and any additional sequences. Accepts 'left', 'right', 'outer', 'inner'. To avoid alignment, apply .values on any additional sequences.\nReturns:\n- A single string if 'others' is not provided; otherwise, a sequence or index of merged text items.",
    "class": "Series"
  },
  "pandas.Series.str.find": {
    "new_func": "text_series_substring_search",
    "description": "Identifies the lowest index at which a substring appears within each text item in a sequence. The search is bound between specified start and end indexes, returning -1 if the substring is not found. This function mirrors the behavior of the standard text search method for finding substrings.\nParameters:\n- sub (str): The substring to locate.\n- start (int): The starting index for the search.\n- end (optional, int): The ending index for the search.\nReturns:\n- A sequence or index of integers indicating the position of the substring within each text item.",
    "class": "Series"
  },
  "pandas.Series.str.get": {
    "new_func": "sequence_element_retrieval",
    "description": "Obtains a specific element or character from each item in a sequence based on a given position or key. Items can be lists, tuples, dictionaries, or text.\nParameters:\n- i (int or hashable): The index position or dictionary key to extract elements from each item.\nReturns:\n- A sequence or index of the extracted elements.",
    "class": "Series"
  },
  "pandas.Series.str.fullmatch": {
    "new_func": "text_series_regex_whole_match",
    "description": "Checks whether each item in a sequence completely conforms to a specified regular expression pattern. It allows for case sensitivity and additional regular expression flags. An optional value can be specified to handle missing values.\nParameters:\n- pat (str): The regular expression pattern to match against each text item.\n- case (bool, default True): Indicates if the matching is case sensitive.\n- flags (int, default 0): Regular expression flags, such as re.IGNORECASE.\n- na (optional, scalar): Value to use for missing items, depending on the data type.\nReturns:\n- A sequence or index of boolean values indicating match success for each text item.",
    "class": "Series"
  },
  "pandas.Series.str.index": {
    "new_func": "text_series_substring_position",
    "description": "Determines the lowest index at which a specified substring appears within each text element of a sequence. The search is performed between the provided start and end indexes. Unlike a similar search method, this function raises an error when the substring is not found.\nParameters:\n- sub (str): The substring to locate.\n- start (int): The starting index for the search.\n- end (optional, int): The ending index for the search.\nReturns:\n- A sequence or index of integers indicating the position of the substring within each text element.",
    "class": "Series"
  },
  "pandas.Series.str.get_dummies": {
    "new_func": "categorical_expansion",
    "description": "Transforms a collection of categorical text data into a table with binary columns, each representing the presence of a category based on the split criterion. The split character is customizable, and the resulting table facilitates the use of categorical data in statistical analysis or machine learning algorithms.\\nParameters: separator (string, default '|') - The delimiter used to split the text data within each element.\\nReturns: BinaryMatrix - A new table with binary columns corresponding to the split text categories.",
    "class": "Series"
  },
  "pandas.Series.str.isalnum": {
    "new_func": "alpha_numeric_verifier",
    "description": "Evaluates each element in a series to determine if the content consists solely of alphanumeric characters. It applies a character-type check similar to a certain built-in Python string method, delivering a boolean outcome for each element.\\nReturns: BooleanSeries - A series of boolean flags indicating the alphanumeric status of each element, with the same count as the input series.",
    "class": "Series"
  },
  "pandas.Series.str.isalpha": {
    "new_func": "alphabetical_checker",
    "description": "Assesses each entry in a series to confirm if all characters within are from the alphabet. It performs a character composition check akin to a certain Python string method, providing a true or false value for each entry.\\nReturns: TruthSeries - A series of truth values indicating the alphabetic nature of each entry, with identical length to the input.",
    "class": "Series"
  },
  "pandas.Series.str.istitle": {
    "new_func": "titlecase_validator",
    "description": "Inspects each sequence of characters in a series to verify if they adhere to titlecase formatting. It employs a check comparable to a particular Python string method, giving a boolean verdict for each sequence.\\nReturns: TitlecaseSeries - A series of booleans indicating whether each sequence is in titlecase format, maintaining the original series size.",
    "class": "Series"
  },
  "pandas.Series.str.islower": {
    "new_func": "lowercase_confirmation",
    "description": "Performs a verification on each string element within a series to ascertain if all characters are in lowercase format. It mimics the behavior of a certain Python string method to generate a boolean result for each element.\\nReturns: LowercaseSeries - A series of booleans representing the lowercase status of each string, with an equivalent count to that of the original series.",
    "class": "Series"
  },
  "pandas.Series.str.lstrip": {
    "new_func": "series_trim_start",
    "description": "Eliminates specified leading characters from each element in the series or index. It defaults to removing leading spaces if no character set is provided. This operation treats non-character data as missing values.\nParameters: to_strip (str or None, optional) - The characters to eliminate from the beginning of each string. If not specified, leading spaces are removed.\nReturns: Series or Index containing trimmed elements.",
    "class": "Series"
  },
  "pandas.Series.str.normalize": {
    "new_func": "standardize_unicode_format",
    "description": "Converts the string elements of the series or index to a standard unicode representation, based on the specified unicode form.\nParameters: form ({'NFC', 'NFKC', 'NFD', 'NFKD'}) - The unicode form to apply for normalization.\nReturns: Series or Index with the normalized unicode format of the strings.",
    "class": "Series"
  },
  "pandas.Series.str.pad": {
    "new_func": "series_enlarge_boundaries",
    "description": "Augments the length of string elements in the series or index to a specified minimum width by adding a specified character, either at the beginning, end, or both sides of the strings.\nParameters: width (int) - The minimum length for the resulting string. fillchar (str, default ' ') - The character used for augmentation. side ({'left', 'right', 'both'}, default 'left') - The side from which to append the fill character.\nReturns: Series or Index with adjusted string lengths.",
    "class": "Series"
  },
  "pandas.Series.str.partition": {
    "new_func": "series_split_once",
    "description": "Divides each string in the series or index into three parts based on the first occurrence of a specified delimiter: the segment before the delimiter, the delimiter itself, and the remaining segment. If the delimiter is not found, the entire string and two empty strings are returned.\nParameters: sep (str, default ' ') - The delimiter to split on. expand (bool, default True) - Determines whether to return a DataFrame/MultiIndex or a Series/Index.\nReturns: DataFrame/MultiIndex or Series/Index with the split components.",
    "class": "Series"
  },
  "pandas.Series.str.removesuffix": {
    "new_func": "series_delete_ending",
    "description": "Excludes a specified ending from the string elements within the series or index. If the ending is not found, the original elements are retained.\nParameters: suffix (str) - The ending to be eliminated from the string elements.\nReturns: Series or Index with the specified endings removed.",
    "class": "Series"
  },
  "pandas.Series.str.slice": {
    "new_func": "substring_extract",
    "description": "Retrieves a portion of the text from each element in a collection based on specified starting and ending positions. Custom strides can be applied to select characters at regular intervals. The output retains the original data structure with modified content.\nParameters: start (int, optional) - Initial index for extraction. stop (int, optional) - Final index for extraction. step (int, optional) - Interval for selecting elements.\nReturns: Modified collection with extracted text segments.",
    "class": "Series"
  },
  "pandas.Series.str.split": {
    "new_func": "divide_text",
    "description": "Separates string elements in a collection based on a given pattern or delimiter, with a limit on the number of divisions to perform. The result can be expanded into multiple columns or retained within a single column as lists.\nParameters: pattern (str or compiled regex, optional) - The criteria used for division. If omitted, defaults to whitespace. n (int, default -1) - Maximum number of separations to apply. expand (bool, default False) - Determines output format, either as multi-column or single column with lists. regex (bool, default None) - Indicates whether the pattern should be interpreted as a regular expression.\nReturns: Collection with separated strings, structure depends on 'expand' flag.",
    "class": "Series"
  },
  "pandas.Series.str.strip": {
    "new_func": "trim_characters",
    "description": "Eliminates specified characters from both ends of each text entry within a collection. The operation defaults to removing whitespace but can be customized to target particular characters.\nParameters: characters_to_remove (str or None, default None) - Characters designated for elimination.\nReturns: Collection with leading and trailing characters removed from each text entry.",
    "class": "Series"
  },
  "pandas.Series.str.slice_replace": {
    "new_func": "segment_substitute",
    "description": "Alters a specified segment within each text entry of a collection by replacing it with a different text value. The replaced segment is determined by its start and end indices. If no replacement text is provided, the segment is removed.\nParameters: start (int, optional) - Initial index of the segment. stop (int, optional) - Final index of the segment. replacement (str, optional) - Text to insert in place of the selected segment.\nReturns: Collection with the specified segments replaced.",
    "class": "Series"
  },
  "pandas.Series.str.upper": {
    "new_func": "capitalize_text",
    "description": "Transforms all the textual elements in a collection to their uppercase form.\nReturns: Collection with all text entries converted to uppercase.",
    "class": "Series"
  },
  "pandas.Series.str.title": {
    "new_func": "capitalize_headings",
    "description": "Transforms each element in the sequence to have the initial character capitalized and the rest in lowercase, adhering to standard capitalization rules for titles. This routine is useful for formatting text data consistently with title case conventions.\nReturns: A sequence with the same index structure containing the transformed text elements.",
    "class": "Series"
  },
  "pandas.Series.struct.dtypes": {
    "new_func": "child_field_types",
    "description": "Acquires the data type descriptor for each subordinate field within a complex data structure. It is useful for examining the specific types that constitute a nested data element.\nReturns: A sequence with data type descriptors for each subordinate field.",
    "class": "Series"
  },
  "pandas.Series.str.zfill": {
    "new_func": "prepend_zeros",
    "description": "Augments each element within the sequence by attaching '0' digits to the beginning until a specified total length is achieved. Elements that already meet or exceed the desired length remain unaltered. This is particularly useful for standardizing numerical string representations.\nParameters: length (int) - The minimum desired length of the output strings. Elements shorter than this length will receive leading zeros.\nReturns: A sequence with the modified text elements.",
    "class": "Series"
  },
  "pandas.Series.str.translate": {
    "new_func": "remap_characters",
    "description": "Alters each element in the sequence by applying a specified remapping to its characters. This process can include character substitution, deletion, or retention based on the provided mapping. It is a powerful tool for text normalization and cleaning.\nParameters: mapping (dict) - A dictionary defining the character transformation, where keys are Unicode code points of the characters to be replaced, and values are the corresponding replacements. Characters to be deleted should be mapped to None.\nReturns: A sequence with the transformed text elements.",
    "class": "Series"
  },
  "pandas.Series.str.swapcase": {
    "new_func": "toggle_text_case",
    "description": "Modifies each element in the sequence by inverting the case of all alphabetical characters. Upper-case characters become lower-case and vice versa. This method is useful for normalizing case variations within text data.\nReturns: A sequence with the case-toggled text elements.",
    "class": "Series"
  },
  "pandas.Series.sub": {
    "new_func": "elemental_difference",
    "description": "Calculates the element-wise subtraction between a data container and another array-like entity, supporting an additional option to replace missing values with a specified number. The calculation proceeds with the substitution of missing entries, ensuring proper alignment during the operation.\nParameters:\nother: Array-like or scalar value - The second operand in the subtraction.\nlevel: Integer or string - Targets a specific level in a MultiIndex to align with the index of the data container.\nfill_value: None or float value, default None - Replaces missing values with this specified number before the calculation.\naxis: {0 or 'index'} - For compatibility with data structures, though unused in this context.\nReturns:\nA data container - The outcome of the subtraction.",
    "class": "Series"
  },
  "pandas.Series.struct.field": {
    "new_func": "substructure_accessor",
    "description": "Retrieves a specified sub-element from a compound data structure within a data series.\nParameters:\nname_or_index: String, bytes, integer, expression, or list - Identifier for the sub-element to retrieve, which may be nested within a more complex structure.\nReturns:\nA data series - The sub-elements extracted as a separate data series.",
    "class": "Series"
  },
  "pandas.Series.str.wrap": {
    "new_func": "text_reflow",
    "description": "Adjusts the character string length within a series by setting a maximum line width, employing similar parameters to a standard text wrapping utility.\nParameters:\nwidth: Integer - The maximum number of characters permitted on a line.\nexpand_tabs: Boolean, optional - Dictates whether tab characters expand to spaces (default: True).\nreplace_whitespace: Boolean, optional - Determines if whitespace characters are replaced with single spaces after tab expansion (default: True).\ndrop_whitespace: Boolean, optional - Decides if leading or trailing whitespace is removed after wrapping (default: True).\nbreak_long_words: Boolean, optional - If set to true, long words are split to adhere to the line width limit; otherwise, they remain intact, potentially exceeding the width (default: True).\nbreak_on_hyphens: Boolean, optional - Allows line breaks at hyphens in compound words if true; otherwise, line breaks occur only at whitespace (default: True).\nReturns:\nA series or index - The reformatted textual data respecting the specified wrapping rules.",
    "class": "Series"
  },
  "pandas.Series.struct.explode": {
    "new_func": "decompose_structure",
    "description": "Transforms a complex nested data series into a tabular representation, with each sub-element occupying a distinct column.\nReturns:\nA tabular data structure - Contains individual columns representing each sub-element of the original nested data series.",
    "class": "Series"
  },
  "pandas.Series.tail": {
    "new_func": "final_elements",
    "description": "Retrieves a specified number of concluding entries from a data sequence, typically for quick examination after modifications such as sorting or adding entries.\nParameters:\nn: Integer, default 5 - The count of final entries to obtain from the sequence. If negative, all entries except the first 'n' are returned.\nReturns:\nThe same type as the invoking sequence - A subset consisting of the concluding entries from the original data sequence.",
    "class": "Series"
  },
  "pandas.Series.truediv": {
    "new_func": "element_wise_divider",
    "description": "Executes element-wise division between the data structure and another, either a scalar or similar structure, allowing for an optional fill value to replace missing data.\nParameters:\nother (Series or scalar value) - The divisor.\nlevel (int or name) - To broadcast across a level, matching Index values on the given MultiIndex level.\nfill_value (None or float, default None) - Specifies a value to fill missing entries before computation.\naxis ({0 or 'index'}) - Axis parameter for compatibility; unused in Series.\nReturns:\nSeries - The result of dividing the original data structure by the 'other' value, element-wise.",
    "class": "Series"
  },
  "pandas.Series.to_xarray": {
    "new_func": "convert_to_xarray",
    "description": "Transforms the data structure into an xarray object. If the input is a single-dimensional data structure, it becomes an DataArray; for multi-dimensional structures, it converts to a Dataset.\nReturns:\nxarray.DataArray or xarray.Dataset - The xarray representation of the input data.",
    "class": "Series"
  },
  "pandas.Series.tz_convert": {
    "new_func": "change_timezone",
    "description": "Alters the time zone of a time-aware data structure to a specified target time zone.\nParameters:\ntz (str or tzinfo object or None) - The desired time zone to convert to, or None to switch to UTC and remove time zone information.\naxis ({0 or 'index', 1 or 'columns'}, default 0) - The axis representing time to be converted.\nlevel (int, str, default None) - Specifies a level in case of a MultiIndex.\ncopy (bool, default True) - Whether to also create a copy of the data.\nReturns:\nSeries/DataFrame - The data structure with its time zone adjusted.\nRaises:\nTypeError - If attempting to change a time-naive axis.",
    "class": "Series"
  },
  "pandas.Series.tz_localize": {
    "new_func": "assign_timezone",
    "description": "Assigns a time zone to a time-naive data structure, effectively converting it into a time-aware one.\nParameters:\ntz (str or tzinfo or None) - The time zone to assign or None to remove time zone information while keeping local time.\naxis ({0 or 'index', 1 or 'columns'}, default 0) - The axis to apply the time zone.\nlevel (int, str, default None) - A level in case of a MultiIndex to localize.\ncopy (bool, default True) - Whether to also create a copy of the data.\nambiguous ('infer', bool-array, 'NaT', default 'raise') - How to handle ambiguous times due to daylight saving transitions.\nnonexistent (str, default 'raise') - How to handle times that do not exist in the time zone due to daylight saving transitions.\nReturns:\nSeries/DataFrame - The data structure with the time zone applied.\nRaises:\nTypeError - If attempting to localize a time-aware data structure.",
    "class": "Series"
  },
  "pandas.StringDtype": {
    "new_func": "TextualDataType",
    "description": "Introduces a data type for handling textual content. It is an experimental feature that may undergo changes. Users can specify the memory representation strategy for string data, with available options including Python's native method or leveraging the Apache Arrow library. The default behavior relies on the global configuration setting for string data representation.\\nParameters:\\nstorage (str, optional) - Defines the strategy for storing string data, with choices being 'python', 'pyarrow', or 'pyarrow_numpy'. If omitted, defaults to the configured global string storage setting.",
    "class": "StringDtype"
  },
  "pandas.Timedelta.asm8": {
    "new_func": "TimeSpanToArrayScalar",
    "description": "Transforms a duration object into an array scalar conforming to the numpy timedelta64 format. The output provides a 64-bit integer encapsulation of the duration in nanosecond units, compatible with Python integers.\\nReturns:\\narray scalar (numpy.timedelta64) - An array scalar view of the duration in nanosecond units.",
    "class": "Timedelta"
  },
  "pandas.Timedelta.as_unit": {
    "new_func": "DurationInUnits",
    "description": "Translates the internal 64-bit integer representation of a duration object to a specified temporal unit. If rounding is not permitted and the conversion is inexact, an exception is raised.\\nParameters:\\nunit (str) - The temporal unit to which the duration should be converted, with permissible values including 'ns', 'us', 'ms', and 's'.\\nround_ok (bool, default True) - If set to False, inexact conversions that require rounding will result in an error.\\nReturns:\\nTimeSpan - The duration represented in the specified unit.",
    "class": "Timedelta"
  },
  "pandas.Timedelta": {
    "new_func": "DurationSpan",
    "description": "Encapsulates a span of time, representing the difference between two points in time. This class is similar to Python's standard `datetime.timedelta` and can often be used interchangeably.\\nParameters:\\nvalue (timedelta, np.timedelta64, str, int) - The magnitude of the duration span, which can be specified in various formats including standard timedelta objects, string representations, or integers.\\nunit (str, optional) - Specifies the unit associated with the integer value, defaults to 'nanoseconds'. Acceptable units range from weeks to nanoseconds.\\n**kwargs - Additional keyword arguments that are compatible with `datetime.timedelta`, such as days, seconds, and weeks, for constructing the duration.\\nReturns:\\nDurationSpan - The created duration span object.",
    "class": "Timedelta"
  },
  "pandas.Timedelta.days": {
    "new_func": "TotalDays",
    "description": "Retrieves the total number of whole days encapsulated within the duration span.\\nReturns:\\nint - The count of whole days.",
    "class": "Timedelta"
  },
  "pandas.Timedelta.value": {
    "new_func": "duration_raw_quantity",
    "description": "Retrieves the total count of nanoseconds represented by the duration object. The returned value is an integer representing the nanoseconds count.",
    "class": "Timedelta"
  },
  "pandas.Timedelta.to_timedelta64": {
    "new_func": "to_nano_duration",
    "description": "Converts the duration object to a 64-bit time duration with nanosecond precision. The conversion yields a standard duration type commonly used in scientific computing.",
    "class": "Timedelta"
  },
  "pandas.TimedeltaIndex": {
    "new_func": "DurationSequence",
    "description": "Represents an immutable array of time durations, with internal representation as 64-bit integers. The array scalars are returned as duration objects. Accepts a variety of input types that can be converted into durations, with an optional unit specifier. Parameters: - data: Optional array-like sequence of time duration data. - unit: The time unit for each element in the data (deprecated, use alternative duration conversion methods). - freq: The frequency string or offset object that specifies the intervals between data points. The special string 'infer' automatically infers the frequency. - dtype: The data type of the array elements, defaulting to nanosecond-based duration. - copy: Boolean indicating whether to copy the input data. - name: An identifier for the array.",
    "class": "TimedeltaIndex"
  },
  "pandas.Timedelta.view": {
    "new_func": "duration_cast",
    "description": "Provides a new view of the duration's underlying data, interpreted according to the specified data type. This method does not change the actual data but presents it in a different format. Parameters: - dtype: The desired data type or string specifying how to interpret the data.",
    "class": "Timedelta"
  },
  "pandas.TimedeltaIndex.as_unit": {
    "new_func": "rescale_duration",
    "description": "Transforms the duration array to a specified time unit resolution while maintaining the same array type. This operation is useful for standardizing duration values to a common scale. Parameters: - unit: The target time unit for rescaling ('s' for seconds, 'ms' for milliseconds, 'us' for microseconds, 'ns' for nanoseconds). Returns: An array of the same type with the duration values converted to the specified unit.",
    "class": "TimedeltaIndex"
  },
  "pandas.TimedeltaIndex.round": {
    "new_func": "temporal_intervals_adjust",
    "description": "Adjusts the intervals to a specified regularity by applying a rounding operation, aligning them to the nearest increment of the stated frequency. Only fixed intervals such as seconds can be utilized for this adjustment. The function also provides options to handle special cases where the exact time might be ambiguous or non-existent due to daylight saving shifts.\nParameters:\n- freq: A string or offset representing the frequency level to which the intervals should be rounded.\n- ambiguous: Options to handle daylight saving time transitions ('infer', boolean array, 'NaT', 'raise').\n- nonexistent: Options to handle times that do not exist in certain timezones when clocks are adjusted ('shift_forward', 'shift_backward', 'NaT', timedelta, 'raise').\nReturns:\nAn index of the same type, adjusted to the nearest frequency increment.",
    "class": "TimedeltaIndex"
  },
  "pandas.TimedeltaIndex.days": {
    "new_func": "interval_day_counts",
    "description": "Retrieves the count of whole days present within each interval.\nReturns:\nAn array-like object containing integer day counts for each interval element.",
    "class": "TimedeltaIndex"
  },
  "pandas.TimedeltaIndex.mean": {
    "new_func": "average_interval_duration",
    "description": "Calculates the central duration value of all intervals, effectively providing a measure of the average interval length while optionally excluding any not-a-time elements.\nParameters:\n- skipna: A boolean indicating whether to bypass any not-a-time elements in the calculation.\n- axis: An integer specifying the axis along which to compute the average.\nReturns:\nA scalar value representing the average interval duration.",
    "class": "TimedeltaIndex"
  },
  "pandas.TimedeltaIndex.seconds": {
    "new_func": "interval_second_elements",
    "description": "Retrieves the total count of seconds encapsulated in each interval, with the value being greater than or equal to zero and less than the number of seconds in one day.\nReturns:\nAn array-like object containing integer second counts for each interval element.",
    "class": "TimedeltaIndex"
  },
  "pandas.TimedeltaIndex.to_frame": {
    "new_func": "interval_to_datatable",
    "description": "Constructs a tabulated structure with a column representing the interval data. The resulting structure can optionally preserve the original index and assign a specified label to the column.\nParameters:\n- index: A boolean indicating if the original index should be retained.\n- name: An optional parameter to label the column, substituting the index's name if available.\nReturns:\nA tabular structure containing the interval data, with the option to maintain the original index.",
    "class": "TimedeltaIndex"
  },
  "pandas.Timestamp.day": {
    "new_func": "solar_cycle_period",
    "description": "Extracts the cardinal date within the current month from a datetime instance. Output is a number representing the position of the day in the corresponding month. Parameters: None. Returns: int - The day of the month.",
    "class": "Timestamp"
  },
  "pandas.Timestamp.combine": {
    "new_func": "merge_date_time",
    "description": "Joins a date object with a time object to produce a new datetime instance reflecting the specified date and time. Parameters: date (date object) - The date part to be combined; time (time object) - The time part to be combined. Returns: datetime - The combined datetime instance.",
    "class": "Timestamp"
  },
  "pandas.Timestamp.day_of_year": {
    "new_func": "annual_ordinal_day",
    "description": "Calculates the position of a date within a given year, expressed as the number of days elapsed since the beginning of the year. Parameters: None. Returns: int - The one-based index representing the day's position in the year.",
    "class": "Timestamp"
  },
  "pandas.Timestamp.dayofweek": {
    "new_func": "timestamp_weekday_index",
    "description": "Determines the index of the week for a given date, where Monday is denoted as 0 and Sunday as 6. Parameters: None. Returns: int - The zero-based index of the weekday.",
    "class": "Timestamp"
  },
  "pandas.Timestamp.day_of_week": {
    "new_func": "weekly_ordinal",
    "description": "Provides the index value corresponding to the day of the week, with a range from 0 (Monday) to 6 (Sunday). Parameters: None. Returns: int - The ordinal number representing the weekday.",
    "class": "Timestamp"
  },
  "pandas.Timestamp.floor": {
    "new_func": "timestamp_round_down",
    "description": "Adjusts the specified moment in time downwards to the nearest increment defined by the given frequency parameter. The rounding respects daylight saving time considerations and handles non-existent times appropriately based on the specified strategy.\nParameters: \n- resolution (str): A string denoting the temporal granularity to round down to.\n- dst_ambiguity_resolver (bool or {'raise', 'NaT'}): Strategy to resolve moments that occur during the end of daylight saving time. A boolean indicates whether the time is considered daylight saving time. 'NaT' results in a NaT (missing value) for ambiguous times, while 'raise' will cause an error.\n- nonexistent_time_strategy ({'raise', 'shift_forward', 'shift_backward', 'NaT', timedelta}): Specifies how to handle times that do not exist due to daylight saving time changes. Options include moving the time forward or backward to the nearest valid moment, returning a NaT (missing value), or shifting by a specified timedelta. The 'raise' option triggers an error for nonexistent times.\nReturns: \n- A new, adjusted moment in time object.",
    "class": "Timestamp"
  },
  "pandas.Timestamp.fromordinal": {
    "new_func": "timestamp_from_ordinal",
    "description": "Generates a new time-stamp based on a given proleptic Gregorian ordinal number, with an optional time zone specification.\nParameters:\n- day_number (int): The proleptic Gregorian ordinal, representing the number of days since January 1 of year 1.\n- timezone (str, timezone object, or None): The time zone to associate with the resulting time-stamp.\nReturns: \n- A time-stamp corresponding to the provided ordinal number.",
    "class": "Timestamp"
  },
  "pandas.Timestamp.is_month_end": {
    "new_func": "timestamp_terminal_day_check",
    "description": "Evaluates whether the object's date coincides with the final calendar day of its respective month.\nReturns:\n- A boolean value: True if it is the terminal day of the month, False otherwise.",
    "class": "Timestamp"
  },
  "pandas.Timestamp.is_leap_year": {
    "new_func": "timestamp_bissextile_year_check",
    "description": "Determines if the year of the current instance qualifies as a bissextile year, commonly known as a leap year.\nReturns:\n- A boolean value signaling whether the year is a leap year.",
    "class": "Timestamp"
  },
  "pandas.Timestamp.hour": {
    "new_func": "timestamp_get_hour",
    "description": "Retrieves the hour component of the time instance, ranging from 0 to 23.\nReturns:\n- An integer representing the hour.",
    "class": "Timestamp"
  },
  "pandas.Timestamp.fromtimestamp": {
    "new_func": "moment_from_epoch",
    "description": "Converts an epoch time value to a localized datetime object based on a specified timezone or the local timezone if none is provided. The epoch time value represents the number of seconds since January 1, 1970 (UTC).\\nParameters: ts (float) - The epoch time value.\\ntz (tzinfo, optional) - The timezone information.\\nReturns: datetime - A datetime object representing the localized date and time.",
    "class": "Timestamp"
  },
  "pandas.Timestamp.fold": {
    "new_func": "daylight_saving_adjustment",
    "description": "Indicates the daylight saving time adjustment status of the datetime object. This attribute can have a value of either 0 or 1, which is used to differentiate between two identical wall times during a daylight saving time transition.\\nReturns: int - The daylight saving time adjustment indicator (0 or 1).",
    "class": "Timestamp"
  },
  "pandas.Timestamp.is_month_start": {
    "new_func": "initiation_of_month",
    "description": "Determines whether the specified date corresponds to the initial day of a month.\\nReturns: boolean - True if it's the initial day of the month, False otherwise.",
    "class": "Timestamp"
  },
  "pandas.Timestamp.is_quarter_start": {
    "new_func": "commencement_of_quarter",
    "description": "Evaluates if the provided date marks the start of a financial quarter.\\nReturns: boolean - True if it's the start of a quarter, False otherwise.",
    "class": "Timestamp"
  },
  "pandas.Timestamp.is_quarter_end": {
    "new_func": "termination_of_quarter",
    "description": "Assesses if the given date signifies the conclusion of a financial quarter.\\nReturns: boolean - True if it's the conclusion of a quarter, False otherwise.",
    "class": "Timestamp"
  },
  "pandas.Timestamp.time": {
    "new_func": "extract_plain_time",
    "description": "Retrieves the time component of a datetime object as a standard time object, disregarding any timezone information.",
    "class": "Timestamp"
  },
  "pandas.Timestamp.tz": {
    "new_func": "timezone_accessor",
    "description": "Provides access to the timezone information associated with the datetime object.",
    "class": "Timestamp"
  },
  "pandas.Timestamp.toordinal": {
    "new_func": "gregorian_days",
    "description": "Calculates the number of days since day 1 of year 1 in the proleptic Gregorian calendar, with January 1 of year 1 being day number 1.",
    "class": "Timestamp"
  },
  "pandas.Timestamp.tzinfo": {
    "new_func": "timezone_information",
    "description": "Accesses the timezone details of the datetime object.",
    "class": "Timestamp"
  },
  "pandas.api.types.is_any_real_numeric_dtype": {
    "new_func": "validate_float_numerals",
    "description": "Verifies if the given array or data type is of a floating-point number type. This operation is primarily used for data validation purposes.\\nParameters: arr_or_dtype - The candidate array or data type for verification.\\nReturns: A boolean value indicating the presence of a floating-point number type.",
    "class": "api"
  },
  "pandas.api.types.is_categorical_dtype": {
    "new_func": "assert_discrete_classification",
    "description": "Determines if an array-like structure or data type corresponds to a discrete classification type. Note that this function is deprecated as of version 2.2.0.\\nParameters: arr_or_dtype - The array-like structure or data type for examination.\\nReturns: A boolean value confirming whether it matches a discrete classification type.",
    "class": "api"
  },
  "pandas.api.types.is_complex": {
    "new_func": "check_complex_number",
    "description": "Evaluates if a given object represents a complex number.\\nReturns: A boolean value that is true if the object is a complex number.",
    "class": "api"
  },
  "pandas.api.types.is_datetime64_any_dtype": {
    "new_func": "verify_temporal_datatype",
    "description": "Assesses if the supplied array or data type pertains to any temporal data type, including timezone-aware and naive variations.\\nParameters: arr_or_dtype - The targeted array or data type for assessment.\\nReturns: A boolean indicating the compatibility with any temporal data type.",
    "class": "api"
  },
  "pandas.api.types.is_complex_dtype": {
    "new_func": "inspect_compound_datatype",
    "description": "Scrutinizes the given array or data type to determine if it is of a compound numerical data type.\\nParameters: arr_or_dtype - The array or data type under inspection.\\nReturns: A boolean outcome denoting whether the data type is compound numerical.",
    "class": "api"
  },
  "pandas.api.types.is_datetime64_dtype": {
    "new_func": "check_temporal_type",
    "description": "Determines if the provided array-like structure or type description corresponds to a temporal data type with date and time information. It evaluates whether the data adheres to a specific temporal type format.\nParameters: arr_or_dtype (array-like or dtype) - The structure or type descriptor to evaluate.\nReturns: bool - True if it matches the specified temporal type, False otherwise.",
    "class": "api"
  },
  "pandas.api.types.is_datetime64_ns_dtype": {
    "new_func": "validate_nanosecond_timestamp_type",
    "description": "Verifies if the given array or type descriptor is a temporal data type with nanosecond precision. This function inspects the data structure or type to confirm it aligns with a fine-grained temporal format.\nParameters: arr_or_dtype (array-like or dtype) - The candidate array or type descriptor for validation.\nReturns: bool - True if the data type corresponds to nanosecond-level temporal data, False otherwise.",
    "class": "api"
  },
  "pandas.api.types.is_dict_like": {
    "new_func": "assess_mapping_trait",
    "description": "Evaluates whether the specified object exhibits characteristics akin to a mapping structure. This function inspects the object for properties typically associated with key-value pair collections.\nParameters: obj (Any) - The object to investigate for mapping-like attributes.\nReturns: bool - True if the object behaves like a mapping structure, False otherwise.",
    "class": "api"
  },
  "pandas.api.types.is_extension_array_dtype": {
    "new_func": "probe_custom_array_type",
    "description": "Checks if the given object represents a custom array data type specific to the library. It determines if the data type is part of a special category of array types that extend the library's core functionality.\nParameters: arr_or_dtype (object) - The data structure or type to scrutinize, where the data type will be extracted if an array-like input is provided.\nReturns: bool - True if the object is recognized as a custom array data type, False otherwise.",
    "class": "api"
  },
  "pandas.api.types.is_datetime64tz_dtype": {
    "new_func": "inspect_timezone_aware_type",
    "description": "Determines whether the input is a temporal data type with timezone awareness. This function assesses if the data structure or type conforms to a temporal type with timezone information.\nParameters: arr_or_dtype (array-like or dtype) - The array-like structure or type to verify.\nReturns: bool - True if it is a temporal type with timezone context, False otherwise.",
    "class": "api"
  },
  "pandas.api.types.is_integer_dtype": {
    "new_func": "check_integral_data_type",
    "description": "Determines if the provided array or data type represents integer values. This method distinguishes between standard and nullable integer types, but excludes durations measured in nanoseconds. It is useful for validating data types before processing to ensure they contain whole numbers.\nParameters: arr_or_dtype (array-like or dtype) - The input to validate as containing integral data types.\nReturns: bool - A boolean indicating if the input is classified as an integral data type.",
    "class": "api"
  },
  "pandas.api.types.is_integer": {
    "new_func": "verify_whole_number",
    "description": "Evaluates whether the specified object is a whole number. This can be used to identify objects that store values without fractions, which is often required in certain numerical operations.\nReturns: bool - True if the object is a whole number, otherwise False.",
    "class": "api"
  },
  "pandas.api.types.is_interval_dtype": {
    "new_func": "validate_span_data_type",
    "description": "Assesses if an array-like or data type corresponds to a range-based data type. Note that this method is obsolete as of a certain version and a different approach using an instance check is recommended.\nParameters: arr_or_dtype (array-like or dtype) - The input to assess for being a range data type.\nReturns: bool - Indicates whether the input is a range-based data type.",
    "class": "api"
  },
  "pandas.api.types.is_interval": {
    "new_func": "check_range_instance",
    "description": "Verifies if the given object is an instance representing a range between two values. This function is typically used to determine if objects encode for ranges, which can be crucial for interval-based computations.\nReturns: bool - True if the object is a range instance, otherwise False.",
    "class": "api"
  },
  "pandas.api.types.is_iterator": {
    "new_func": "assess_iterator_presence",
    "description": "Inspects the provided object to ascertain if it is an iterator, with a particular focus on generator types as opposed to list-like collections. This facilitates the identification of objects suitable for iteration in a lazy-evaluation context.\nParameters: obj - The object to inspect for iterator characteristics.\nReturns: is_iter (bool) - True if the object is recognized as an iterator, otherwise False.",
    "class": "api"
  },
  "pandas.api.types.is_named_tuple": {
    "new_func": "is_structured_record",
    "description": "Evaluates if the given object is an instance of a structured tuple with named fields. Each field can have a name as well as an index position. Useful for differentiating between simple tuples and those akin to records or simple objects.\nParameters: obj - The entity to be evaluated.\nReturns: True if the object is a structured tuple, False otherwise.",
    "class": "api"
  },
  "pandas.api.types.is_numeric_dtype": {
    "new_func": "has_numeric_structure",
    "description": "Assesses if the provided array structure or data type descriptor corresponds to a numeric data type, which includes integers, floating points, or any variation thereof.\nParameters: arr_or_dtype - The array structure or descriptor of data type to be examined.\nReturns: A truth value indicating if the given array structure or data type descriptor is numeric.",
    "class": "api"
  },
  "pandas.api.types.is_number": {
    "new_func": "is_scalar_value",
    "description": "Determines whether the passed argument is a scalar value, typically a member of the numeric domain, such as an integer or a floating-point.\nParameters: obj - The argument to be inspected.\nReturns: True if the argument is a scalar value, False otherwise.",
    "class": "api"
  },
  "pandas.api.types.is_list_like": {
    "new_func": "is_sequence_type",
    "description": "Verifies if the provided argument exhibits characteristics of a sequence container, which includes structures like arrays, linked lists, or any iterable collection excluding character sequences and temporal objects.\nParameters: obj - The object under scrutiny; allow_sets - A flag determining if set types should be included as sequence containers.\nReturns: True if the object is sequence-like, False if not, based on the criteria and the allow_sets flag.",
    "class": "api"
  },
  "pandas.api.types.is_object_dtype": {
    "new_func": "has_generic_structure",
    "description": "Inspects whether the given array-like construct or data type descriptor pertains to a generic object data type, typically used for mixed or non-specific data types in a container.\nParameters: arr_or_dtype - The array-like construct or data type descriptor to be inspected.\nReturns: A boolean indicator signaling if the construct or descriptor is of a generic object data type.",
    "class": "api"
  },
  "pandas.api.types.is_period_dtype": {
    "new_func": "check_cycle_time_type",
    "description": "Evaluates if the provided input is of a time-span data type commonly used for time series. The method is being phased out and a direct type comparison is recommended instead.\nParameters: arr_or_dtype (array-like or data type) - The input to evaluate.\nReturns: bool - Indicator of whether the input corresponds to the specified data type.",
    "class": "api"
  },
  "pandas.api.types.is_re_compilable": {
    "new_func": "can_construct_pattern",
    "description": "Assesses whether a given object can be transformed into a regular expression pattern.\nParameters: obj - The object to evaluate.\nReturns: bool - True if the object can be turned into a regular expression pattern, False otherwise.",
    "class": "api"
  },
  "pandas.api.types.is_signed_integer_dtype": {
    "new_func": "has_negative_number_type",
    "description": "Determines if the argument is a data type that includes both positive and negative whole numbers, but not time intervals. Null-aware integer data types are also recognized by this method.\nParameters: arr_or_dtype (array-like or data type) - The input to evaluate.\nReturns: bool - True if the input is a data type that allows for negative values, excluding time intervals.",
    "class": "api"
  },
  "pandas.api.types.is_re": {
    "new_func": "pattern_instance_check",
    "description": "Verifies if a given object is an instance of a regular expression pattern.\nParameters: obj - The object to examine.\nReturns: bool - True if the object is an instance of a regular expression pattern, False otherwise.",
    "class": "api"
  },
  "pandas.api.types.is_scalar": {
    "new_func": "elementary_value_check",
    "description": "Determines if the provided argument is a single-value entity, which includes individual numbers, strings, byte sequences, time-related objects, or similar singular data items.\nParameters: val (object) - The entity to inspect.\nReturns: bool - True if the entity is a single-value, otherwise False.",
    "class": "api"
  },
  "pandas.api.types.is_timedelta64_dtype": {
    "new_func": "check_duration_datatype",
    "description": "Evaluates whether the specified array or data type is a duration data type based on 64-bit time delta representation. It determines if the data conforms to the expected time duration format.\nParameters: \n- arr_or_dtype (array-like or data type): The data or data type to evaluate.\nReturns: \n- bool: True if it matches the duration data type, otherwise False.",
    "class": "api"
  },
  "pandas.api.types.is_unsigned_integer_dtype": {
    "new_func": "verify_nonnegative_whole_number_type",
    "description": "Determines if the given array or data type represents a non-negative whole number data type. It includes non-nullable integer types as well as the nullable integer data types.\nParameters: \n- arr_or_dtype (array-like or data type): The data or data type to evaluate.\nReturns: \n- bool: True if it is a non-negative whole number data type, otherwise False.",
    "class": "api"
  },
  "pandas.api.types.is_string_dtype": {
    "new_func": "validate_textual_datatype",
    "description": "Assesses if the provided array or data type is composed of textual data elements. If an array with object data type is given, it ensures that each item can be interpreted as text.\nParameters: \n- arr_or_dtype (array-like or data type): The data or data type to assess.\nReturns: \n- bool: True if the data type is textual, otherwise False.",
    "class": "api"
  },
  "pandas.api.types.pandas_dtype": {
    "new_func": "convert_to_specific_datatype",
    "description": "Transforms the input into an exclusive data type object used within the library or a general numerical data type object.\nParameters: \n- dtype (object): The object to be transformed into a data type.\nReturns: \n- A library-specific or general numerical data type object.\nRaises: \n- TypeError: Raised if the input is not a valid data type.",
    "class": "api"
  },
  "pandas.api.types.union_categoricals": {
    "new_func": "merge_categorical_series",
    "description": "Merges an array-like collection of categorical-like entities into a single categorical entity, combining their categories. All entities must share the same data type.\nParameters: \n- to_union (list-like): Collection of Categorical, CategoricalIndex, or Series with category data type.\n- sort_categories (bool, default False): Determines if the combined categories should be sorted lexically.\n- ignore_order (bool, default False): If set to true, disregards the order of the categories, resulting in an unordered categorical entity.\nReturns: \n- A unified categorical entity.\nRaises: \n- TypeError: If there are data type inconsistencies or order property mismatches among the input entities, or if ordered categories differ and sorting is requested.\n- ValueError: If an empty collection is provided.",
    "class": "api"
  },
  "pandas.array": {
    "new_func": "assemble_sequence",
    "description": "Constructs a one-dimensional array-like object from a sequence of scalar values. The method allows for specifying the desired data type and whether to create a copy of the input data. It supports the creation of custom-typed arrays if the data type is registered as an extension. The output is an array that can store various types of data including intervals, periods, datetimes, timedeltas, integers, floats, strings, booleans, and more, depending on the scalar type provided. If no data type is specified, the method tries to deduce the appropriate type based on the input data's characteristics.\nParameters:\n- data (Sequence of objects): The sequence from which to create the array.\n- dtype (optional): The desired data type for the array.\n- copy (bool, default True): Whether to copy the data if necessary.\nReturns:\n- An array-like object of the specified data type.",
    "class": "main"
  },
  "pandas.api.types.is_sparse": {
    "new_func": "verify_sparsity",
    "description": "Determines if an array-like object is a one-dimensional sparse array. This function is marked as deprecated and will be removed in future versions. It is recommended to use another method to check for sparsity by testing the data type.\nParameters:\n- arr (array-like): The input object to check for sparsity.\nReturns:\n- A boolean indicating if the input is a sparse array.",
    "class": "api"
  },
  "pandas.arrays.DatetimeArray": {
    "new_func": "time_series_array",
    "description": "Creates a specialized array for handling sequences of date and time information. This array can store either timezone-naive or timezone-aware datetime data. It is important to note that this type of array is still undergoing development and its interface may change in future releases. The array's data type and frequency can be specified upon creation, and the data can be copied if desired.\nParameters:\n- values (array-like): The date and time data.\n- dtype (optional): The desired data type for the datetime data.\n- freq (optional): The frequency of the datetime data.\n- copy (bool, default False): Whether to copy the data.\nReturns:\n- An array specifically designed for datetime data.",
    "class": "arrays"
  },
  "pandas.arrays.BooleanArray": {
    "new_func": "binary_logic_array",
    "description": "Constructs an array for storing binary (True/False) values, including the presence of missing data. Internally, it uses two arrays to represent the data: one for the actual boolean values and another for indicating missing values. This array type supports three-valued logic operations. When creating this array from an array-like input, a specified data type of 'boolean' can be used. This array type is still under development and may see changes to its API.\nParameters:\n- values (numpy.array): A one-dimensional array with boolean data.\n- mask (numpy.array): A one-dimensional array indicating missing values.\n- copy (bool, default False): Whether to make a copy of the input arrays.\nReturns:\n- An array designed for boolean data with missing value support.",
    "class": "arrays"
  },
  "pandas.arrays.ArrowStringArray": {
    "new_func": "chunked_text_array",
    "description": "Provides an array structure specifically for text data stored in a pyarrow.ChunkedArray. This array is optimized for string operations and is based on the Arrow computing framework. Users should be aware that this array type is experimental and may experience changes or alterations in its API without prior notice.\nParameters:\n- values (pyarrow.Array or pyarrow.ChunkedArray): The data to be stored in the array.\nReturns:\n- An array optimized for string data.",
    "class": "arrays"
  },
  "pandas.concat": {
    "new_func": "unify_series_frames",
    "description": "Joins a sequence or mapping of similar structured data containers along a specified axis. It provides the ability to perform set logic on the other axes and to create a MultiIndex when labels align or overlap. The function allows for different types of concatenation logic such as intersection or union of the indexes. Parameters: - sequence (sequence or mapping): Data structures to be joined. - axis (int): The axis along which to join. - join_mode (str): Method for handling indexes on other axes. - disregard_index (bool): Whether to ignore index values on the concatenation axis. - key_sequence (sequence): Keys for the outermost level of a resulting MultiIndex. - level_values (list of sequences): Values to use for constructing a MultiIndex. - level_names (list): Names for levels in the MultiIndex. - check_duplicates (bool): Whether to check for duplicates on concatenated axis. - sort_nonconcat_axis (bool): Whether to sort non-concatenation axis. - duplicate_data (bool): Whether to copy data or not. Returns: - combined_object: The unified data structure.",
    "class": "main"
  },
  "pandas.arrays.StringArray": {
    "new_func": "textual_array",
    "description": "Represents an array specifically for text data. This type is under development and might change. It encapsulates sequences of text elements, including handling missing data. Parameters: - text_data (array-like): Collection of string data. - create_copy (bool): Flag to determine if the original data should be duplicated. Returns: None",
    "class": "arrays"
  },
  "pandas.cut": {
    "new_func": "segment_intervals",
    "description": "Segments data into intervals, converting continuous data into categorical data by sorting it into bins. The function allows for equal or custom-defined binning. Parameters: - data (array-like): One-dimensional array to be binned. - partitioning (int, sequence of scalars, or IntervalIndex): Defines the number of bins or specific bin edges. - include_right (bool): Whether the bins include the rightmost edge. - bin_labels (array or bool): Labels for the resulting bins. - return_bins (bool): Whether to return the bins. - decimal_precision (int): Precision for bin labels. - include_lowest (bool): Whether the first interval is left-inclusive. - handle_duplicates (str): How to handle duplicate bin edges. - label_order (bool): Whether the labels are ordered. Returns: - binned_output: Representing the bin for each value. - bin_edges: The computed or specified bins. Returned when return_bins is True.",
    "class": "main"
  },
  "pandas.date_range": {
    "new_func": "timepoint_sequence",
    "description": "Generates a sequence of time points at specified intervals, within a defined date range. Each point adheres to a uniform frequency or a custom frequency rule. Parameters: - start_point (str or datetime-like): Initial date for the range. - end_point (str or datetime-like): Final date for the range. - period_count (int): Quantity of periods to generate. - time_frequency (str, Timedelta, or DateOffset): The increment between each time point. - timezone (str or tzinfo): Time zone for the date range. - day_normalization (bool): Adjust the start and end dates to midnight. - range_name (str): Name for the resulting index. - bound_inclusion (str): Inclusivity of range boundaries. - time_unit (str): Desired resolution of the result. Returns: - time_index: Index of equally spaced time points.",
    "class": "main"
  },
  "pandas.eval": {
    "new_func": "string_expression_executor",
    "description": "Calculates the result of a string expression, using different evaluation engines. This method supports arithmetic and boolean operations and is capable of handling data objects in the expression. Parameters: - expression (str): The string expression to evaluate. - syntax_parser (str): Choice of syntax tree construction method. - computation_engine (str): The backend used for calculation. - scope_locals (dict): Local variables for expression context. - scope_globals (dict): Global variables for expression context. - name_resolvers (list): Additional namespaces for variable lookup. - scope_level (int): Number of prior stack frames to include in scope. - assignment_target (object): The object for variable assignment. - apply_changes (bool): Whether to modify the assignment target in place. Returns: - evaluation_result: The result of the evaluated expression, which could be an array, scalar, or data structure.",
    "class": "main"
  },
  "pandas.plotting.lag_plot": {
    "new_func": "time_series_delay_scatter",
    "description": "Generates a scatter plot to visualize the relationship between data points in a time series and their preceding values by a specified lag. This is useful for examining the autocorrelation of the series.\nParameters: series (Series) - The time series data to plot. lag (int, default 1) - The number of intervals by which to lag the observations. ax (matplotlib axis object, optional) - The plotting area to use for the scatter diagram. **kwds - Additional keyword arguments for matplotlib scatter function.\nReturns: Axes object from matplotlib.",
    "class": "plotting"
  },
  "pandas.plotting.andrews_curves": {
    "new_func": "multivariate_cluster_visualizer",
    "description": "Creates a plot that transforms multivariate data into a two-dimensional space using a series of Fourier series functions, enabling the visual assessment of cluster separation. Each instance in the dataset is represented by a continuous curve within the plot domain.\nParameters: frame (DataFrame) - The data set to be transformed and displayed. class_column (label) - The column name in the frame that contains the class information. ax (axes object, default None) - The plot area to be used for drawing the curves. samples (int) - The number of values to generate for each curve. color (str, list[str], tuple[str], optional) - The color identifiers for each class. colormap (str or colormap object, default None) - The coloring scheme to be applied. **kwargs - Additional options for the plotting method.\nReturns: Axes object from matplotlib.",
    "class": "plotting"
  },
  "pandas.plotting.bootstrap_plot": {
    "new_func": "statistical_sampling_uncertainty_plot",
    "description": "Produces a visual analysis of the variability of key statistical figures such as the mean, median, and mid-range from a data series using resampling with replacement. This technique provides insight into the distribution of a statistic and its reliability.\nParameters: series (Series) - The input data for generating the bootstrap samples. fig (Figure, default None) - An existing figure to draw on, if any. size (int, default 50) - The sample size for each resampling iteration. samples (int, default 500) - The number of bootstrap iterations to perform. **kwds - Additional keyword arguments for the plotting function.\nReturns: Figure object from matplotlib.",
    "class": "plotting"
  },
  "pandas.plotting.plot_params": {
    "new_func": "charting_parameter_defaults",
    "description": "Defines a dictionary that stores default parameter settings for charting functions. It simplifies the process of managing and applying plotting parameters by allowing the use of aliases that correspond to existing function arguments.",
    "class": "plotting"
  },
  "pandas.plotting.register_matplotlib_converters": {
    "new_func": "initiate_custom_chart_formatters",
    "description": "Incorporates custom formatters and data type converters into the plotting library to handle specific date and time representations. This ensures proper interpretation and display of these data types within charts.",
    "class": "plotting"
  },
  "pandas.read_csv": {
    "new_func": "ingest_delimited_data",
    "description": "This function loads data from a file with values separated by a specific character into a two-dimensional labeled data structure. It can handle large files by breaking them into smaller chunks or iterating through the file if desired. It infers the file's compression format and supports various delimiters, quoting conventions, and data types.\nParameters:\n- filepath_or_buffer (str or file-like object): The file path or object to read from.\n- sep (str, default ','): Delimiter to use between fields.\n- header (int, list of int, 'infer', None): Row to use for column names.\n- names (list of str): List of column names.\n- index_col (int, str, list of int, None): Column to set as index.\n- usecols (list, callable): Columns to read from the file.\n- dtype (type or dict): Data type for data or columns.\n- engine (str): Parser engine to use.\n- converters (dict): Functions for converting column values.\n- skiprows (int, list, callable): Line numbers to skip.\n- nrows (int): Number of rows to read.\n- na_values (scalar, str, list-like, dict): Additional values to consider as NA/NaN.\n- keep_default_na (bool): Include default NaN values when parsing.\n- na_filter (bool): Detect missing value markers.\n- parse_dates (bool, list, dict): Columns to parse as dates.\n- chunksize (int): Number of lines to read per chunk.\n- compression (str, dict): For on-the-fly decompression of on-disk data.\n- ... and additional parameters.\nReturns:\n- A two-dimensional labeled data structure with labeled axes.",
    "class": "main"
  },
  "pandas.read_feather": {
    "new_func": "load_feathered_dataset",
    "description": "This function retrieves a dataset stored in the feather binary file format. It allows for selecting specific columns and can read the data in parallel using multiple threads.\nParameters:\n- path (str or file-like object): File path or object to read from.\n- columns (list of str, optional): Columns to read from the file.\n- use_threads (bool): Whether to parallelize reading with multiple threads.\n- storage_options (dict): Options for storage connection.\n- dtype_backend (str): Data type backend for the resulting data structure.\nReturns:\n- The type of object stored in the feather file.",
    "class": "main"
  },
  "pandas.read_fwf": {
    "new_func": "import_fixed_width_format",
    "description": "This function imports data from a text file with fixed-width formatted lines into a tabular data structure. It supports custom field widths and can automatically infer column specifications from the data. It can also process the file in chunks for memory efficiency.\nParameters:\n- filepath_or_buffer (str or file-like object): The file path or object to read from.\n- colspecs (list of tuples or 'infer'): Column specifications.\n- widths (list of int): Field widths.\n- infer_nrows (int): Number of rows to consider for inferring colspecs.\n- dtype_backend (str): Data type backend for the resulting data structure.\n- iterator (bool): Return an iterator for iteration or getting chunks.\n- chunksize (int): Number of lines to read per chunk.\n- **kwds (optional): Additional keyword arguments for TextFileReader.\nReturns:\n- A tabular data structure with labeled axes or a TextFileReader object.",
    "class": "main"
  },
  "pandas.read_excel": {
    "new_func": "extract_spreadsheet",
    "description": "This function extracts data from an Excel file into a tabular data structure. It supports various file formats and can read either a single sheet or a list of sheets. The function can handle custom column types, date parsing, and allows for selecting specific columns or rows to parse.\nParameters:\n- io (str, file-like object): File path or object to read from.\n- sheet_name (int, str, list, None): Sheets to read from the file.\n- header (int, list of int): Row to use for column labels.\n- names (list of str): Column names to use.\n- index_col (int, str, list of int): Column to set as index.\n- usecols (str, list, callable): Columns to parse from the file.\n- dtype (type or dict): Data type for data or columns.\n- engine (str): Engine to use for reading.\n- converters (dict): Functions for converting column values.\n- skiprows (int, list, callable): Lines to skip.\n- nrows (int): Number of rows to read.\n- na_values (scalar, str, list-like, dict): Additional values to consider as NA/NaN.\n- keep_default_na (bool): Include default NaN values when parsing.\n- na_filter (bool): Detect missing value markers.\n- parse_dates (bool, list, dict): Columns to parse as dates.\n- storage_options (dict): Options for storage connection.\n- dtype_backend (str): Data type backend for the resulting data structure.\n- engine_kwargs (dict): Arbitrary keyword arguments for excel engine.\nReturns:\n- A tabular data structure or a dictionary of them, depending on the sheet_name parameter.",
    "class": "main"
  },
  "pandas.read_gbq": {
    "new_func": "fetch_bigquery_data",
    "description": "This function retrieves data from a Google BigQuery dataset using a SQL-like query. It supports custom configurations for queries, including changing the dialect of the syntax. The user can specify the project ID, reauthentication requirements, and a number of other options to customize the data retrieval process.\nParameters:\n- query (str): SQL-like query for retrieving data.\n- project_id (str, optional): Google BigQuery Account project ID.\n- index_col (str, optional): Column name for index in resulting data structure.\n- col_order (list of str, optional): Order of columns in the result.\n- reauth (bool): Force re-authentication if needed.\n- auth_local_webserver (bool): Use the local webserver flow for authentication.\n- dialect (str): The SQL syntax dialect to use.\n- location (str, optional): Location where the query job should run.\n- configuration (dict, optional): Query config parameters.\n- credentials (google.auth.credentials.Credentials, optional): Credentials for Google APIs.\n- use_bqstorage_api (bool): Use the BigQuery Storage API for faster downloads.\n- max_results (int, optional): Maximum number of rows to fetch.\n- progress_bar_type (str, optional): Use a progress bar for downloads.\nReturns:\n- A tabular data structure representing the results of the query.",
    "class": "main"
  },
  "pandas.read_spss": {
    "new_func": "ingest_sav_file",
    "description": "Loads data from an SPSS file format into a structured data frame. This function allows selective column retrieval and can convert categorical variables into a specialized data structure for categorical data. The backend data type for the returned data structure can be specified to be either based on nullable types or a particular third-party library's data types. Parameters: - file_path (str or Path): The file path to the SPSS file. - desired_columns (list-like, optional): Columns to include in the resulting data frame. - categorical_conversion (bool, default True): Whether to convert categorical columns into a categorical data structure. - backend_dtype (str, {'numpy_nullable', 'third_party_lib'}, default 'numpy_nullable'): The backend data type to use for the returned data structure. Returns: - A structured data frame containing the loaded data.",
    "class": "main"
  },
  "pandas.read_parquet": {
    "new_func": "fetch_parquet_data",
    "description": "Retrieves data from a Parquet file and outputs it as a structured data frame. The function supports various read configurations, including selective column retrieval, filesystem specification for paths, and data filtering. The backend data type for the returned data frame is configurable, and the data frame can be chunked for memory efficiency. Parameters: - file_path (str, path-like, or file-like object): The path to the Parquet file or a file-like object. - read_engine (str, {'auto', 'third_party_lib1', 'third_party_lib2'}, default 'auto'): The library to use for reading the Parquet file. - selected_columns (list, optional): Specific columns to read from the file. - storage_options (dict, optional): Additional options relevant to the storage connection. - nullable_dtypes (bool, default False): If True, use nullable data types for the result. - backend_dtype (str, {'numpy_nullable', 'third_party_lib'}, default 'numpy_nullable'): The backend data type to use for the returned data frame. - file_system (object, optional): The file system object to use when reading the Parquet file. - data_filters (list, optional): Filters to apply to the data while reading. - Additional keyword arguments passed to the read engine. Returns: - A structured data frame containing the retrieved data.",
    "class": "main"
  },
  "pandas.read_sas": {
    "new_func": "extract_sas_dataset",
    "description": "Imports data from a SAS file, which can be in XPORT or SAS7BDAT format, into a structured data frame. The function supports various options, including incremental reading, specifying an index column, and handling different encodings. Parameters: - sas_file_path (str, path-like, or file-like object): The path to the SAS file or a file-like object. - file_format (str, {'xport', 'sas7bdat'}, optional): The format of the SAS file to read. - index_column (str, optional): The column to set as the index of the data frame. - text_encoding (str, optional): The encoding to use for reading text data. - read_chunksize (int, optional): The number of lines to read at a time if reading in chunks. - use_iterator (bool, default False): Whether to return an iterator for reading the file incrementally. - compression_method (str or dict, default 'infer'): The compression format of the SAS file, if any. Returns: - A structured data frame or an iterator object for the SAS data.",
    "class": "main"
  },
  "pandas.read_stata": {
    "new_func": "ingest_dta_format",
    "description": "Reads data from a DTA file format used by Stata into a structured data frame. The function allows for various data conversion options and can handle different compression methods. It also supports reading the data in chunks, returning an iterator for large files. Parameters: - dta_file_path (str, path-like, or file-like object): The path to the Stata DTA file or a file-like object. - date_conversion (bool, default True): Whether to convert date columns to datetime objects. - categorical_conversion (bool, default True): Whether to convert columns with value labels to categorical variables. - index_column (str, optional): The column to set as the index of the data frame. - missing_values_conversion (bool, default False): Whether to convert missing values to their Stata representations. - dtype_preservation (bool, default True): Whether to preserve Stata data types when importing. - specified_columns (list, optional): The columns to retain from the DTA file. - categorical_ordering (bool, default True): Whether the converted categorical data should be ordered. - chunksize (int, optional): The number of lines to include in each chunk if reading in chunks. - use_iterator (bool, default False): Whether to return an iterator for reading the file incrementally. - decompression (str or dict, default 'infer'): The decompression method if the DTA file is compressed. - storage_options (dict, optional): Additional options for storage connections. Returns: - A structured data frame or a reader object for the Stata data.",
    "class": "main"
  },
  "pandas.read_sql": {
    "new_func": "retrieve_sql_records",
    "description": "Extracts records from a SQL database query or table and loads them into a structured data frame. The function serves as a wrapper that delegates to specific functions based on the input provided, with support for various data types and chunked reading. Parameters: - sql_query_or_table (str or selectable object): The SQL query string or table name to execute. - connector (object): A connection object to the SQL database, or a connection string. - index_columns (str or list of str, optional): Column(s) to use as the index for the resulting data frame. - floating_conversion (bool, default True): Whether to convert non-numeric data to float. - query_params (list, tuple, or dict, optional): Parameters to pass to the SQL query execution. - datetime_parsing (list or dict, optional): Instructions on which columns to parse as dates and how. - selected_columns (list, optional): List of column names to select from the SQL table. - read_chunksize (int, optional): The number of rows to include in each chunk of the data frame. - backend_dtype (str, {'numpy_nullable', 'third_party_lib'}, default 'numpy_nullable'): The backend data type to use for the returned data frame. - column_types (type or dict of column types, optional): The data type to use for the data or specified columns. Returns: - A structured data frame or an iterator of data frames containing the SQL records.",
    "class": "main"
  },
  "pandas.tseries.offsets.BQuarterBegin.is_year_end": {
    "new_func": "terminates_annual_cycle",
    "description": "Evaluates whether a specified timestamp coincides with the final day of an annual cycle. It checks for alignment with the last day of the fiscal year. Parameters: ts (Timestamp) - The moment in time to check. Returns: boolean - True if the timestamp is the last day of the year, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BQuarterBegin.is_month_start": {
    "new_func": "initiates_monthly_phase",
    "description": "Ascertains if a particular timestamp corresponds to the initial day of a monthly phase. It determines if the date is the commencement of a month. Parameters: ts (Timestamp) - The date-time instance to verify. Returns: boolean - True if the timestamp signifies the beginning of a month, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BQuarterEnd.freqstr": {
    "new_func": "quarterly_closing_periodicity_representation",
    "description": "Outputs a textual representation of the period between the final weekday of each quarter.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BQuarterEnd": {
    "new_func": "business_quarter_terminator",
    "description": "Creates an object that advances dates to the last weekday of a quarter, considering the specified starting month. The object can be used to increment dates by a certain number of quarter periods.\nParameters:\n- count (int, default 1): The number of quarter periods to advance.\n- standardize (bool, default False): If True, sets the time to midnight before computing the range.\n- commencement_month (int, default 3): An integer representing the month from which the quarter count begins, where 1 is January and 12 is December.\nReturns: An object that can be used to increment date values.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BQuarterEnd.copy": {
    "new_func": "duplicate_quarterly_terminus",
    "description": "Generates an identical clone of the current object that denotes the last working day of a quarter period.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BQuarterEnd.is_anchored": {
    "new_func": "unitary_quarter_span_check",
    "description": "Evaluates if the object represents a single quarter period. Note: This functionality is deprecated and will be removed in upcoming releases. As an alternative, check if the 'n' attribute equals 1.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BQuarterEnd.is_month_end": {
    "new_func": "final_weekday_of_month_check",
    "description": "Determines if a given timestamp falls on the final business day of the month.\nParameters: timestamp - The point in time to evaluate.\nReturns: A boolean indicating if the timestamp is the last business day of the month.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BQuarterEnd.normalize": {
    "new_func": "standardize_quarterly_closure",
    "description": "Adjusts the quarter end datetime object to a standard time of day, typically setting it to midnight. This process ensures that the time component of the datetime is consistent, usually for comparison or alignment purposes.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BQuarterEnd.name": {
    "new_func": "alias_for_quarter_terminus",
    "description": "Provides a textual identifier that encapsulates the underlying period at a quarterly granularity. This identifier is commonly used for labeling or referencing the specific interval in a concise format.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BYearBegin": {
    "new_func": "initiate_fiscal_annum",
    "description": "Advances a datetime object to the first working day of a new calendar year, with the option to advance multiple years. This is used for aligning dates within financial or business contexts where the start of the working year is significant.\nParameters:\n- count (int, default 1): The number of periods to leap.\n- standardize (bool, default False): Whether to set the time to midnight.\n- month_idx (int, default 1): The month from which the year should be considered as starting.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BYearBegin.freqstr": {
    "new_func": "temporal_frequency_descriptor",
    "description": "Yields a character code that succinctly represents the interval pattern of the date advancement. This code is typically utilized in time series analysis to define the regularity of the data points.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BYearBegin.is_quarter_end": {
    "new_func": "fiscal_period_closure_check",
    "description": "Evaluates if a specific point in time coincides with the closure of a fiscal quarter. It outputs a truth value confirming or denying the coincidence.\nParameters: ts (timestamp) - The point in time for evaluation.\nReturns: bool - True if the timestamp aligns with the end of a fiscal quarter, False otherwise.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BYearBegin.is_year_end": {
    "new_func": "annual_terminus_occurrence",
    "description": "Assesses whether a given moment falls on the final day of the financial year. It generates a boolean outcome indicating this occurrence.\nParameters: ts (timestamp) - The moment to be assessed.\nReturns: bool - True if the moment matches the last day of a financial year, False otherwise.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BYearBegin.is_year_start": {
    "new_func": "initial_annual_instant_check",
    "description": "Determines if a specified instant is concurrent with the commencement of a fiscal year. The result is a boolean indicating such alignment.\nParameters: ts (timestamp) - The instant to be determined.\nReturns: bool - True if the instant aligns with the start of a fiscal year, False if not.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BYearBegin.is_quarter_start": {
    "new_func": "quarter_inception_alignment",
    "description": "Checks if a particular timestamp matches the inception of a fiscal quarter. A boolean value is returned to denote this alignment.\nParameters: ts (timestamp) - The timestamp to check.\nReturns: bool - True if the timestamp coincides with the beginning of a fiscal quarter, False otherwise.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BYearBegin.kwds": {
    "new_func": "offset_parameters_retrieval",
    "description": "Retrieves a dictionary containing supplementary parameters pertinent to the financial year's offset computation.\nParameters: None.\nReturns: dict - A dictionary of additional keyword arguments related to the offset.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BYearEnd.is_year_end": {
    "new_func": "terminal_annum_check",
    "description": "Determines if a given timestamp coincides with the final day of the business year. It outputs a value indicating the truth of this condition.\\nParameters: ts (timestamp) - The point in time to evaluate.\\nReturns: bool - True if the timestamp is the last business day of the year; otherwise, False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BYearEnd.is_year_start": {
    "new_func": "commence_annum_verification",
    "description": "Evaluates whether a specific timestamp aligns with the initial day of the business year. It yields a true or false value based on this assessment.\\nParameters: ts (timestamp) - The moment in time to analyze.\\nReturns: bool - True if the timestamp matches the first business day of the year; else, False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BYearEnd.month": {
    "new_func": "terminal_month_retrieval",
    "description": "Accesses the month component of the business year end offset. This attribute specifies the month in which the business year typically concludes.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BusinessDay.calendar": {
    "new_func": "workweek_schedule",
    "description": "Retrieves the scheduling details for standard workdays.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BusinessDay": {
    "new_func": "weekday_interval",
    "description": "Represents a span of standard working days. It can be used to calculate date offsets considering only the days when businesses typically operate. Parameters: - count (int, default 1): The quantity of intervals to include. - standardize (bool, default False): Adjust the start and end times to the beginning of the day. - shift (timedelta, default timedelta(0)): The additional time to apply to the offset. Returns: A date offset object that can be used to perform date arithmetic on standard working days.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BYearEnd.rule_code": {
    "new_func": "fiscal_year_terminus_code",
    "description": "Retrieves the identifier for the offset corresponding to the last business day of the fiscal year.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BusinessDay.is_month_end": {
    "new_func": "final_workday_checker",
    "description": "Determines if a given timestamp falls on the final working day of a month. Parameters: timestamp (Timestamp) - The point in time to evaluate. Returns: bool - True if the timestamp corresponds with the last working day of the month; otherwise, False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BusinessDay.freqstr": {
    "new_func": "daily_rhythm_code",
    "description": "Provides a textual representation of the regular occurrence cycle for working days.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BusinessDay.is_on_offset": {
    "new_func": "weekday_concurrence_check",
    "description": "Determines if a specific date coincides with the working weekday frequency. This operation checks for the alignment of a given date with the standard workweek schedule.\nParameters: dt (datetime.datetime) - The date to be evaluated.\nReturns: bool - True if the date aligns with the working weekday, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BusinessDay.is_anchored": {
    "new_func": "unit_frequency_verifier",
    "description": "Assesses if the frequency corresponds to a singular unit (n=1). This function is pending deprecation and will be discontinued in subsequent releases. As an alternative, one should verify if the frequency's 'n' attribute is equal to one.\nParameters: None.\nReturns: bool - True if the frequency is equivalent to a single unit, otherwise False.\nNote: This function is deprecated as of version 2.2.0.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BusinessDay.is_quarter_end": {
    "new_func": "terminal_of_quarter",
    "description": "Checks if a given date signifies the cessation of a fiscal quarter. This function is instrumental in identifying the last working day of a quarter.\nParameters: ts (datetime.datetime) - The date to check.\nReturns: bool - True if the date aligns with the final day of a quarter, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BusinessDay.is_quarter_start": {
    "new_func": "inception_of_quarter",
    "description": "Determines if a specified date corresponds with the outset of a fiscal quarter. This function is particularly useful for pinpointing the first working day of a quarter.\nParameters: ts (datetime.datetime) - The date to be scrutinized.\nReturns: bool - True if the date coincides with the start of a quarter, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BusinessDay.weekmask": {
    "new_func": "active_days_indicator",
    "description": "Provides a string representing the days of the week that are considered active or working days. Each character in the string corresponds to a day of the week, starting with Monday.\nParameters: None\nReturns: str - A string with boolean flags (e.g., '1111100') indicating working days.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BusinessDay.rule_code": {
    "new_func": "weekday_rule_identifier",
    "description": "Yields a string that symbolizes the specific rule used for determining working days within a given frequency setup.\nParameters: None\nReturns: str - The code that encapsulates the rule logic for working days.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BusinessHour.end": {
    "new_func": "closing_time",
    "description": "Retrieves the time of day that signifies the end of the business hours. This is typically when operations cease for the day.\nParameters: None\nReturns: datetime.time - The time at which the business hours conclude.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BusinessMonthBegin.copy": {
    "new_func": "duplicate_monthly_offset",
    "description": "Produces an identical instance of the initial business month commencement timing setting, ensuring any modifications do not affect the original instance. The method guarantees the replication of all attributes of the original object.\nParameters: None.\nReturns: An exact duplicate of the business month commencement timing setting.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BusinessMonthBegin.freqstr": {
    "new_func": "monthly_offset_notation",
    "description": "Provides a textual representation of the business month inception periodicity, encapsulating the timing pattern in a concise format suitable for display or further processing.\nParameters: None.\nReturns: String - A textual notation of the business month inception periodicity.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BusinessHour.start": {
    "new_func": "initial_work_hour",
    "description": "Retrieves the commencement time of the standard business hours, defining the point at which the interval begins each day.\nParameters: None.\nReturns: A datetime.time object representing the start of business hours.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BusinessHour.weekmask": {
    "new_func": "weekday_active_pattern",
    "description": "Yields the binary sequence that represents the days of the week when business operations are active, providing a template for which days are considered as working days within the week.\nParameters: None.\nReturns: String - A binary sequence indicating active business days of the week.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BusinessMonthEnd.is_year_end": {
    "new_func": "fiscal_curtain_fall",
    "description": "Evaluates whether a particular moment coincides with the concluding day of a financial cycle. This function examines the given temporal marker and produces a truth value denoting the concurrence with this chronological juncture. Parameters: timestamp (datetime-like) - The temporal marker to be appraised. Returns: boolean - True if the timestamp matches the end of the financial period, False otherwise.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.BusinessMonthEnd.is_year_start": {
    "new_func": "fiscal_outset_check",
    "description": "Ascertain whether a given point in time falls on the inaugural day of a financial annum. This procedure probes the specified temporal reference and returns a veracity value reflecting the start of the financial term. Parameters: timestamp (datetime-like) - The temporal reference for examination. Returns: boolean - True if the timestamp is concurrent with the start of the financial cycle, False otherwise.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CustomBusinessDay": {
    "new_func": "TailoredWeekdayInterval",
    "description": "Represents a specific span of tailored weekdays which can be adjusted according to a custom schedule. This span can be defined by a number of tailored weekdays, with the ability to normalize the interval's start and end times, apply a specific weekly schedule, exclude certain dates, and integrate a predefined calendar. Additionally, a time offset can be added to the start times of the interval.\\nParameters:\\n- count (int, default 1): The number of tailored weekdays in the span.\\n- standardize (bool, default False): If true, adjusts the interval's start and end times to the start of the day.\\n- schedule (str, default 'Mon Tue Wed Thu Fri'): A string representing the weekly schedule of valid weekdays.\\n- exclusions (list): A list or array of dates to be excluded from the valid weekdays.\\n- integration_calendar (object): A calendar object that defines valid business days.\\n- time_shift (timedelta, default timedelta(0)): The time duration to add to the start times within the interval.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CustomBusinessDay.holidays": {
    "new_func": "TailoredWeekdayExclusions",
    "description": "Fetches the array of dates that are designated as exclusions from tailored weekdays. These exclusions help in defining a custom interval by omitting specific days.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CustomBusinessDay.is_anchored": {
    "new_func": "UnitFrequencyChecker",
    "description": "Determines if the interval represents a single tailored weekday unit. Indicates whether the span is anchored to a unitary count. Note that this method is deprecated and will be removed in future updates. It is advised to compare the count attribute to 1 as an alternative check.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CustomBusinessDay.is_month_end": {
    "new_func": "MonthTerminationMatcher",
    "description": "Checks if a given timestamp coincides with the last day of the month, indicating the end of the monthly cycle.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CustomBusinessDay.freqstr": {
    "new_func": "IntervalNotationRetriever",
    "description": "Obtains a textual representation of the frequency at which the tailored weekday interval occurs.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CustomBusinessDay.is_on_offset": {
    "new_func": "aligns_with_schedule",
    "description": "Determines if a specified date aligns with a particular frequency. Useful for custom business schedules, it verifies if the provided date corresponds to a defined regular interval.\nParameters: dt (datetime.datetime) - The date to verify against the frequency.\nReturns: bool - True if the date coincides with the frequency, False otherwise.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CustomBusinessDay.is_month_start": {
    "new_func": "initiates_monthly_cycle",
    "description": "Checks if a given timestamp signifies the commencement of a new month.\nParameters: ts (datetime-like) - The timestamp to evaluate.\nReturns: bool - True if the timestamp corresponds to the first day of a month, False otherwise.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CustomBusinessDay.is_year_end": {
    "new_func": "concludes_annual_period",
    "description": "Assesses if a particular timestamp marks the conclusion of an annual cycle.\nParameters: ts (datetime-like) - The timestamp to examine.\nReturns: bool - True if the timestamp falls on the last day of the year, False otherwise.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CustomBusinessDay.is_year_start": {
    "new_func": "CustomBusinessDay_commences_annual_cycle",
    "description": "Evaluates if a specific timestamp indicates the beginning of an annual term.\nParameters: ts (datetime-like) - The timestamp to analyze.\nReturns: bool - True if the timestamp marks the first day of the year, False otherwise.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CustomBusinessDay.is_quarter_start": {
    "new_func": "kickstarts_quarterly_phase",
    "description": "Determines whether a timestamp corresponds to the initiation of a quarterly segment.\nParameters: ts (datetime-like) - The timestamp to scrutinize.\nReturns: bool - True if the timestamp aligns with the start of a quarter, False otherwise.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CustomBusinessHour": {
    "new_func": "TailoredWorkHourSpan",
    "description": "A subclass of DateOffset that represents a specified number of tailored work hours. It allows for customization of workdays, exclusion dates, and specific business hours. The class can be tailored using a week mask, an array of holidays, and a calendar to define valid business days.\nParameters:\nn (int, default 1): The count of work hours to represent.\nnormalize (bool, default False): Whether to set the start/end dates to midnight before creating a range.\nweekmask (str, default 'Mon Tue Wed Thu Fri'): String representing the work week, used to define valid business days.\nholidays (list): Dates to be omitted from the set of valid business days.\ncalendar: A calendar object defining business days.\nstart (str, time, or list, default '09:00'): The commencement time of the business hours in 24-hour format.\nend (str, time, or list, default '17:00'): Conclusion time of the business hours in 24-hour format.\noffset (timedelta, default timedelta(0)): The time differential to apply.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CustomBusinessHour.freqstr": {
    "new_func": "HourlyFrequencyDescriptor",
    "description": "Outputs a textual representation of the frequency for tailored business hours.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CustomBusinessHour.end": {
    "new_func": "BusinessHourClosure",
    "description": "Retrieves the designated closing time for the custom work hours.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CustomBusinessHour.holidays": {
    "new_func": "ExclusionDates",
    "description": "Accesses the list of dates that are excluded from being considered as valid business days in the custom work hours configuration.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CustomBusinessHour.is_month_end": {
    "new_func": "TerminalDayChecker",
    "description": "Evaluates whether a given timestamp coincides with the final day of a month. It returns a boolean value indicating the result.\nParameters: \nts: A timestamp to be checked.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CustomBusinessHour.is_month_start": {
    "new_func": "initial_month_moment",
    "description": "Determines if a given timestamp corresponds to the commencement of a month. It evaluates to true if the specified point in time marks the beginning of a month.\nParameters: ts (datetime-like) - The point in time to be evaluated.\nReturns: bool - True if the timestamp coincides with the start of a month, otherwise false.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CustomBusinessHour.is_quarter_end": {
    "new_func": "terminal_quarter_moment",
    "description": "Evaluates if a specific timestamp aligns with the termination of a quarter. The result is true if the timestamp is the final moment of a fiscal quarter.\nParameters: ts (datetime-like) - The point in time to be assessed.\nReturns: bool - True if the timestamp marks the end of a quarter, otherwise false.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CustomBusinessHour.is_on_offset": {
    "new_func": "frequency_intersection",
    "description": "Determines the coincidence of a precise timestamp with the established frequency. This function checks for alignment between a moment in time and the frequency's criteria.\nParameters: dt (datetime or Timestamp) - The moment in time to check for alignment.\nReturns: bool - True if there is an intersection with the frequency, otherwise false.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CustomBusinessHour.is_quarter_start": {
    "new_func": "commencing_quarter_moment",
    "description": "Identifies if a timestamp signifies the start of a quarter period. It returns true if the timestamp corresponds with the initial moment of a quarter.\nParameters: ts (datetime-like) - The timestamp to verify.\nReturns: bool - True if the timestamp is at the start of a quarter, otherwise false.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CustomBusinessMonthBegin.normalize": {
    "new_func": "month_commence_standardize",
    "description": "Adjusts the starting point of a custom business monthly period to the beginning of the day. This method is used to ensure that the time component of the date is set to midnight (00:00:00) for consistency in time series analysis.\\nParameters: None.\\nReturns: A similar object with the time component normalized to midnight.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CustomBusinessMonthEnd": {
    "new_func": "tailored_work_month_termination",
    "description": "Represents a time-span that rolls forward to the last valid business day of the month based on specified work week patterns and holidays. It provides flexibility to calculate dates that are aligned with non-standard business cycles.\\nParameters:\\nn - An integer indicating the number of months to be considered.\\nnormalize - A boolean flag indicating whether to set the time to midnight.\\nweekmask - A string representing the days of the week considered as valid business days.\\nholidays - A list of dates that should be excluded from business days.\\ncalendar - An object representing the business day calendar.\\noffset - A time delta to apply to the calculated dates.\\nReturns: An object capable of calculating dates that align with the defined custom business month end.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CustomBusinessMonthEnd.holidays": {
    "new_func": "work_month_closure_nonworking_days",
    "description": "Retrieves the list of dates that are considered non-working days within the context of the custom business month's end calculation. These dates are skipped when determining the last business day of the month.\\nParameters: None.\\nReturns: A list of non-working day dates.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CustomBusinessMonthEnd.copy": {
    "new_func": "duplicate_work_month_termination",
    "description": "Creates an identical clone of the current instance that defines the end of a custom business month. This can be useful for preserving the original state before making modifications.\\nParameters: None.\\nReturns: A new instance that is a copy of the current business month end configuration.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.CustomBusinessMonthEnd.calendar": {
    "new_func": "work_month_closure_schedule",
    "description": "Accesses the business day calendar that is used for computing the last business day of the custom business month. This calendar takes into account the specified weekly working schedule and holidays.\\nParameters: None.\\nReturns: The business day calendar associated with the custom business month end.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Day.freqstr": {
    "new_func": "frequency_descriptor",
    "description": "Procures the alphabetic representation of the temporal frequency.\nParameters: None.\nReturns: A string encapsulating the frequency's representation.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Day.delta": {
    "new_func": "timeframe_difference",
    "description": "Retrieves the time span difference represented by the frequency object.\nParameters: None.\nReturns: A timedelta object indicating the temporal span.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Day.is_on_offset": {
    "new_func": "timepoint_intersects_frequency",
    "description": "Determines if a specified temporal point coincides with the established periodicity. It evaluates a given moment to ascertain if it aligns with the frequency of the object.\nParameters: dt (datetime.datetime) - The temporal point to evaluate for intersection with a frequency.\nReturns: bool - True if the moment intersects with the frequency, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Day.is_month_start": {
    "new_func": "commences_with_month",
    "description": "Assesses if a given temporal marker corresponds to the inception of a month. The method examines a point in time to check if it represents the commencement of a month's cycle.\nParameters: ts (datetime.datetime) - The temporal marker to evaluate for alignment with the beginning of a month.\nReturns: bool - True if the marker is at the start of a month, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Day.is_quarter_end": {
    "new_func": "terminates_periodic_quarter",
    "description": "Evaluates whether a specific temporal point marks the cessation of a quarter. It scrutinizes a moment to determine if it signifies the conclusion of the quarterly period.\nParameters: ts (datetime.datetime) - The temporal point to check for alignment with the end of a quarter.\nReturns: bool - True if the moment signifies the ending of a quarter, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Day.is_year_end": {
    "new_func": "culminates_annual_cycle",
    "description": "Inspects a temporal point to ascertain if it coincides with the annual cycle's conclusion. It determines whether a moment in time aligns with the finality of a yearly period.\nParameters: ts (datetime.datetime) - The temporal point to check for concurrence with the year's end.\nReturns: bool - True if the moment coincides with the end of a year, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Day.is_quarter_start": {
    "new_func": "initiates_periodic_quarter",
    "description": "Determines if a moment in time indicates the initiation of a quarterly period. This function scrutinizes the specified temporal marker to verify if it aligns with the onset of a quarter.\nParameters: ts (datetime.datetime) - The temporal marker to evaluate for synchronization with the beginning of a quarter.\nReturns: bool - True if the marker denotes the start of a quarter, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Day.rule_code": {
    "new_func": "daily_standard_identifier",
    "description": "Retrieves the conventional identifier for daily offset within a temporal rule system.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Day.normalize": {
    "new_func": "midnight_reset",
    "description": "Adjusts a temporal offset to the start of the day at midnight.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Easter": {
    "new_func": "spring_festival_calculator",
    "description": "Calculates the observance date for the spring festival based on a specific algorithm valid for the years between 1583 and 4099. It takes into account the number of years to apply the calculation to and whether to adjust the start and end dates to the first moment of the day.\nParameters:\nannual_increment (int, default 1) - The number of years to calculate the date for.\nday_start_adjustment (bool, default False) - Option to adjust dates to the beginning of the day.\nReturns: DateOffset - The calculated date offset for the festival.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Easter.is_anchored": {
    "new_func": "single_year_frequency_check",
    "description": "Assesses whether the frequency represents a single unit or span. Note: This method is planned for deprecation; it is advised to compare the frequency value directly to 1.\nReturns: bool - True if the frequency represents a single year, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Easter.copy": {
    "new_func": "replicate_frequency",
    "description": "Produces an exact duplicate of the specified frequency instance.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Easter.is_year_start": {
    "new_func": "commence_annual_check",
    "description": "Assesses if a given timestamp coincides with the commencement of the calendar year. It outputs a truth value indicating this condition.\nParameters: ts (Timestamp) - Point in time to evaluate.\nReturns: bool - True if the timestamp aligns with the start of the year, False otherwise.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Easter.is_quarter_start": {
    "new_func": "initiate_quarterly_verification",
    "description": "Determines if a specific timestamp matches the initiation of a fiscal quarter. It delivers a boolean outcome reflecting this situation.\nParameters: ts (Timestamp) - Moment to check.\nReturns: bool - True if the timestamp signifies the start of a quarter, False otherwise.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Easter.kwds": {
    "new_func": "offset_parameter_map",
    "description": "Provides a mapping containing additional arguments relevant to the temporal offset.\nParameters: None.\nReturns: dict - A dictionary of extra parameters associated with the offset.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Easter.is_year_end": {
    "new_func": "conclude_annual_assessment",
    "description": "Evaluates whether a certain timestamp aligns with the conclusion of a calendar year, returning a boolean indicator of this status.\nParameters: ts (Timestamp) - The instant in time to test.\nReturns: bool - True if the timestamp corresponds with the end of the year, False otherwise.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Easter.n": {
    "new_func": "offset_integer_value",
    "description": "Accesses the integer value that specifies the magnitude of the offset.\nParameters: None.\nReturns: int - The integer representing the offset's magnitude.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Easter.name": {
    "new_func": "resurrection_frequency_identifier",
    "description": "Outputs a textual label that indicates the base recurrence interval of the object.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Easter.nanos": {
    "new_func": "resurrection_nanosecond_value",
    "description": "Provides the nanosecond scale measurement of the object's offset.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Easter.rule_code": {
    "new_func": "resurrection_policy_identifier",
    "description": "Outputs a short string used as a quick reference to the object's offset rule.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Easter.normalize": {
    "new_func": "resurrection_evening",
    "description": "Adjusts the object's offset to the very start of the day (midnight) prior to the application of the offset.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.FY5253": {
    "new_func": "financial_cycle_organizer",
    "description": "Defines a fiscal calendar system where the financial year spans 52 to 53 weeks. It ensures the closing of the financial year on a consistent weekday, aiding in the comparison of financial reports over different periods. This system is tailored for specific sectors that benefit from uniform week-based fiscal periods. Parameters: year_span: The number of years this calendar should cover. midnight_adjust: A boolean flag indicating whether to adjust the starting and ending dates of the period to midnight. week_day: An integer representing the day of the week (0 for Monday to 6 for Sunday) on which the fiscal year should end. closure_month: An integer from 1 to 12 denoting the month in which the fiscal year terminates. pattern: A string specifying the approach for applying the calendar system, either aligning the end of the fiscal year to the nearest weekday to the month's end ('nearest') or always on the last weekday of the final month ('last').",
    "class": "tseries"
  },
  "pandas.tseries.offsets.FY5253.is_month_end": {
    "new_func": "terminal_day_of_month_check",
    "description": "Determines if a given point in time coincides with the last day of a month. It produces a truth value indicating the condition.\nParameters: ts (datetime-like) - Point in time to evaluate.\nReturns: bool - True if it is the final day of the month, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.FY5253.is_on_offset": {
    "new_func": "frequency_congruence",
    "description": "Assesses whether a specific moment aligns with the established periodicity. Outputs a truth value based on this alignment.\nParameters: dt (datetime-like) - The moment to be evaluated against the period.\nReturns: bool - True if there is alignment, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.FY5253.is_month_start": {
    "new_func": "initial_day_of_month_check",
    "description": "Evaluates if a temporal instance corresponds with the initial day of a month. Outputs a boolean representing this occurrence.\nParameters: ts (datetime-like) - The temporal instance to test.\nReturns: bool - True if it is the commencement day of the month, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.FY5253.is_year_end": {
    "new_func": "culminating_day_of_year_check",
    "description": "Checks if a temporal point falls on the closing day of a year. It yields a boolean indicative of this event.\nParameters: ts (datetime-like) - The temporal point for assessment.\nReturns: bool - True if it matches the final day of the year, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.FY5253Quarter.is_quarter_start": {
    "new_func": "inauguration_periodic",
    "description": "Assesses whether a specific timestamp matches with the commencement of a financial quarter. Outputs a truth value based on this evaluation. Parameters: ts (Timestamp) - The moment in time to be checked. Returns: bool - Indicates whether the timestamp corresponds with the onset of a financial quarter.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.FY5253Quarter.kwds": {
    "new_func": "extra_parameters",
    "description": "Retrieves a dictionary containing additional arguments relevant to the financial quarter offset. Returns: dict - A collection of key-value pairs representing supplementary parameters.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.FY5253Quarter.is_year_end": {
    "new_func": "closure_annual",
    "description": "Determines if a timestamp falls on the concluding day of the fiscal year, returning a truth value indicative of this condition. Parameters: ts (Timestamp) - The temporal point to analyze. Returns: bool - True if the timestamp is on the final day of the fiscal year, False otherwise.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.FY5253Quarter.is_quarter_end": {
    "new_func": "termination_periodic",
    "description": "Checks if a provided timestamp aligns with the terminal day of a fiscal quarter and yields a boolean reflecting this relation. Parameters: ts (Timestamp) - The specific instant in time to evaluate. Returns: bool - True if the timestamp matches the last day of a fiscal quarter, False if not.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.FY5253Quarter.startingMonth": {
    "new_func": "initialMonthFiscalQuartet",
    "description": "Retrieves the month when the fiscal quarter period commences for the 52-53 week accounting year structure.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.FY5253Quarter.year_has_extra_week": {
    "new_func": "leapWeekPresence",
    "description": "Evaluates whether the specified date falls within a fiscal year that contains an additional week, adhering to the 52-53 week accounting system. Parameters: dt (datetime-like) - The date to assess. Returns: bool - True if the year includes an extra week, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Hour": {
    "new_func": "TemporalStep",
    "description": "Represents a temporal increment measured in hours, facilitating date and time arithmetic. Parameters: n (int, default 1) - The quantity of hours to advance.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.FY5253Quarter.weekday": {
    "new_func": "quarterWeekdayAnchor",
    "description": "Determines the specific day of the week used as a reference point for the fiscal quarter within the 52-53 week accounting cycle.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Hour.delta": {
    "new_func": "hourlyTimeSpan",
    "description": "Obtains the time duration value in a timedelta object that represents the hour span.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Hour.is_on_offset": {
    "new_func": "timestamp_intersects_frequency",
    "description": "Determines if a specific point in time coincides with the start of this time frequency. Useful for filtering or segmenting data based on temporal alignment.\nParameters:\ndt (datetime.datetime) - The point in time to evaluate alignment with the frequency.\nReturns: bool - True if the timestamp aligns with the frequency, False otherwise.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Hour.is_month_start": {
    "new_func": "commences_monthly_cycle",
    "description": "Evaluates if a given moment marks the commencement of a new month. This can be utilized to identify transitions between monthly periods.\nParameters:\nts (datetime.datetime) - The moment to check for alignment with the start of a month.\nReturns: bool - True if the timestamp coincides with the beginning of the month, False otherwise.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Hour.is_quarter_start": {
    "new_func": "initiates_quarterly_period",
    "description": "Assesses whether a given instant signifies the initiation of a quarterly interval. This function is useful in temporal analyses that require segmentation by quarters.\nParameters:\nts (datetime.datetime) - The instant to verify for concurrence with the start of a quarter.\nReturns: bool - True if the timestamp corresponds with the onset of a quarter, False otherwise.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Hour.is_anchored": {
    "new_func": "fixed_frequency_check",
    "description": "Previously checked if the time frequency was anchored. However, this method is now deprecated and always returns False. It is recommended to use a direct False value in place of this function.\nParameters: None\nReturns: False - Always returns False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Hour.is_quarter_end": {
    "new_func": "concludes_quarterly_cycle",
    "description": "Determines if a specific moment coincides with the termination of a quarterly period. This is particularly useful for financial and statistical analysis that relies on quarter-based timeframes.\nParameters:\nts (datetime.datetime) - The moment to assess for its position at the end of a quarter.\nReturns: bool - True if the timestamp is concurrent with the end of a quarter, False otherwise.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Hour.is_year_start": {
    "new_func": "initial_annum_check",
    "description": "Determines if a given timestamp corresponds with the commencement of an annum. It evaluates whether the specific point in time marks the beginning of a new calendar year.\nParameters: ts (Timestamp) - The point in time to evaluate.\nReturns: bool - True if the timestamp is at the start of the year, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Hour.normalize": {
    "new_func": "standardize_to_midnight",
    "description": "Adjusts the time component of the offset to the start of the day (00:00:00).\nReturns: An offset instance with the time normalized to midnight.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Hour.rule_code": {
    "new_func": "offset_identifier",
    "description": "Retrieves an identifier that represents the type of frequency offset.\nReturns: str - A string code that uniquely identifies the frequency offset.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.LastWeekOfMonth": {
    "new_func": "terminal_week_selector",
    "description": "Represents a periodical date selector targeting a specific day within the concluding week of each calendar month. This temporal construct is designed to pinpoint occurrences such as 'the final Thursday of every month'.\nParameters:\nn (int, default 1) - The count of monthly intervals.\nstandardize (bool, default False) - Whether to reset the starting and ending dates to the initial hours of the day.\nweek_day (int, {0, 1, \u2026, 6}, default 0) - An integer indicating the desired day of the week, commencing with 0 for Monday up to 6 for Sunday.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.LastWeekOfMonth.is_on_offset": {
    "new_func": "final_week_coincidence_check",
    "description": "Assesses if a given point in time coincides with the frequency of the final week of the month. It produces a truth value indicating the presence or absence of this alignment. Parameters: dt (datetime.datetime) - The point in time to evaluate. Returns: bool - Truth value indicating the alignment with the frequency.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.LastWeekOfMonth.kwds": {
    "new_func": "extra_parameters_retrieve",
    "description": "Accesses a dictionary containing additional parameters relevant to the final week of the month offset. Returns: dict - A dictionary of extra parameters.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.LastWeekOfMonth.is_quarter_start": {
    "new_func": "initial_trimester_alignment",
    "description": "Determines if a specific moment falls at the commencement of a financial quarter. Outputs a truth value related to this occurrence. Parameters: ts (datetime.datetime) - The point in time to check. Returns: bool - Truth value for the start of a financial quarter.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.LastWeekOfMonth.is_year_end": {
    "new_func": "closure_annual_verification",
    "description": "Checks if a given timestamp corresponds with the termination of a calendar year, providing a boolean outcome. Parameters: ts (datetime.datetime) - The timestamp to verify. Returns: bool - Truth value denoting the timestamp's position at the year's end.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.LastWeekOfMonth.week": {
    "new_func": "final_seven_days_period",
    "description": "Retrieves the week of the month when the last week occurs for a given LastWeekOfMonth offset instance. The week is returned as an integer value.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Micro": {
    "new_func": "subsecond_shift",
    "description": "Defines a temporal displacement by a specified number of microseconds. This class allows for precise time increments at the microsecond level. Parameters: n (int, optional, default 1) - The quantity of microseconds the offset represents.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Micro.copy": {
    "new_func": "duplicate_time_shift",
    "description": "Generates an exact replica of the current microsecond-level offset instance, ensuring that the original object remains unaltered.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.LastWeekOfMonth.weekday": {
    "new_func": "terminal_weekday_of_month",
    "description": "Retrieves the day of the week on which the last week of the month falls for a particular LastWeekOfMonth offset instance. The weekday is provided as an integer, where Monday is 0 and Sunday is 6.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Micro.freqstr": {
    "new_func": "microsecond_frequency_descriptor",
    "description": "Yields a textual representation of the microsecond-level frequency associated with the offset instance.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Micro.is_anchored": {
    "new_func": "microsecond_fixed",
    "description": "This method was used to check if the microsecond frequency was fixed. As of version 2.2.0, this method is deprecated and always returns False. Users should directly use False in its place.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Micro.is_month_start": {
    "new_func": "initial_microsecond",
    "description": "Determines if a given timestamp coincides with the initial microsecond of a month. The method returns a boolean value corresponding to this check.\\nParameters: ts (datetime-like) - The timestamp to be examined.\\nReturns: bool - True if the timestamp is at the start of the month, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Micro.is_month_end": {
    "new_func": "terminal_microsecond",
    "description": "Assesses whether a specified timestamp aligns with the concluding microsecond of a month. This function yields a true or false outcome based on this criterion.\\nParameters: ts (datetime-like) - The timestamp under scrutiny.\\nReturns: bool - True if the timestamp is at the end of the month, else False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Micro.is_on_offset": {
    "new_func": "microsecond_concurrence",
    "description": "Evaluates the coincidence of a particular timestamp with the designated microsecond frequency. Outputs a boolean indicating the result of this evaluation.\\nParameters: dt (datetime-like) - The point in time to verify for frequency intersection.\\nReturns: bool - True if the timestamp intersects with the frequency, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Micro.delta": {
    "new_func": "microsecond_difference",
    "description": "Calculates the time span difference in microseconds for the specified frequency.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Micro.is_quarter_start": {
    "new_func": "microscopic_initial_quadrant_check",
    "description": "Determines whether a given point in time coincides with the outset of a fiscal quadrant. The method yields a truth value confirming the alignment with the start of a calendar quarter.\nParameters: ts (timestamp) - The moment in time to be evaluated.\nReturns: bool - True if the timestamp aligns with the beginning of a quarter, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Micro.is_quarter_end": {
    "new_func": "microscopic_terminal_quadrant_check",
    "description": "Assesses if the specified temporal marker aligns with the culmination of a quarter. It generates a truth value indicative of the moment's concurrence with the quarter's closure.\nParameters: ts (timestamp) - The temporal marker under scrutiny.\nReturns: bool - True if the timestamp coincides with a quarter's end, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Micro.is_year_end": {
    "new_func": "microscopic_annual_closure_check",
    "description": "Evaluates whether a specific temporal point coincides with the finality of a calendar cycle. This function outputs a truth value indicating whether the provided timestamp matches the last tick of an annual period.\nParameters: ts (timestamp) - The point in time to be assessed.\nReturns: bool - True if the timestamp matches the end of a year, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Micro.is_year_start": {
    "new_func": "microscopic_annual_commencement_check",
    "description": "Determines if a chosen moment in time corresponds with the inception of an annual period. A boolean output indicates the concurrence of the timestamp with the initial phase of the year.\nParameters: ts (timestamp) - The moment in time to ascertain.\nReturns: bool - True if the timestamp is concurrent with the start of a year, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Micro.nanos": {
    "new_func": "microscopic_nano_count",
    "description": "Computes the aggregate quantity of nanoseconds encapsulated within the microsecond frequency. An integer is returned representing this total count.\nReturns: int - The sum of nanoseconds.\nExceptions: Raises a ValueError if the frequency is of a non-fixed type.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Milli.delta": {
    "new_func": "millisecond_interval",
    "description": "Retrieves the difference in time at a millisecond granularity. This property is expressed as a Timedelta object that represents the duration of the offset.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Milli.copy": {
    "new_func": "duplicate_millisecond_offset",
    "description": "Creates and returns an identical instance of the current millisecond time increment. This method ensures the creation of a new object with the same properties.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Milli": {
    "new_func": "millisecond_shift",
    "description": "Represents a time displacement in units of milliseconds. This class enables the manipulation of datetime objects by increments specified in milliseconds.\nParameters:\nn (integer, optional, default is 1) - The quantity of milliseconds to represent.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Milli.freqstr": {
    "new_func": "milliseconds_frequency_string",
    "description": "Yields a textual representation of the millisecond-based time increment. This string succinctly conveys the magnitude of the temporal shift.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Milli.is_on_offset": {
    "new_func": "intersects_with_millisecond",
    "description": "Evaluates the alignment of a specific point in time with the defined millisecond-based interval. It returns a boolean indicating whether the given datetime coincides with the onset of the shift.\nParameters:\ndt (datetime.datetime) - The point in time to assess for alignment with the time increment.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Minute.is_quarter_end": {
    "new_func": "terminus_trimonthly_check",
    "description": "Determines if a specified timestamp coincides with the final moment of a three-month period. It outputs true or false based on the assessment of the timestamp.\nParameters: ts (Timestamp) - The point in time to assess.\nReturns: bool - True if the timestamp aligns with the end of a fiscal quarter, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Minute.is_anchored": {
    "new_func": "fixed_position_status",
    "description": "Provides a constant response indicating the lack of a fixed temporal reference. The method is considered obsolete and is scheduled for removal in subsequent releases.\nReturns: bool - Always returns False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Minute.is_quarter_start": {
    "new_func": "inception_trimonthly_check",
    "description": "Evaluates if a given timestamp aligns with the initial moment of a quarterly cycle. It yields a boolean value based on this evaluation.\nParameters: ts (Timestamp) - The point in time to evaluate.\nReturns: bool - True if the timestamp corresponds to the start of a quarter, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Minute.n": {
    "new_func": "increment_value",
    "description": "Accesses the magnitude of the time increment associated with the object. This attribute represents the number of minutes for the offset.\nReturns: int - The number of minutes.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Minute.is_year_start": {
    "new_func": "commencing_annual_instant",
    "description": "Assesses whether a given timestamp coincides with the commencement of a year. It yields a truth value indicating the start of an annual cycle.\nParameters: ts (Timestamp) - The point in time to evaluate.\nReturns: bool - True if the timestamp marks the beginning of the year, False otherwise.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Minute.is_year_end": {
    "new_func": "concluding_annual_instant",
    "description": "Determines if a specific timestamp aligns with the closure of a year. It produces a boolean result signifying the end of an annual period.\nParameters: ts (Timestamp) - The moment in time to check.\nReturns: bool - True if the timestamp is at the year's end, False otherwise.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Minute.nanos": {
    "new_func": "nano_interval_quantity",
    "description": "Computes the aggregate nanosecond count for the minute frequency. An error is raised if the frequency is not fixed.\nReturns: int - The total nanoseconds for the minute interval.\nRaises: ValueError - If the frequency is variable.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.MonthBegin.is_on_offset": {
    "new_func": "commencement_alignment_check",
    "description": "Determines if a specific point in time coincides with the initiation point of a period. This method assesses the alignment with the start of a period.\\nParameters: dt (datetime.datetime) - The point in time to evaluate for alignment.\\nReturns: bool - True if the timestamp aligns with the start of the period, False otherwise.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.MonthBegin.is_quarter_start": {
    "new_func": "trimester_commencement",
    "description": "Assesses if the provided temporal marker signifies the commencement of a trimester.\\nParameters: ts (timestamp) - The temporal marker to evaluate.\\nReturns: bool - True if it marks the beginning of a trimester, False otherwise.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.MonthBegin.is_year_start": {
    "new_func": "annual_inception_check",
    "description": "Verifies if a temporal data point coincides with the initial day of an annum.\\nParameters: ts (timestamp) - The temporal data point to verify.\\nReturns: bool - True if it represents the start of an annum, False otherwise.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.MonthEnd.copy": {
    "new_func": "duplicate_period_terminus",
    "description": "Creates a duplicate of the period's terminal point object. This is useful when an unaltered clone of the object is needed for further operations or manipulations.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.MonthEnd.is_month_start": {
    "new_func": "commencement_of_interval",
    "description": "Determines if a given point in time coincides with the beginning of the interval. It checks this alignment for a specified datetime instance and returns a truth value. Parameters: ts (datetime-like) - The point in time to evaluate. Returns: bool - True if the instance aligns with the interval's start, False otherwise.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.MonthEnd.is_quarter_end": {
    "new_func": "culmination_of_quartile",
    "description": "Evaluates if a specified temporal point corresponds with the final day of a quartile period. It returns a boolean signifying this occurrence. Parameters: ts (datetime-like) - The moment in time to be evaluated. Returns: bool - True if the moment coincides with the quartile's last day, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.MonthEnd.is_on_offset": {
    "new_func": "intersects_with_period",
    "description": "Assesses whether a specified moment in time intersects with the designated period frequency. Parameters: dt (datetime.datetime) - The moment in time to check for an intersection with the period frequency. Returns: bool - True if there is an intersection, False otherwise.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.MonthEnd.is_month_end": {
    "new_func": "terminus_of_interval",
    "description": "Checks if a particular temporal point matches with the closure of the interval. This function discerns whether the provided datetime instance is the last day of the interval. Parameters: ts (datetime-like) - The point in time to verify. Returns: bool - Indicates whether the point is the final day of the interval.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Nano.is_year_end": {
    "new_func": "culmination_of_annum_check",
    "description": "Ascertains if a given temporal point matches with the cessation of a calendar year. This function accepts a timestamp and produces a boolean reflecting whether the condition is met.\nParameters: ts (datetime-like) - The temporal point for determination.\nReturns: bool - True if the timestamp falls on the last day of the year, False otherwise.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Nano.is_on_offset": {
    "new_func": "temporal_intersection_check",
    "description": "Determines the concurrence of a specific datetime with the defined frequency interval. It takes a datetime object and returns a boolean indicating if an overlap occurs.\nParameters: dt (datetime.datetime) - The datetime object to test for frequency intersection.\nReturns: bool - True if there is an intersection with the frequency, False otherwise.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.QuarterBegin.startingMonth": {
    "new_func": "QuarterBegin_initial_quarter_month",
    "description": "Retrieves the initial month of the fiscal quarter period. This attribute designates the month when a quarter commences.\nParameters: None.\nReturns: int - The month number with which a quarter begins.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.QuarterEnd.freqstr": {
    "new_func": "periodicity_identifier",
    "description": "Provides a textual representation of the temporal interval's frequency.\nParameters: None.\nReturns: str - Textual depiction of the interval cadence.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.QuarterEnd": {
    "new_func": "end_of_term_adjustment",
    "description": "A class that represents the adjustment for end dates of fiscal quarters. It supports customization of the quarter period ending based on the month specified.\nParameters:\nn (int, default 1) - The number of quarter terms to represent.\nnormalize (bool, default False) - Whether to set the start/end dates to midnight before generating the date range.\nstartingMonth (int, default 3) - The particular month number that signifies the commencement of the quarter term.\nReturns: An instance that can be used to shift dates to the end of the specified fiscal quarter.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.QuarterEnd.is_month_start": {
    "new_func": "commences_with_cycle",
    "description": "Assesses whether a given datetime instance coincides with the initial day of a month. The function returns a truth value indicating the alignment of the date with the cycle's commencement.\nParameters: ts (datetime-like) - The datetime instance to evaluate.\nReturns: bool - True if the instance is the first day of a month, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.QuarterEnd.is_month_end": {
    "new_func": "concludes_with_cycle",
    "description": "Determines if a specified datetime instance aligns with the terminal day of a month. It outputs a truth value reflecting the concurrence of the date with the cycle's conclusion.\nParameters: ts (datetime-like) - The datetime instance to analyze.\nReturns: bool - True if the instance is the last day of a month, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.QuarterEnd.is_quarter_start": {
    "new_func": "initiates_with_quadrant",
    "description": "Checks if a provided datetime instance corresponds to the commencement of a financial quarter. It yields a boolean value signifying whether the date marks the onset of the quarter.\nParameters: ts (datetime-like) - The datetime instance to scrutinize.\nReturns: bool - True if the instance marks the start of a quarter, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.QuarterEnd.is_quarter_end": {
    "new_func": "terminates_with_quadrant",
    "description": "Verifies if a certain datetime instance matches the culmination of a financial quarter. The result is a boolean indicating if the date signifies the quarter's closing.\nParameters: ts (datetime-like) - The datetime instance to verify.\nReturns: bool - True if the instance signifies the end of a quarter, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.QuarterEnd.is_year_start": {
    "new_func": "QuarterEnd_commences_annual_cycle",
    "description": "Checks if a given timestamp corresponds to the initial day of the calendar year. Outputs a boolean value as the result. Parameters: ts (Timestamp) - The point in time to be checked. Returns: bool - True if the timestamp is the first day of the year, False otherwise.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Second.is_month_end": {
    "new_func": "final_moment_monthly",
    "description": "Determines if a given timestamp coincides with the final day of a month. Utilizes a specific time unit based on the smallest measurable interval of time to assess the timing within the calendar structure.\nParameters: ts (Timestamp) - The point in time to be evaluated.\nReturns: bool - True if the timestamp aligns with the last day of the month, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Second.is_quarter_start": {
    "new_func": "initiation_instant_quarterly",
    "description": "Evaluates if a specified timestamp aligns with the commencement of a fiscal quarter. Leverages a minimal time unit to determine the position of the timestamp within the fiscal calendar.\nParameters: ts (Timestamp) - The moment in time under consideration.\nReturns: bool - True if the timestamp corresponds with the start of a quarter, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Second.is_quarter_end": {
    "new_func": "termination_tick_quarterly",
    "description": "Checks whether a provided timestamp matches the concluding date of a fiscal quarter. Employs the smallest unit of time to ascertain the timestamp's placement in terms of the business calendar.\nParameters: ts (Timestamp) - The point in time to be scrutinized.\nReturns: bool - True if the timestamp is synchronous with the quarter's final day, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Second.is_year_end": {
    "new_func": "culmination_clock_annual",
    "description": "Determines if a certain timestamp falls on the last day of the year. Uses the briefest division of time to confirm the timestamp's occurrence in the annual calendar cycle.\nParameters: ts (Timestamp) - The time instance to be verified.\nReturns: bool - True if the timestamp coincides with the year's end, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Second.n": {
    "new_func": "time_unit_multiplier",
    "description": "Represents the multiplier for the smallest time unit within a time delta object, indicating the number of such units.\nReturns: int - The multiplier for the base unit of time.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Second.is_on_offset": {
    "new_func": "intersects_temporal_frequency",
    "description": "Evaluates whether a specified datetime aligns with the interval of the temporal unit. It returns a truth value indicating the presence or absence of alignment. Parameters: dt (datetime.datetime) - The datetime instance to evaluate against the interval. Returns: bool - True if the datetime intersects with the unit's frequency, False otherwise.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Second.is_year_start": {
    "new_func": "Second_commences_annual_cycle",
    "description": "Checks if a given timestamp coincides with the commencement of the annual cycle. Parameters: ts (datetime.datetime) - The timestamp to evaluate. Returns: bool - True if the timestamp is at the start of the year, False otherwise.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Second.nanos": {
    "new_func": "interval_nanosecond_total",
    "description": "Calculates the aggregate nanosecond count for the specific interval unit. It may raise an exception if the unit does not have a fixed frequency. Returns: int - The total nanosecond count for the interval unit. Raises: ValueError - If the interval unit's frequency is variable.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Second.rule_code": {
    "new_func": "tick_interval_code",
    "description": "Retrieves the shorthand representation of the time interval for a given frequency object denoting seconds.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.SemiMonthBegin": {
    "new_func": "bi_monthly_start_adjuster",
    "description": "Creates a frequency object that shifts dates to the specified days at the beginning of every two-week period within a month. It can advance dates by a specified number of increments, and optionally normalize the time component of starting or ending timestamps. Parameters: - increments (int, default 1): The number of two-week periods to shift by. - align_to_midnight (bool, default False): Whether to adjust dates to the stroke of midnight. - specified_day (int, {1, 3, ..., 27}, default 15): The day of the month to use as the anchor for the bi-monthly period.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Second.normalize": {
    "new_func": "tick_align_to_midnight",
    "description": "Adjusts the base frequency object representing seconds such that the time component of its starting or ending points is aligned with the beginning of the day.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.SemiMonthBegin.day_of_month": {
    "new_func": "bi_monthly_anchor",
    "description": "Accesses or sets the specific day within the month that serves as the anchor point for the bi-monthly frequency adjustment.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.SemiMonthBegin.copy": {
    "new_func": "duplicate_bi_monthly_start",
    "description": "Generates an exact replica of the current bi-monthly frequency adjustment object.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.SemiMonthBegin.is_month_start": {
    "new_func": "initial_half_month_check",
    "description": "Determines if a given timestamp coincides with the initial day of a month. It evaluates the timestamp to establish if it matches the commencement of the half-month period.\nParameters: ts (Timestamp) - The point in time to evaluate.\nReturns: bool - True if the timestamp aligns with the start of the month, False otherwise.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.SemiMonthBegin.is_quarter_start": {
    "new_func": "initial_quarter_period_check",
    "description": "Evaluates if a specific timestamp aligns with the beginning of a fiscal quarter. This function checks the provided timestamp to ascertain its correspondence with the commencement of the quarter.\nParameters: ts (Timestamp) - The point in time to evaluate.\nReturns: bool - True if the timestamp matches the start of a quarter, False otherwise.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.SemiMonthBegin.is_year_end": {
    "new_func": "terminal_annual_instant_check",
    "description": "Assesses if a particular timestamp falls on the final day of the calendar year. This function scrutinizes the provided timestamp to determine if it represents the conclusion of the year.\nParameters: ts (Timestamp) - The point in time to evaluate.\nReturns: bool - True if the timestamp signifies the end of a year, False otherwise.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.SemiMonthBegin.is_year_start": {
    "new_func": "commencement_annual_instant_check",
    "description": "Confirms whether a timestamp is indicative of the first day of the calendar year. It checks the timestamp against the criteria to verify if it signifies the onset of the year.\nParameters: ts (Timestamp) - The point in time to assess.\nReturns: bool - True if the timestamp indicates the beginning of a year, False otherwise.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.SemiMonthBegin.kwds": {
    "new_func": "additional_parameters_retrieval",
    "description": "Retrieves a dictionary containing supplementary parameters pertinent to the time offset. This function provides access to various other settings that can modify the behavior of the time offset.\nReturns: dict - A collection of extra parameters.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.SemiMonthEnd": {
    "new_func": "BiMonthlyTerminal",
    "description": "Generates two date offsets within a single month, targeting the final day and a specified intermediate day. This class facilitates the creation of date ranges that repeat semi-monthly at designated points.\\nParameters:\\nn (int, default 1) - The number of periods to include.\\nnormalize (bool, default False) - Adjusts the start and end times to the stroke of midnight prior to generating the range.\\nday_of_month (int, {1, 3,\u2026,27}, default 15) - Fixed calendar day to use for the mid-month offset.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.SemiMonthEnd.day_of_month": {
    "new_func": "MidPeriodDay",
    "description": "Accesses the specific calendar day used for the mid-month portion of the bi-monthly offset.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.SemiMonthEnd.copy": {
    "new_func": "DuplicateFrequency",
    "description": "Produces an exact replica of the current bi-monthly offset instance.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.SemiMonthEnd.freqstr": {
    "new_func": "PeriodicityNotation",
    "description": "Yields a textual representation that denotes the frequency of the bi-monthly offset.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Tick.delta": {
    "new_func": "interval_span",
    "description": "Retrieves the time span represented by the frequency object in terms of the timedelta type. Returns: timedelta - The time duration the frequency object represents.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Tick.is_on_offset": {
    "new_func": "coincides_with_interval",
    "description": "Evaluates if a particular datetime aligns with the specified interval of the frequency. Parameters: dt (datetime-like) - The datetime to test for alignment. Returns: bool - True if the datetime aligns with the frequency, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Week": {
    "new_func": "SevenDayInterval",
    "description": "Represents a regular interval of seven days. It can be used to generate a sequence of dates separated by a specified number of week-long periods. This class also allows for normalization of start and end dates to midnight and can target a specific day within the week.\nParameters: \n- n (integer, default 1): The quantity of seven-day periods.\n- normalize (boolean, default False): Adjust start/end dates to the beginning of the day.\n- weekday (integer or None, default None): Target a day within the week range, with 0 representing the first day (typically Monday) and 6 as the last day (typically Sunday).",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Week.copy": {
    "new_func": "DuplicateInterval",
    "description": "Creates an exact replica of the current weekly time span.\nReturns: A new instance with identical properties as the original weekly time span.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Tick.is_year_end": {
    "new_func": "TerminalAnnualMoment",
    "description": "Assesses if a given timestamp occurs at the final moment of a calendar year.\nParameters: ts (timestamp) - The point in time to evaluate.\nReturns: boolean - True if the timestamp coincides with the end of the year, otherwise False.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Week.freqstr": {
    "new_func": "WeeklyCycleNotation",
    "description": "Provides a textual representation of the seven-day cycle frequency.\nReturns: string - The textual depiction of the weekly interval.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Week.is_month_start": {
    "new_func": "InitialMonthlyInstant",
    "description": "Determines if a specific timestamp aligns with the commencement of a month.\nParameters: ts (timestamp) - The moment in time to check.\nReturns: boolean - True if the timestamp aligns with the start of the month, False otherwise.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Week.is_on_offset": {
    "new_func": "weekly_sync_check",
    "description": "Determines if a specific point in time aligns with the start of the defined weekly period. This method checks for alignment between a given datetime instance and the frequency period of the week.\nParameters: dt (datetime.datetime) - The point in time to verify for alignment with the weekly frequency.\nReturns: bool - True if the datetime instance aligns with the frequency period, False otherwise.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Week.is_anchored": {
    "new_func": "weekly_period_unit_check",
    "description": "Evaluates whether the frequency period represents a base unit interval, specifically one week in duration. This method is now deprecated and it is recommended to check if the frequency period is equal to one directly.\nParameters: None.\nReturns: bool - True if the frequency is a single unit interval, False otherwise.\nNote: Deprecated since version 2.2.0 and will be removed in a future version.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Week.is_month_end": {
    "new_func": "concludes_monthly_cycle",
    "description": "Assesses if a given timestamp coincides with the final day of the month. This method verifies if a specific datetime occurrence marks the end of a monthly cycle.\nParameters: ts (datetime.datetime) - The timestamp to assess for its position at the end of the month.\nReturns: bool - True if the timestamp is on the last day of a month, False otherwise.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Week.is_year_end": {
    "new_func": "terminates_annual_sequence",
    "description": "Determines if a particular timestamp coincides with the end of an annual period. This method checks if a given datetime instance signifies the completion of the yearly cycle.\nParameters: ts (datetime.datetime) - The timestamp to evaluate for its occurrence at the year's end.\nReturns: bool - True if the timestamp falls on the last day of the year, False otherwise.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Week.is_quarter_end": {
    "new_func": "quarterly_terminus_alignment",
    "description": "Verifies whether a specified timestamp aligns with the concluding day of a fiscal quarter. This method ascertains if a particular datetime aligns with the cessation of a quarterly segment.\nParameters: ts (datetime.datetime) - The timestamp to confirm for alignment with the quarter's end.\nReturns: bool - True if the timestamp aligns with the end of a quarter, False otherwise.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Week.nanos": {
    "new_func": "microsecond_intervals",
    "description": "retrieves the microsecond duration for a weekly time interval.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Week.normalize": {
    "new_func": "standardize_weekly_time",
    "description": "modifies a weekly time span to begin at the start of the day.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.Week.rule_code": {
    "new_func": "weekly_period_identifier",
    "description": "provides a shorthand representation for the weekly frequency.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.WeekOfMonth": {
    "new_func": "monthly_weekday_sequence",
    "description": "specifies a sequence of dates based on the occurrence of specific weekdays within a month's weeks. This class can be used to generate dates such as 'the second Tuesday of each month'. Parameters: months_count (int, default 1) - The count of months for the range. time_normalization (bool, default False) - Adjusts the starting and ending times to the beginning of the day. week_of_month (int {0, 1, 2, 3, ...}, default 0) - The ordinal number of the week within the month. day_of_week (int {0, 1, ..., 6}, default 0) - An integer denoting the day of the week, where 0 represents Monday and 6 represents Sunday. Returns: An object that enables generating date ranges based on the defined weekly and weekday criteria.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.WeekOfMonth.is_anchored": {
    "new_func": "unit_periodicity",
    "description": "Assesses if the frequency object represents a single-period frequency. Note that this method is deprecated and scheduled for future removal.\nParameters: None.\nReturns: Boolean - True if the frequency denotes a singular period, False otherwise (i.e., n=1).",
    "class": "tseries"
  },
  "pandas.tseries.offsets.YearBegin.is_year_start": {
    "new_func": "commencement_annum_check",
    "description": "Determines if a given timestamp corresponds to the initial day of an annum. It verifies if the input timestamp marks the commencement of a calendar year. Parameters: ts (Timestamp) - The point in time to check. Returns: bool - True if the timestamp aligns with the start of the year, False otherwise.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.YearBegin.is_quarter_end": {
    "new_func": "terminal_trimester_evaluation",
    "description": "Assesses whether a specific timestamp coincides with the final day of a trimester. This function evaluates if the provided timestamp falls on the ultimate day of any quarter. Parameters: ts (Timestamp) - The point in time to evaluate. Returns: bool - True if the timestamp is the last day of a quarter, False otherwise.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.YearBegin.is_year_end": {
    "new_func": "finalization_annum_inquiry",
    "description": "Checks if a particular timestamp aligns with the concluding day of an annum. It ascertains whether the given timestamp signifies the end of a calendar year. Parameters: ts (Timestamp) - The point in time to ascertain. Returns: bool - True if the timestamp corresponds to the year's final day, False otherwise.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.YearBegin.n": {
    "new_func": "incremental_annum_quantity",
    "description": "Represents the number of years for the offset to be applied from a starting point. This attribute denotes the magnitude of the annual increment or decrement for the offset. Parameters: None Returns: int - The number of annual periods for the offset.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.YearBegin.month": {
    "new_func": "initial_month_retrieval",
    "description": "Obtains the month value associated with the commencement of the annum. This attribute reflects the month number at which the year is considered to begin. Parameters: None Returns: int - The month number representing the start of the year.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.YearEnd.is_quarter_start": {
    "new_func": "initial_quarter_verifier",
    "description": "Checks if a given moment corresponds to the commencement of a fiscal quarter. Outputs a boolean value indicative of the result.\nParameters: timestamp (datetime.datetime) - The moment to be evaluated.\nReturns: bool - True if the moment marks the start of a quarter, False otherwise.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.YearEnd.is_month_start": {
    "new_func": "inaugural_day_assessment",
    "description": "Evaluates whether a specific timestamp falls on the initial day of the month. The function produces a boolean outcome.\nParameters: timestamp (datetime.datetime) - The timestamp to be checked.\nReturns: bool - True if the timestamp is the first day of the month, False otherwise.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.YearEnd.is_year_end": {
    "new_func": "culmination_period_query",
    "description": "Determines if a particular timestamp corresponds to the termination of the calendar year. It returns a boolean value reflecting this condition.\nParameters: timestamp (datetime.datetime) - The timestamp to scrutinize.\nReturns: bool - True if the timestamp signifies the end of the year, False otherwise.",
    "class": "tseries"
  },
  "pandas.tseries.offsets.YearEnd.name": {
    "new_func": "annual_frequency_alias",
    "description": "Retrieves the textual alias that denotes the underlying period's frequency, specifically for the conclusion of the year.",
    "class": "tseries"
  },
  "pandas.util.hash_pandas_object": {
    "new_func": "secure_item_digest",
    "description": "Computes a fixed-size digest for data structures, ensuring each element is uniquely identified. The result is a Series with hashed values of type uint64. Parameters: - obj (Index, Series, DataFrame): The data structure to hash. - index (bool, default True): Whether to include the data structure's index in the computation. - encoding (str, default 'utf8'): The character encoding for string data and keys. - hash_key (str, default '0123456789123456'): A key involved in the hash function, providing an additional layer of security. - categorize (bool, default True): Determines if object arrays should be converted to categorical type before hashing, which optimizes performance for arrays with repeated values. Returns: - Series: A series of 64-bit unsigned integers corresponding to the hashed values.",
    "class": "util"
  },
  "pandas.wide_to_long": {
    "new_func": "broad_to_deep_transform",
    "description": "Transforms data from a broad format with multiple related columns into a deep format with a multi-level index. Parameters: - df (DataFrame): The data structure in broad format. - stubnames (str or list-like): Prefixes of the wide-format variable names. - i (str or list-like): Identifier column(s) that uniquely define a row. - j (str): The new column name in the deep format that stores the suffixes. - sep (str, default ''): Separator character to be removed from the column names in the transition. - suffix (str, default '\\\\d+'): Regular expression to match the column suffixes. Returns: - DataFrame: A data structure in deep format with each prefix as a separate variable, indexed by the specified identifiers and suffixes.",
    "class": "main"
  }
}